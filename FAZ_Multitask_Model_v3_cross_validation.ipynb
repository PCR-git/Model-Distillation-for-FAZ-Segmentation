{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pas13I3Ho1uJ",
    "outputId": "c6d96e9e-18ea-40fc-9203-3fd9bb91229a"
   },
   "outputs": [],
   "source": [
    "%cd /Users/Pracioppo/Desktop/VPTR/VPTR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5erGq6DCneF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # Loading bar\n",
    "from PIL import Image\n",
    "\n",
    "from model import VPTREnc, VPTRDec, VPTRDisc, init_weights\n",
    "from model import GDL, MSELoss, L1Loss, GANLoss\n",
    "from utils import get_dataloader\n",
    "from utils import VidCenterCrop, VidPad, VidResize, VidNormalize, VidReNormalize, VidCrop, VidRandomHorizontalFlip, VidRandomVerticalFlip, VidToTensor\n",
    "from utils import visualize_batch_clips, save_ckpt, load_ckpt, set_seed, AverageMeters, init_loss_dict, write_summary, resume_training\n",
    "from utils import set_seed\n",
    "from utils import f_rescale_dataset, f_Residuals, f_reshape_training_data, f_rotate, f_rotate_and_zoom, f_random_crop, f_rotate_and_zoom_all, f_crop_all, f_flip_all, f_augment_dataset2\n",
    "\n",
    "from utils import KTHDataset, BAIRDataset, MovingMNISTDataset\n",
    "\n",
    "set_seed(2024)\n",
    "torch.manual_seed(2024)\n",
    "\n",
    "import argparse\n",
    "\n",
    "import cv2\n",
    "from tabulate import tabulate\n",
    "\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXakUi8kHYAX"
   },
   "outputs": [],
   "source": [
    "ckpt_save_dir = Path('Y:/FAZ/Healthy/all_Healthy/Models/FAZ_ckpt')\n",
    "tensorboard_save_dir = Path('Y:/FAZ/Healthy/all_Healthy/Models/FAZ_tensorboard')\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "resume_ckpt = None\n",
    "\n",
    "summary_writer = SummaryWriter(tensorboard_save_dir.absolute().as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('SINDy NN')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAIwvSK-ouwf"
   },
   "outputs": [],
   "source": [
    "args.num_past_frames = 1\n",
    "args.num_future_frames = 1\n",
    "args.encH, args.encW, args.encC = 16, 16, 128 # Increased dimensions for 512 x 512 images\n",
    "args.img_channels = 1 #3 channels for BAIR datset\n",
    "args.epochs = 10\n",
    "\n",
    "args.N = 10\n",
    "\n",
    "args.AE_lr = 2e-4\n",
    "\n",
    "args.batch_size = args.N\n",
    "test_past_frames = 1\n",
    "test_future_frames = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AQuHiikouwg",
    "outputId": "6f7354a6-b755-45fc-b4bf-0f4a5dbbd0d2"
   },
   "outputs": [],
   "source": [
    "args.device = torch.device('cuda:0')\n",
    "# args.device = torch.device('cpu')\n",
    "print(f\"Using {args.device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_splits(imgs,split=4):\n",
    "    num_data = int(imgs.size()[0])\n",
    "    num_split = int(num_data/split)\n",
    "\n",
    "    tot_idxs_s = np.arange(num_data)\n",
    "    np.random.shuffle(tot_idxs_s)\n",
    "\n",
    "    res = np.mod(num_data,num_split)\n",
    "    ones = np.ones(res)\n",
    "\n",
    "    splits = []\n",
    "    R = 0\n",
    "    for i in np.arange(split):\n",
    "        if len(ones) > i:\n",
    "            r_i = int(ones[i])\n",
    "        else:\n",
    "            r_i = 0\n",
    "        splits.append(np.sort(tot_idxs_s[i*num_split+R:(i+1)*num_split+R+r_i]).tolist())\n",
    "        R += r_i\n",
    "\n",
    "    return splits\n",
    "\n",
    "def flatten_list(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "def train_test_split(imgs,masks,splits,test_r):\n",
    "\n",
    "    test_idxs = np.array(splits[test_r]).flatten().astype('int')\n",
    "    train_idxs = np.array(flatten_list(splits[0:test_r] + splits[test_r+1:])).astype('int')\n",
    "    train_idxs = np.sort(train_idxs)\n",
    "\n",
    "    train_imgs = imgs[train_idxs]\n",
    "    test_imgs = imgs[test_idxs]\n",
    "\n",
    "    train_masks = masks[train_idxs]\n",
    "    test_masks = masks[test_idxs]\n",
    "\n",
    "    return train_imgs, test_imgs, train_masks, test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise:\n",
    "    def __init__(self, mean, std, clip):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.clip = clip\n",
    "\n",
    "    def __call__(self, img):\n",
    "        noise = torch.randn_like(img) * self.std + self.mean\n",
    "        noisy_img = img + noise\n",
    "        if self.clip:\n",
    "            noisy_img = torch.clamp(noisy_img, 0, 1)\n",
    "        return noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_by_index(tensor):\n",
    "    even_indices = tensor[::2]\n",
    "    odd_indices = tensor[1::2]\n",
    "    return torch.cat((even_indices, odd_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_augment_all_single(imgs, masks, p_rot = 0.8, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, p_noise = 0.5, trans=0, N = 10, mode=0):\n",
    "    \n",
    "    L = len(imgs)\n",
    "#     print(L)\n",
    "\n",
    "    VF = torchvision.transforms.RandomVerticalFlip(1)\n",
    "    HF = torchvision.transforms.RandomHorizontalFlip(1)\n",
    "    CJ = torchvision.transforms.ColorJitter(brightness = 0.8, contrast = 0.8)\n",
    "\n",
    "    Imgs = torch.zeros(N*L,256,256)\n",
    "    Masks = torch.zeros(N*L,256,256)\n",
    "\n",
    "    for j in np.arange(N):\n",
    "\n",
    "        for i in np.arange(L):\n",
    "\n",
    "            img = imgs[i]\n",
    "            mask = masks[i]\n",
    "\n",
    "#             if j > 0 and mode != 1:\n",
    "            if mode != 1:\n",
    "            \n",
    "                h_flip_dice = np.random.uniform(0,1)\n",
    "                if h_flip_dice < p_flip:\n",
    "                    img = HF.forward(img)\n",
    "                    mask = HF.forward(mask)\n",
    "\n",
    "                rot_dice = np.random.uniform(0,1)\n",
    "                if rot_dice < p_rot:\n",
    "                    angle = np.random.uniform(0,360)\n",
    "#                     angle = np.random.uniform(0,1)**2*45\n",
    "#                     img = f_rotate_and_zoom(img, angle)\n",
    "#                     mask = f_rotate_and_zoom(mask, angle)\n",
    "                    img = f_rotate(img, angle)\n",
    "                    mask = f_rotate(mask, angle)\n",
    "\n",
    "                v_flip_dice = np.random.uniform(0,1)\n",
    "                if v_flip_dice < p_flip:\n",
    "                    img = VF.forward(img)\n",
    "                    mask = VF.forward(mask)\n",
    "\n",
    "                shear_dice = np.random.uniform(0,1)\n",
    "                if shear_dice < p_shear:\n",
    "                    shr = np.random.uniform(-15,15)\n",
    "\n",
    "                    if rot_dice > p_rot:\n",
    "                        transx = np.random.uniform(-trans,trans)\n",
    "                        transy = np.random.uniform(-trans,trans)\n",
    "                    else:\n",
    "                        transx = 0\n",
    "                        transy = 0\n",
    "\n",
    "                    img = torchvision.transforms.functional.affine(img.unsqueeze(0),angle=0,scale=1,translate=(transx,transy),shear=(shr,shr))\n",
    "                    mask = torchvision.transforms.functional.affine(mask.unsqueeze(0),angle=0,scale=1,translate=(transx,transy),shear=(shr,shr))\n",
    "\n",
    "                    jitter_dice = np.random.uniform(0,1)\n",
    "                    if jitter_dice < p_jitter:\n",
    "                        img = CJ.forward(img.unsqueeze(0)).squeeze()\n",
    "                        \n",
    "                    v_flip_noise = np.random.uniform(0,1)\n",
    "                    if v_flip_noise < p_noise:\n",
    "                        sigma = np.random.uniform(low=0.0, high=0.1)\n",
    "                        GN = GaussianNoise(0, sigma, True)\n",
    "                        img = GN(img)\n",
    "                        img = (img - torch.min(img))/torch.max(img)\n",
    "\n",
    "            Imgs[i*N + j,:,:] = img\n",
    "            Masks[i*N + j,:,:] = mask\n",
    "            \n",
    "    if mode == 1:\n",
    "        Imgs = rearrange_by_index(Imgs)\n",
    "        Masks = rearrange_by_index(Masks)\n",
    "\n",
    "    return Imgs, Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sum_Domain_Adapter(nn.Module):\n",
    "    def __init__(self, num_tasks, dim, args):\n",
    "        super(Sum_Domain_Adapter, self).__init__()\n",
    "        \n",
    "        L1 = int(dim/2)\n",
    "        L2 = dim\n",
    "        L3 = 2*dim\n",
    "#         self.l1 = nn.Linear(num_tasks, L1).to(args.device)\n",
    "#         self.l2 = nn.Linear(L1, L1).to(args.device)\n",
    "#         self.l3 = nn.Linear(L1, L2).to(args.device)\n",
    "        \n",
    "        self.l1 = nn.Linear(num_tasks, L1).to(args.device)\n",
    "        self.l2 = nn.Linear(L1, L2).to(args.device)\n",
    "        self.l3 = nn.Linear(L2, L3).to(args.device)\n",
    "        self.l4 = nn.Linear(L3, L2).to(args.device)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "    def forward(self, feats, one_hot_enc): \n",
    "\n",
    "        a1 = self.l1(one_hot_enc)\n",
    "        a2 = self.ReLU(a1)\n",
    "        a3 = self.l2(a2)\n",
    "        a4 = self.ReLU(a3)\n",
    "\n",
    "#         x1_f = self.l3(a4)\n",
    "        a5 = self.l3(a4)\n",
    "        a6 = self.ReLU(a5)\n",
    "        x1_f = self.l4(a6) + a4\n",
    "\n",
    "        x0_a = feats.flatten(start_dim=2)\n",
    "        x0_b = torch.swapaxes(x0_a,1,2)\n",
    "\n",
    "        sum1 = torch.swapaxes(x1_f + x0_b,1,2)\n",
    "\n",
    "        return sum1.reshape(feats.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head_Domain_Adapter(nn.Module):\n",
    "    def __init__(self, num_tasks, dim, nhead, args):\n",
    "        super(Head_Domain_Adapter, self).__init__()\n",
    "        \n",
    "        self.nhead = nhead\n",
    "        \n",
    "        self.l1 = nn.Linear(num_tasks, int(dim/4)).to(args.device)\n",
    "        self.l2 = nn.Linear(int(dim/4), int(dim/2)).to(args.device)\n",
    "        self.l3 = nn.Linear(int(dim/2), int(dim/2)).to(args.device)\n",
    "        self.l4 = nn.Linear(int(dim/2), dim).to(args.device)\n",
    "\n",
    "        self.mha1 = torch.nn.MultiheadAttention(embed_dim=dim, num_heads=nhead, batch_first=True).to(args.device)\n",
    "\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.SM = nn.Softmax(dim=1)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, feats, one_hot_enc):\n",
    "        \n",
    "        dim = feats.size()[1]\n",
    "        num_embed = feats.size()[-1]*feats.size()[-2]\n",
    "        head_dim = int(dim/self.nhead)\n",
    "        \n",
    "        a1 = self.l1(one_hot_enc)\n",
    "        a2 = self.ReLU(a1)\n",
    "        a3 = self.l2(a2)\n",
    "        a4 = self.ReLU(a3)\n",
    "        a5 = self.l3(a4)\n",
    "        a6 = self.ReLU(a5)\n",
    "        a7 = self.l4(a6)\n",
    "        a8 = a7.reshape(args.batch_size,self.nhead,head_dim)\n",
    "        a9 = self.SM(a8)\n",
    "\n",
    "        # Query, key, and value matrices\n",
    "        q_w, k_w, v_w = torch.split(self.mha1.in_proj_weight, [dim, dim, dim])\n",
    "        q_b, k_b, v_b = torch.split(self.mha1.in_proj_bias, [dim, dim, dim])\n",
    "\n",
    "        q_w = q_w.T\n",
    "        k_w = k_w.T\n",
    "        v_w = v_w.T\n",
    "\n",
    "        x_a = feats.flatten(start_dim=2)\n",
    "        x_b = torch.swapaxes(x_a,1,2)\n",
    "        x_f = f_pos_encoding_additive(x_b,args).squeeze()\n",
    "\n",
    "        x_r = x_f.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "        x_p = a9.unsqueeze(2)*x_r\n",
    "        x_pp = x_p.reshape(x_f.size())\n",
    "\n",
    "        qp = x_pp @ q_w + q_b\n",
    "        kp = x_pp @ k_w + k_b\n",
    "        vp = x_pp @ v_w + v_b\n",
    "\n",
    "        qpp = qp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "        kpp = kp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "        vpp = vp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "\n",
    "        ap = self.SM(qpp @ kpp.transpose(-1, -2) / np.sqrt(head_dim))\n",
    "        pp = ap @ vpp\n",
    "\n",
    "        pp_t = pp.transpose(1, 2).reshape(args.batch_size, num_embed, dim)\n",
    "\n",
    "        op = self.mha1.out_proj(pp_t).transpose(1, 2)\n",
    "\n",
    "        return op.reshape(feats.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f_construct_kernel(N,gamma=1):\n",
    "\n",
    "#     L = np.sqrt(N)\n",
    "#     adj = np.zeros((N,N))\n",
    "\n",
    "#     for i in np.arange(N):\n",
    "#         for j in np.arange(N):\n",
    "# #             adj[i,j] = np.exp(-gamma*(np.sqrt(np.mod(np.abs(i-j),L)**2 + (np.floor(np.abs(i-j)/L))**2)))\n",
    "#             adj[i,j] = (np.sqrt(np.mod(np.abs(i-j),L)**2 + (np.floor(np.abs(i-j)/L))**2))\n",
    "    \n",
    "#     return adj\n",
    "\n",
    "class KernelAttn(nn.Module):\n",
    "    def __init__(self, N, args):\n",
    "        super(KernelAttn, self).__init__()\n",
    "        self.N = N\n",
    "        \n",
    "        # Initialize learnable parameters for four directions\n",
    "        self.weight_left = nn.Parameter(torch.tensor(0.01)).to(args.device)    # Weight for left\n",
    "        self.weight_right = nn.Parameter(torch.tensor(0.01)).to(args.device)   # Weight for right\n",
    "        self.weight_up = nn.Parameter(torch.tensor(0.01)).to(args.device)      # Weight for up\n",
    "        self.weight_down = nn.Parameter(torch.tensor(0.01)).to(args.device)    # Weight for down\n",
    "        \n",
    "        self.M = nn.Parameter(torch.rand(N,N)*0.01).to(args.device) \n",
    "        \n",
    "        self.i = torch.arange(self.N).view(-1, 1).to(args.device)  # Shape (N, 1)\n",
    "        self.j = torch.arange(self.N).view(1, -1).to(args.device)  # Shape (1, N)\n",
    "                              \n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "          # Calculate L\n",
    "\n",
    "    def forward(self):\n",
    "        i = self.i\n",
    "        j = self.j\n",
    "        L = np.sqrt(self.N)\n",
    "        \n",
    "        # Calculate horizontal and vertical distances\n",
    "        h_dist = (torch.sign(i - j)*(torch.abs(i - j) % L)).float() # Horizontal distances (Shape: (N, N))\n",
    "        v_dist = (torch.sign(i - j)*torch.floor(torch.abs(i - j) / L)).float() # Vertical distances (Shape: (N, N))\n",
    "\n",
    "        # Initialize adjacency matrix\n",
    "        adj = torch.zeros((self.N, self.N), dtype=torch.float32).to(args.device) \n",
    "\n",
    "        # Apply weights based on conditions\n",
    "        adj += (h_dist**2 * (h_dist > 0) * (0.001 + self.ReLU(self.weight_right)))  # Right direction\n",
    "        adj += (h_dist**2 * (h_dist < 0) * (0.001 + self.ReLU(self.weight_left)))   # Left direction\n",
    "        adj += (v_dist**2 * (v_dist > 0) * (0.001 + self.ReLU(self.weight_down)))  # Down direction\n",
    "        adj += (v_dist**2 * (v_dist < 0) * (0.001 + self.ReLU(self.weight_up)))     # Up direction\n",
    "        \n",
    "#         adj += h_dist**2 + v_dist**2\n",
    "\n",
    "        return torch.exp(-torch.sqrt(0.001 * adj))*self.Sigmoid(self.M)\n",
    "\n",
    "KA1 = KernelAttn(256, args).to(args.device) \n",
    "adj = KA1().detach().cpu().numpy()\n",
    "plt.imshow(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sparse_MHA(nn.Module):\n",
    "    def __init__(self, dim, nhead, n_embed, args):\n",
    "        super(Sparse_MHA, self).__init__()\n",
    "        \n",
    "        self.nhead = nhead\n",
    "        self.dim = dim\n",
    "        self.n_embed = n_embed\n",
    "        self.head_dim = int(self.dim/self.nhead)\n",
    "        \n",
    "        self.mha1 = torch.nn.MultiheadAttention(embed_dim=dim, num_heads=nhead, batch_first=True)\n",
    "\n",
    "        self.KA1 = KernelAttn(n_embed, args).to(args.device)\n",
    "        self.M = nn.Parameter(torch.rand(n_embed,n_embed)).to(args.device) \n",
    "        \n",
    "        self.Softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, q, k, v):\n",
    "        \n",
    "#         dim = feats.size()[1]\n",
    "\n",
    "        # Query, key, and value matrices\n",
    "        q_w, k_w, v_w = torch.split(self.mha1.in_proj_weight, [self.dim, self.dim, self.dim])\n",
    "        q_b, k_b, v_b = torch.split(self.mha1.in_proj_bias,   [self.dim, self.dim, self.dim])\n",
    "\n",
    "        qp = q @ q_w.T + q_b\n",
    "        kp = k @ k_w.T + k_b\n",
    "        vp = v @ v_w.T + v_b\n",
    "\n",
    "        qpp = qp.reshape(args.batch_size, self.n_embed, self.nhead, self.head_dim).transpose(1, 2)\n",
    "        kpp = kp.reshape(args.batch_size, self.n_embed, self.nhead, self.head_dim).transpose(1, 2)\n",
    "        vpp = vp.reshape(args.batch_size, self.n_embed, self.nhead, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        ap1 = self.Softmax(qpp @ kpp.transpose(-1, -2) / np.sqrt(self.head_dim))\n",
    "        self.ap = ap1 + self.KA1() + self.M\n",
    "#         self.ap = ap1\n",
    "    \n",
    "        pp = self.ap @ vpp\n",
    "\n",
    "        pp_t = pp.transpose(1, 2).reshape(args.batch_size, self.n_embed, self.dim)\n",
    "\n",
    "        op = self.mha1.out_proj(pp_t)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sparse_AE(nn.Module):\n",
    "    def __init__(self, dim, k, args):\n",
    "        super(Sparse_AE, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(dim, k).to(args.device)\n",
    "        self.l2 = nn.Linear(k, dim).to(args.device)\n",
    "\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "    def forward(self, feats):\n",
    "  \n",
    "        a1 = self.l1(feats)\n",
    "        a2 = self.ReLU(a1)\n",
    "        a3 = self.l2(a2)\n",
    "        \n",
    "        return a3\n",
    "\n",
    "#####\n",
    "    \n",
    "class Sparse_AE_bn(nn.Module):\n",
    "    def __init__(self, dim, k1, k2, args):\n",
    "        super(Sparse_AE_bn, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(dim, int(dim/k1)).to(args.device)\n",
    "        self.l2 = nn.Linear(int(dim/k1), int(k2*dim)).to(args.device)\n",
    "        self.l3 = nn.Linear(int(k2*dim), int(dim/k1)).to(args.device)\n",
    "        self.l4 = nn.Linear(int(dim/k1), dim).to(args.device)\n",
    "\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "    def forward(self, feats):\n",
    "  \n",
    "        a1 = self.l1(feats)\n",
    "        a2 = self.ReLU(a1)\n",
    "        a3 = self.l2(a2)\n",
    "        a4 = self.ReLU(a3)\n",
    "        a5 = self.l3(a4)\n",
    "        a6 = self.ReLU(a5)\n",
    "        a7 = self.l4(a6)\n",
    "        \n",
    "        return a7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseTransformerEncoder(nn.Module):\n",
    "    def __init__(self, dim_embed, nhead, n_embed, k1, k2, args):\n",
    "        super(SparseTransformerEncoder, self).__init__()\n",
    "        self.smha = Sparse_MHA(dim_embed, nhead, n_embed, args)\n",
    "        self.layer_norm1 = nn.LayerNorm(dim_embed)\n",
    "        self.SAE = Sparse_AE_bn(dim_embed, k1, k2, args)\n",
    "        self.layer_norm2 = nn.LayerNorm(dim_embed)\n",
    "\n",
    "    def forward(self, q, k, v):\n",
    "        # Multi-head attention\n",
    "        a1 = self.smha(q, k, v)\n",
    "        # Add & Norm\n",
    "        a2 = self.layer_norm1(q + a1)\n",
    "        # Feedforward network\n",
    "        a3 = self.SAE(a2)\n",
    "        # Final Add & Norm\n",
    "        out = self.layer_norm2(a3)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## See https://stackoverflow.com/questions/75189397/getting-the-query-key-and-value-matrices-from-pytorch-with-self-attn-in-proj-we\n",
    "# class Head_Domain_Adapter_v2(nn.Module):\n",
    "#     def __init__(self, num_tasks, dim, nhead, args):\n",
    "#         super(Head_Domain_Adapter_v2, self).__init__()\n",
    "        \n",
    "#         self.nhead = nhead\n",
    "\n",
    "#         self.l1 = nn.Linear(num_tasks, int(dim/4)).to(args.device)\n",
    "#         self.l2 = nn.Linear(int(dim/4), int(dim/2)).to(args.device)\n",
    "#         self.l3 = nn.Linear(int(dim/2), dim).to(args.device)\n",
    "#         self.l4 = nn.Linear(dim, dim*3).to(args.device)\n",
    "\n",
    "#         self.mha1 = torch.nn.MultiheadAttention(embed_dim=dim, num_heads=nhead, batch_first=True).to(args.device)\n",
    "\n",
    "#         self.ReLU = nn.ReLU()\n",
    "#         self.SM = nn.Softmax(dim=1)\n",
    "#         self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#     def forward(self, feats, one_hot_enc):\n",
    "        \n",
    "#         dim = feats.size()[1]\n",
    "#         num_embed = feats.size()[-1]*feats.size()[-2]\n",
    "#         head_dim = int(dim/self.nhead)\n",
    "\n",
    "#         a1 = self.l1(one_hot_enc)\n",
    "#         a2 = self.ReLU(a1)\n",
    "#         a3 = self.l2(a2)\n",
    "#         a4 = self.ReLU(a3)\n",
    "#         a5 = self.l3(a4)\n",
    "#         a6 = self.ReLU(a5)\n",
    "#         a7 = self.l4(a6)\n",
    "# #         a8 = a7.reshape(args.batch_size,self.nhead,head_dim,3)\n",
    "#         a8 = self.Sigmoid(a7).reshape(args.batch_size,self.nhead,head_dim,3)\n",
    "#         a9 = self.SM(a8)\n",
    "#         aq = a9[:,:,:,0]\n",
    "#         ak = a9[:,:,:,1]\n",
    "#         av = a9[:,:,:,2]\n",
    "\n",
    "#         # Query, key, and value matrices\n",
    "#         q_w, k_w, v_w = torch.split(self.mha1.in_proj_weight, [dim, dim, dim])\n",
    "#         q_b, k_b, v_b = torch.split(self.mha1.in_proj_bias, [dim, dim, dim])\n",
    "\n",
    "#         q_w = q_w.T\n",
    "#         k_w = k_w.T\n",
    "#         v_w = v_w.T\n",
    "\n",
    "#         x_a = feats.flatten(start_dim=2)\n",
    "#         x_b = torch.swapaxes(x_a,1,2)\n",
    "#         x_f = f_pos_encoding_additive(x_b,args).squeeze()\n",
    "\n",
    "#         qp = x_f @ q_w + q_b\n",
    "#         kp = x_f @ k_w + k_b\n",
    "#         vp = x_f @ v_w + v_b\n",
    "\n",
    "#         qpp = qp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "#         kpp = kp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "#         vpp = vp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "        \n",
    "#         qpp_a = aq.unsqueeze(2)*qpp\n",
    "#         kpp_a = ak.unsqueeze(2)*kpp\n",
    "#         vpp_a = av.unsqueeze(2)*vpp\n",
    "\n",
    "#         ap = self.SM(qpp_a @ kpp_a.transpose(-1, -2) / np.sqrt(head_dim))\n",
    "#         pp = ap @ vpp_a\n",
    "\n",
    "#         pp_t = pp.transpose(1, 2).reshape(args.batch_size, num_embed, dim)\n",
    "#         op = self.mha1.out_proj(pp_t).transpose(1, 2)\n",
    "\n",
    "#         return op.reshape(feats.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Dot_Product_Domain_Adapter(nn.Module):\n",
    "#     def __init__(self, num_tasks, dim, nhead, args):\n",
    "#         super(Dot_Product_Domain_Adapter, self).__init__()\n",
    "        \n",
    "#         self.l1 = nn.Linear(num_tasks, int(dim/2)).to(args.device)\n",
    "#         self.l2 = nn.Linear(int(dim/2), int(dim/2)).to(args.device)\n",
    "#         self.l3 = nn.Linear(int(dim/2), dim).to(args.device)\n",
    "        \n",
    "#         self.mha1 = torch.nn.MultiheadAttention(embed_dim=dim, num_heads=nhead, batch_first=True).to(args.device)\n",
    "        \n",
    "#         self.ReLU = nn.ReLU()\n",
    "        \n",
    "#     def forward(self, feats, one_hot_enc):\n",
    "        \n",
    "#         a1 = self.l1(one_hot_enc)\n",
    "#         a2 = self.ReLU(a1)\n",
    "#         a3 = self.l2(a2)\n",
    "#         a4 = self.ReLU(a3)\n",
    "#         mask = self.l3(a4)\n",
    "\n",
    "#         # Query, key, and value matrices\n",
    "#         q_w, k_w, v_w = torch.split(self.mha1.in_proj_weight, [dim, dim, dim])\n",
    "#         q_b, k_b, v_b = torch.split(self.mha1.in_proj_bias, [dim, dim, dim])\n",
    "\n",
    "#         q_w = q_w.T\n",
    "#         k_w = k_w.T\n",
    "#         v_w = v_w.T\n",
    "\n",
    "#         x_a = feats.flatten(start_dim=2)\n",
    "#         x_b = torch.swapaxes(x_a,1,2)\n",
    "#         x_f = f_pos_encoding_additive(x_b,args).squeeze()\n",
    "\n",
    "#         qp = mask @ q_w + q_b\n",
    "#         kp = x_f @ k_w + k_b\n",
    "#         vp = x_f @ v_w + v_b\n",
    "\n",
    "#         qpp = qp.reshape(args.batch_size, 1, self.nhead, head_dim).transpose(1, 2)\n",
    "#         kpp = kp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "#         vpp = vp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "        \n",
    "#         ap = self.SM(qpp @ kpp.transpose(-1, -2) / np.sqrt(head_dim))\n",
    "#         pp = ap @ vpp\n",
    "        \n",
    "# #         prod = mask.unsqueeze(2)*pp\n",
    "# #         prod_t = prod.transpose(1, 2).reshape(args.batch_size, num_embed, dim)\n",
    "# #         op = self.mha1.out_proj(prod_t).transpose(1, 2)\n",
    "        \n",
    "#         return out.reshape(feats.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Full_Domain_Adapter(nn.Module):\n",
    "    def __init__(self, num_tasks, dim, nhead, args):\n",
    "        super(Full_Domain_Adapter, self).__init__()\n",
    "        \n",
    "        self.DA_s = Sum_Domain_Adapter(num_tasks, dim, args)\n",
    "#         self.DA_sp = Simple_Domain_Adapter(num_tasks, dim, num_t, args)\n",
    "#         self.DA_p = Prod_Domain_Adapter(num_tasks, dim, args)\n",
    "#         self.DA_dp = Dot_Product_Domain_Adapter(num_tasks, dim, nhead, args)\n",
    "        self.DA_h = Head_Domain_Adapter(num_tasks, dim, nhead, args)\n",
    "        \n",
    "    def forward(self, feats, one_hot_enc):\n",
    "        \n",
    "        a2 = self.DA_h(feats, one_hot_enc)\n",
    "#         a2 = self.DA_s(feats, one_hot_enc)\n",
    "\n",
    "#         a1 = self.DA_s(feats, one_hot_enc)\n",
    "#         a2 = self.DA_h(a1, one_hot_enc)\n",
    "\n",
    "        return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain_Adapter_lin_v1(nn.Module):\n",
    "    def __init__(self, num_tasks, dim, args):\n",
    "        super(Domain_Adapter_lin_v1, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(num_tasks, int(dim/2)).to(args.device)\n",
    "        self.l2 = nn.Linear(int(dim/2), int(dim/2)).to(args.device)\n",
    "        self.l3 = nn.Linear(int(dim/2), dim).to(args.device)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "    def forward(self, feats, one_hot_enc):\n",
    "\n",
    "        a1 = self.l1(one_hot_enc.squeeze())\n",
    "        a2 = self.ReLU(a1)\n",
    "        a3 = self.l2(a2)\n",
    "        a4 = self.ReLU(a3)\n",
    "        mask = self.l3(a4)\n",
    "\n",
    "        return mask*feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Domain_Adapter_lin_v2(nn.Module):\n",
    "    def __init__(self, num_tasks, dim, args):\n",
    "        super(Domain_Adapter_lin_v2, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(num_tasks, int(dim/2)).to(args.device)\n",
    "        self.l2 = nn.Linear(int(dim/2), int(dim/2)).to(args.device)\n",
    "        self.l3 = nn.Linear(int(dim/2), dim).to(args.device)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Sigmoid = Sigmoid()\n",
    "#         self.Tanh = Tanh()\n",
    "        \n",
    "    def forward(self, feats, one_hot_enc):\n",
    "\n",
    "        a1 = self.l1(one_hot_enc.squeeze())\n",
    "        a2 = self.ReLU(a1)\n",
    "        a3 = self.l2(a2)\n",
    "        a4 = self.ReLU(a3)\n",
    "        a5 = self.l3(a4)\n",
    "        mask = self.Sigmoid(a5)\n",
    "\n",
    "        return mask*feats, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_Data = Healthy_Imgs_SVC_aug\n",
    "# Target_Data = Healthy_RealMasks_SVC_aug\n",
    "\n",
    "# enc_base = Enc_base\n",
    "\n",
    "# args.num_batches = int(len(Train_Data)/args.N)\n",
    "\n",
    "# ea = nn.Conv2d(128, 64, kernel_size=3, padding=1).to(args.device) # output: 136x136x256\n",
    "\n",
    "# random_idxs = np.arange(len(Train_Data))\n",
    "# np.random.shuffle(random_idxs)\n",
    "# train_data_shuffle = Train_Data[random_idxs]\n",
    "# target_data_shuffle = Target_Data[random_idxs]\n",
    "\n",
    "# epoch_losses = np.zeros(args.num_batches)\n",
    "\n",
    "# it = 0\n",
    "\n",
    "# in_frames = train_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "# target_frames = target_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "\n",
    "# feats0u, feats1u, feats2u, feats3u_f, feats4u_f, x4_sz = enc_base(in_frames, one_hot_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim0 = 1\n",
    "# dim1 = 32\n",
    "# dim2 = 64\n",
    "# dim3 = 128\n",
    "\n",
    "# a0 = nn.Conv2d(dim0, dim1, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "\n",
    "# a1 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# a2 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# a3 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "\n",
    "# b0 = nn.Conv2d(dim1, dim2, kernel_size=2, stride = 2, padding=0).to(args.device)\n",
    "\n",
    "# c0 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# c1 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# c2 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# c3 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "\n",
    "# d0 = nn.Conv2d(dim2, dim3, kernel_size=2, stride = 2, padding=0).to(args.device)\n",
    "\n",
    "# e0 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# e1 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# e2 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# e3 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "\n",
    "# l0 = nn.Linear(args.num_tasks, int(dim1/2)).to(args.device)\n",
    "# l1 = nn.Linear(int(dim1/2), dim1).to(args.device)\n",
    "# l2 = nn.Linear(dim1, dim1).to(args.device)\n",
    "# l3 = nn.Linear(dim1, dim2).to(args.device)\n",
    "# l4 = nn.Linear(dim2, dim2).to(args.device)\n",
    "# l5 = nn.Linear(dim2, dim3).to(args.device)\n",
    "# l6 = nn.Linear(dim3, dim3).to(args.device)\n",
    "\n",
    "# ReLU = nn.ReLU()\n",
    "\n",
    "# q0 = l0(one_hot_enc.squeeze())   \n",
    "# q01 = ReLU(q0)                 \n",
    "# q1 = l1(q01)\n",
    "# q2 = ReLU(q1)\n",
    "# q3 = l2(q2)\n",
    "# u1 = q3\n",
    "# q4 = l3(q2)\n",
    "# q5 = ReLU(q4)\n",
    "# q6 = l4(q5)\n",
    "# u2 = q6\n",
    "# q7 = l5(q5)                 \n",
    "# q8 = ReLU(q7)\n",
    "# q9 = l6(q8)    \n",
    "# u3 = q9\n",
    "\n",
    "# x1 = a0(in_frames.squeeze().unsqueeze(1))\n",
    "# x2 = ReLU(x1)\n",
    "# x2u = x2 + u1.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "# x3 = a1(x2u)\n",
    "# x4 = ReLU(x3) + x2u\n",
    "# x5 = a2(x4)\n",
    "# x6 = ReLU(x5) + x4\n",
    "# x7 = a3(x6)\n",
    "# x8 = ReLU(x7) + x6\n",
    "# # x8u = x8 + u1.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "# x9 = self.b0(x8)\n",
    "# x10 = self.ReLU(x9) + x9\n",
    "# x10u = x10 + u2.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "# x11 = self.c0(x10u)\n",
    "# x12 = self.ReLU(x11) + x10u\n",
    "# x13 = self.c1(x12)\n",
    "# x14 = self.ReLU(x13) + x12\n",
    "# x15 = self.c2(x14)\n",
    "# x16 = self.ReLU(x15) + x14\n",
    "# x17 = self.c3(x16)\n",
    "# x18 = self.ReLU(x17) + x16\n",
    "# # x18u = x18 + u2.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "# x19 = self.d0(x18)\n",
    "# x20 = self.ReLU(x19) + x19\n",
    "# x20u = x20 + u3.unsqueeze(2).unsqueeze(3)\n",
    "\n",
    "# x21 = self.e0(x20u)\n",
    "# x22 = self.ReLU(x21) + x20u\n",
    "# x23 = self.e1(x22)\n",
    "# x24 = self.ReLU(x23) + x22\n",
    "# x25 = self.e2(x24)\n",
    "# x26 = self.ReLU(x25) + x24\n",
    "# x27 = self.e3(x26)\n",
    "# out = self.ReLU(x27) + x26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = feats2u\n",
    "# dim = feats.size()[1]\n",
    "# num_t = feats.size()[2]*feats.size()[3]\n",
    "# dim_tot = dim*num_t\n",
    "# num_tasks = 2\n",
    "\n",
    "# head_dim = int(dim/nhead)\n",
    "\n",
    "# l1 = nn.Linear(num_tasks, int(dim/4)).to(args.device)\n",
    "# l2 = nn.Linear(int(dim/4), int(dim/2)).to(args.device)\n",
    "# l3 = nn.Linear(int(dim/2), int(dim/2)).to(args.device)\n",
    "# l4 = nn.Linear(int(dim/2), dim).to(args.device)\n",
    "\n",
    "# mha1 = torch.nn.MultiheadAttention(embed_dim=dim, num_heads=nhead, batch_first=True).to(args.device)\n",
    "\n",
    "# ReLU = nn.ReLU()\n",
    "# SM = nn.Softmax(dim=1)\n",
    "\n",
    "# num_embed = feats.size()[-1]*feats.size()[-2]\n",
    "# head_dim = int(dim/nhead)\n",
    "\n",
    "# a1 = l1(one_hot_enc)\n",
    "# a2 = ReLU(a1)\n",
    "# a3 = l2(a2)\n",
    "# a4 = ReLU(a3)\n",
    "# a5 = l3(a4)\n",
    "# a6 = ReLU(a5)\n",
    "# a7 = l4(a6)\n",
    "# a8 = a7.reshape(args.batch_size,nhead,head_dim)\n",
    "# a9 = SM(a8)\n",
    "\n",
    "# # Query, key, and value matrices\n",
    "# q_w, k_w, v_w = torch.split(mha1.in_proj_weight, [dim, dim, dim])\n",
    "# q_b, k_b, v_b = torch.split(mha1.in_proj_bias, [dim, dim, dim])\n",
    "\n",
    "# q_w = q_w.T\n",
    "# k_w = k_w.T\n",
    "# v_w = v_w.T\n",
    "\n",
    "# x_a = feats.flatten(start_dim=2)\n",
    "# x_b = torch.swapaxes(x_a,1,2)\n",
    "# x_f = f_pos_encoding_additive(x_b,args).squeeze()\n",
    "\n",
    "# x_r = x_f.reshape(args.batch_size, num_embed, nhead, head_dim).transpose(1, 2)\n",
    "# x_p = a9.unsqueeze(2)*x_r\n",
    "# x_pp = x_p.reshape(x_f.size())\n",
    "\n",
    "# qp = x_pp @ q_w + q_b\n",
    "# kp = x_pp @ k_w + k_b\n",
    "# vp = x_pp @ v_w + v_b\n",
    "\n",
    "# qpp = qp.reshape(args.batch_size, num_embed, nhead, head_dim).transpose(1, 2)\n",
    "# kpp = kp.reshape(args.batch_size, num_embed, nhead, head_dim).transpose(1, 2)\n",
    "# vpp = vp.reshape(args.batch_size, num_embed, nhead, head_dim).transpose(1, 2)\n",
    "\n",
    "# qpp_a = aq.unsqueeze(2)*qpp\n",
    "# kpp_a = ak.unsqueeze(2)*kpp\n",
    "# vpp_a = av.unsqueeze(2)*vpp\n",
    "\n",
    "# ap = SM(qpp @ kpp.transpose(-1, -2) / np.sqrt(head_dim))\n",
    "# pp = ap @ vpp\n",
    "\n",
    "# pp_t = pp.transpose(1, 2).reshape(args.batch_size, num_embed, dim)\n",
    "\n",
    "# op = mha1.out_proj(pp_t).transpose(1, 2)\n",
    "\n",
    "# op.reshape(feats.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN_Enc(torch.nn.Module):\n",
    "\n",
    "#     # Initialize the network and specify input/output dimensions:\n",
    "#     def __init__(self, args, dim0, dim1, dim2, dim3):\n",
    "#         super(CNN_Enc, self).__init__()\n",
    "    \n",
    "#         self.a0 = nn.Conv2d(dim0, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.a1 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.a2 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.a3 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "#         self.b0 = nn.Conv2d(dim1, dim2, kernel_size=2, stride = 2, padding=0)\n",
    "\n",
    "#         self.c0 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.c1 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.c2 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.c3 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "#         self.d0 = nn.Conv2d(dim2, dim3, kernel_size=2, stride = 2, padding=0)\n",
    "\n",
    "#         self.e0 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.e1 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.e2 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.e3 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "#         self.ReLU = nn.ReLU()\n",
    "\n",
    "#      # Build the network:\n",
    "#     def forward(self, in_frames):\n",
    "\n",
    "#         x1 = self.a0(in_frames)\n",
    "#         x2 = self.ReLU(x1)\n",
    "#         x3 = self.a1(x2)\n",
    "#         x4 = self.ReLU(x3) + x2\n",
    "#         x5 = self.a2(x4)\n",
    "#         x6 = self.ReLU(x5) + x4\n",
    "#         x7 = self.a3(x6)\n",
    "#         x8 = self.ReLU(x7) + x6\n",
    "\n",
    "#         x9 = self.b0(x8)\n",
    "#         x10 = self.ReLU(x9) + x9\n",
    "\n",
    "#         x11 = self.c0(x10)\n",
    "#         x12 = self.ReLU(x11) + x10\n",
    "#         x13 = self.c1(x12)\n",
    "#         x14 = self.ReLU(x13) + x12\n",
    "#         x15 = self.c2(x14)\n",
    "#         x16 = self.ReLU(x15) + x14\n",
    "#         x17 = self.c3(x16)\n",
    "#         x18 = self.ReLU(x17) + x16\n",
    "\n",
    "#         x19 = self.d0(x18)\n",
    "#         x20 = self.ReLU(x19) + x19\n",
    "\n",
    "#         x21 = self.e0(x20)\n",
    "#         x22 = self.ReLU(x21) + x20\n",
    "#         x23 = self.e1(x22)\n",
    "#         x24 = self.ReLU(x23) + x22\n",
    "#         x25 = self.e2(x24)\n",
    "#         x26 = self.ReLU(x25) + x24\n",
    "#         x27 = self.e3(x26)\n",
    "#         out = self.ReLU(x27) + x26\n",
    "\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Enc(torch.nn.Module):\n",
    "\n",
    "    # Initialize the network and specify input/output dimensions:\n",
    "    def __init__(self, args, dim0, dim1, dim2, dim3, mode):\n",
    "        super(CNN_Enc, self).__init__()\n",
    "        \n",
    "        self.mode = mode\n",
    "    \n",
    "        self.a0 = nn.Conv2d(dim0, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "        self.a1 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "        self.a2 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "        self.a3 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "        self.b0 = nn.Conv2d(dim1, dim2, kernel_size=2, stride = 2, padding=0)\n",
    "\n",
    "        self.c0 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "        self.c1 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "        self.c2 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "        self.c3 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "        self.d0 = nn.Conv2d(dim2, dim3, kernel_size=2, stride = 2, padding=0)\n",
    "\n",
    "        self.e0 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "        self.e1 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "        self.e2 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "        self.e3 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "        \n",
    "        if self.mode == 'base':\n",
    "            self.l0 = nn.Linear(args.num_tasks, int(dim1/2)).to(args.device)\n",
    "            self.l1 = nn.Linear(int(dim1/2), dim1).to(args.device)\n",
    "            self.l2 = nn.Linear(dim1, dim1).to(args.device)\n",
    "            self.l3 = nn.Linear(dim1, dim2).to(args.device)\n",
    "            self.l4 = nn.Linear(dim2, dim2).to(args.device)\n",
    "            self.l5 = nn.Linear(dim2, dim3).to(args.device)\n",
    "            self.l6 = nn.Linear(dim3, dim3).to(args.device)\n",
    "\n",
    "        self.ReLU = nn.ReLU()\n",
    "\n",
    "     # Build the network:\n",
    "    def forward(self, in_frames, one_hot_enc):\n",
    "            \n",
    "        if self.mode == 'base':\n",
    "            q0 = self.l0(one_hot_enc.squeeze())   \n",
    "            q01 = self.ReLU(q0)                 \n",
    "            q1 = self.l1(q01)\n",
    "            q2 = self.ReLU(q1)\n",
    "            q3 = self.l2(q2)\n",
    "            u1 = q3.unsqueeze(2).unsqueeze(3)   \n",
    "            q4 = self.l3(q2)\n",
    "            q5 = self.ReLU(q4)\n",
    "            q6 = self.l4(q5)\n",
    "            u2 = q6.unsqueeze(2).unsqueeze(3)   \n",
    "            q7 = self.l5(q5)                 \n",
    "            q8 = self.ReLU(q7)\n",
    "            q9 = self.l6(q8)    \n",
    "            u3 = q9.unsqueeze(2).unsqueeze(3)   \n",
    "        else:\n",
    "            u1 = u2 = u3 = 0\n",
    "\n",
    "        x1 = self.a0(in_frames)\n",
    "        x2 = self.ReLU(x1)\n",
    "        x2u = x2 + u1              \n",
    "        \n",
    "        x3 = self.a1(x2u)\n",
    "        x4 = self.ReLU(x3) + x2u\n",
    "        x5 = self.a2(x4)\n",
    "        x6 = self.ReLU(x5) + x4\n",
    "        x7 = self.a3(x6)\n",
    "        x8 = self.ReLU(x7) + x6\n",
    "\n",
    "        x9 = self.b0(x8)\n",
    "        x10 = self.ReLU(x9) + x9\n",
    "        x10u = x10 + u2               \n",
    "\n",
    "        x11 = self.c0(x10u)\n",
    "        x12 = self.ReLU(x11) + x10u\n",
    "        x13 = self.c1(x12)\n",
    "        x14 = self.ReLU(x13) + x12\n",
    "        x15 = self.c2(x14)\n",
    "        x16 = self.ReLU(x15) + x14\n",
    "        x17 = self.c3(x16)\n",
    "        x18 = self.ReLU(x17) + x16\n",
    "\n",
    "        x19 = self.d0(x18)\n",
    "        x20 = self.ReLU(x19) + x19\n",
    "        x20u = x20 + u3           \n",
    "\n",
    "        x21 = self.e0(x20u)\n",
    "        x22 = self.ReLU(x21) + x20u\n",
    "        x23 = self.e1(x22)\n",
    "        x24 = self.ReLU(x23) + x22\n",
    "        x25 = self.e2(x24)\n",
    "        x26 = self.ReLU(x25) + x24\n",
    "        x27 = self.e3(x26)\n",
    "        out = self.ReLU(x27) + x26\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN_Dec(torch.nn.Module):\n",
    "\n",
    "#     # Initialize the network and specify input/output dimensions:\n",
    "#     def __init__(self, args, dim3, dim2, dim1, dim0):\n",
    "#         super(CNN_Dec, self).__init__()\n",
    "#         self.e0 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.e1 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.e2 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.e3 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "#         self.d0 = nn.ConvTranspose2d(dim3, dim2, kernel_size=2, stride=2)\n",
    "\n",
    "#         self.c0 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.c1 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.c2 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.c3 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "#         self.b0 = nn.ConvTranspose2d(dim2, dim1, kernel_size=2, stride=2)\n",
    "\n",
    "#         self.a0 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.a1 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.a2 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "#         self.a3 = nn.Conv2d(dim1, dim0, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "#         self.ReLU = nn.ReLU()\n",
    "#         self.Sigmoid = nn.Sigmoid()\n",
    "    \n",
    "#     # Build the network:\n",
    "#     def forward(self, x0):\n",
    "\n",
    "#         x1 = self.e0(x0)\n",
    "#         x2 = self.ReLU(x1) + x0\n",
    "#         x3 = self.e1(x2)\n",
    "#         x4 = self.ReLU(x3) + x2\n",
    "#         x5 = self.e2(x4)\n",
    "#         x6 = self.ReLU(x5) + x4\n",
    "#         x7 = self.e3(x6)\n",
    "#         x8 = self.ReLU(x7) + x6\n",
    "\n",
    "#         x9 = self.d0(x8)\n",
    "#         x10 = self.ReLU(x9) + x9\n",
    "\n",
    "#         x11 = self.c0(x10)\n",
    "#         x12 = self.ReLU(x11) + x10\n",
    "#         x13 = self.c1(x12)\n",
    "#         x14 = self.ReLU(x13) + x12\n",
    "#         x15 = self.c2(x14)\n",
    "#         x16 = self.ReLU(x15) + x14\n",
    "#         x17 = self.c3(x16)\n",
    "#         x18 = self.ReLU(x17) + x16\n",
    "\n",
    "#         x19 = self.b0(x18)\n",
    "#         x20 = self.ReLU(x19) + x19\n",
    "\n",
    "#         x21 = self.a0(x20)\n",
    "#         x22 = self.ReLU(x21) + x20\n",
    "#         x23 = self.a1(x22)\n",
    "#         x24 = self.ReLU(x23) + x22\n",
    "#         x25 = self.a2(x24)\n",
    "#         x26 = self.ReLU(x25) + x24\n",
    "#         x27 = self.a3(x26)\n",
    "#         out = self.Sigmoid(x27)\n",
    "\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Dec(torch.nn.Module):\n",
    "\n",
    "    # Initialize the network and specify input/output dimensions:\n",
    "    def __init__(self, args, dim3, dim2, dim1, dim0, mode):\n",
    "        super(CNN_Dec, self).__init__()\n",
    "        \n",
    "        self.mode = mode\n",
    "        \n",
    "        self.e0 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "        self.e1 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "        self.e2 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "        self.e3 = nn.Conv2d(dim3, dim3, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "        self.d0 = nn.ConvTranspose2d(dim3, dim2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.c0 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "        self.c1 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "        self.c2 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "        self.c3 = nn.Conv2d(dim2, dim2, kernel_size=3, stride = 1, padding=1)\n",
    "\n",
    "        self.b0 = nn.ConvTranspose2d(dim2, dim1, kernel_size=2, stride=2)\n",
    "\n",
    "        self.a0 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "        self.a1 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "        self.a2 = nn.Conv2d(dim1, dim1, kernel_size=3, stride = 1, padding=1)\n",
    "        self.a3 = nn.Conv2d(dim1, dim0, kernel_size=3, stride = 1, padding=1)\n",
    "        \n",
    "        if self.mode == 'base':\n",
    "            self.l0 = nn.Linear(args.num_tasks, int(dim1/2)).to(args.device)\n",
    "            self.l1 = nn.Linear(int(dim1/2), dim1).to(args.device)\n",
    "            self.l2 = nn.Linear(dim1, dim1).to(args.device)\n",
    "            self.l3 = nn.Linear(dim1, dim2).to(args.device)\n",
    "            self.l4 = nn.Linear(dim2, dim2).to(args.device)\n",
    "            self.l5 = nn.Linear(dim2, dim3).to(args.device)\n",
    "            self.l6 = nn.Linear(dim3, dim3).to(args.device)\n",
    "\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    # Build the network:\n",
    "    def forward(self, x0, one_hot_enc):\n",
    "        \n",
    "        if self.mode == 'base':\n",
    "            q0 = self.l0(one_hot_enc.squeeze())   \n",
    "            q01 = self.ReLU(q0)                 \n",
    "            q1 = self.l1(q01)\n",
    "            q2 = self.ReLU(q1)\n",
    "            q3 = self.l2(q2)\n",
    "            u1 = q3.unsqueeze(2).unsqueeze(3)\n",
    "            q4 = self.l3(q2)\n",
    "            q5 = self.ReLU(q4)\n",
    "            q6 = self.l4(q5)\n",
    "            u2 = q6.unsqueeze(2).unsqueeze(3)\n",
    "            q7 = self.l5(q5)                 \n",
    "            q8 = self.ReLU(q7)\n",
    "            q9 = self.l6(q8)    \n",
    "            u3 = q9.unsqueeze(2).unsqueeze(3)\n",
    "        elif self.mode == 'aux':\n",
    "            u1 = u2 = u3 = 0\n",
    "\n",
    "        x1 = self.e0(x0)\n",
    "        x2 = self.ReLU(x1) + x0\n",
    "        x2u = x2 + u3\n",
    "        \n",
    "        x3 = self.e1(x2u)\n",
    "        x4 = self.ReLU(x3) + x2u\n",
    "        x5 = self.e2(x4)\n",
    "        x6 = self.ReLU(x5) + x4\n",
    "        x7 = self.e3(x6)\n",
    "        x8 = self.ReLU(x7) + x6\n",
    "\n",
    "        x9 = self.d0(x8)\n",
    "        x10 = self.ReLU(x9) + x9\n",
    "        x10u = x10 + u2\n",
    "\n",
    "        x11 = self.c0(x10u)\n",
    "        x12 = self.ReLU(x11) + x10u\n",
    "        x13 = self.c1(x12)\n",
    "        x14 = self.ReLU(x13) + x12\n",
    "        x15 = self.c2(x14)\n",
    "        x16 = self.ReLU(x15) + x14\n",
    "        x17 = self.c3(x16)\n",
    "        x18 = self.ReLU(x17) + x16\n",
    "\n",
    "        x19 = self.b0(x18)\n",
    "        x20 = self.ReLU(x19) + x19\n",
    "        x20u = x20 + u1\n",
    "\n",
    "        x21 = self.a0(x20u)\n",
    "        x22 = self.ReLU(x21) + x20u\n",
    "        x23 = self.a1(x22)\n",
    "        x24 = self.ReLU(x23) + x22\n",
    "        x25 = self.a2(x24)\n",
    "        x26 = self.ReLU(x25) + x24\n",
    "        x27 = self.a3(x26)\n",
    "        out = self.Sigmoid(x27)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compress_Im_feats(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Compress img feats\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the network and specify input/output dimensions:\n",
    "    def __init__(self, args, dim1, dim2, dim3):\n",
    "        super(Compress_Im_feats, self).__init__()\n",
    "    \n",
    "        self.h_enc1 = nn.Linear(dim1, dim2).to(args.device)\n",
    "        self.h_enc2 = nn.Linear(dim2, dim2).to(args.device)\n",
    "        self.h_enc3 = nn.Linear(dim2, dim2).to(args.device)\n",
    "        self.h_enc4 = nn.Linear(dim2, dim3).to(args.device)\n",
    "\n",
    "        self.ReLU = nn.ReLU()\n",
    "\n",
    "     # Build the network:\n",
    "    def forward(self, in_feats):\n",
    "\n",
    "        a3 = self.h_enc1(in_feats)\n",
    "        a4 = self.ReLU(a3)\n",
    "        a5 = self.h_enc2(a4)\n",
    "        a6 = self.ReLU(a5)\n",
    "        a7 = self.h_enc3(a6)\n",
    "        a8 = self.ReLU(a7)\n",
    "        out = self.h_enc4(a8)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compress_Im_feats_v2(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Compress img feats\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the network and specify input/output dimensions:\n",
    "    def __init__(self, args, dim1, dim2, dim3):\n",
    "        super(Compress_Im_feats_v2, self).__init__()\n",
    "    \n",
    "        self.h_enc1 = nn.Linear(dim1, dim2).to(args.device)\n",
    "        self.h_enc2 = nn.Linear(dim2, dim2).to(args.device)\n",
    "        self.h_enc3 = nn.Linear(dim2, dim2).to(args.device)\n",
    "        self.h_enc4 = nn.Linear(dim2, dim3).to(args.device)\n",
    "        \n",
    "        self.l01 = nn.Linear(args.num_tasks, int(dim2/2)).to(args.device)\n",
    "        self.l02 = nn.Linear(int(dim2/2), dim2).to(args.device)\n",
    "        self.l1 = nn.Linear(dim2, dim2).to(args.device)\n",
    "        self.l2 = nn.Linear(dim2, dim2).to(args.device)\n",
    "        self.l3 = nn.Linear(dim2, dim2).to(args.device)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "\n",
    "     # Build the network:\n",
    "    def forward(self, in_feats, one_hot_enc):\n",
    "                \n",
    "        u1 = self.l01(one_hot_enc.squeeze())\n",
    "        u2 = self.ReLU(u1)\n",
    "        u3 = self.l02(u2)\n",
    "        u4 = self.ReLU(u3)\n",
    "        \n",
    "        u5 = self.l1(u4)\n",
    "        u6 = self.Sigmoid(u5)\n",
    "        u7 = self.l2(u4)\n",
    "        u8 = self.Sigmoid(u7)\n",
    "        u9 = self.l3(u4)\n",
    "        u10 = self.Sigmoid(u9)\n",
    "\n",
    "        a3 = self.h_enc1(in_feats)\n",
    "        a4 = self.ReLU(a3)\n",
    "        a4u = u6*a4                                     \n",
    "        a5 = self.h_enc2(a4u)                       \n",
    "        a6 = self.ReLU(a5)\n",
    "        a6u = u8*a6                    \n",
    "        a7 = self.h_enc3(a6u)                  \n",
    "        a8 = self.ReLU(a7)\n",
    "        a8u = u10*a8                       \n",
    "        out = self.h_enc4(a8u)\n",
    "        \n",
    "#         u_mean = (torch.mean(u6) + torch.mean(u8) + torch.mean(u10))/3\n",
    "#         U = torch.cat((u6, u8, u10),dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Head_Domain_Adapter(nn.Module):\n",
    "#     def __init__(self, num_tasks, dim, nhead, args):\n",
    "#         super(Head_Domain_Adapter, self).__init__()\n",
    "        \n",
    "#         self.nhead = nhead\n",
    "        \n",
    "#         self.mha1 = torch.nn.MultiheadAttention(embed_dim=dim, num_heads=nhead, batch_first=True).to(args.device)\n",
    "\n",
    "#         self.ReLU = nn.ReLU()\n",
    "#         self.SM = nn.Softmax(dim=1)\n",
    "#         self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#     def forward(self, feats):\n",
    "        \n",
    "#         dim = feats.size()[1]\n",
    "#         num_embed = feats.size()[-1]*feats.size()[-2]\n",
    "#         head_dim = int(dim/self.nhead)\n",
    "        \n",
    "\n",
    "#         # Query, key, and value matrices\n",
    "#         q_w, k_w, v_w = torch.split(self.mha1.in_proj_weight, [dim, dim, dim])\n",
    "#         q_b, k_b, v_b = torch.split(self.mha1.in_proj_bias, [dim, dim, dim])\n",
    "\n",
    "#         q_w = q_w.T\n",
    "#         k_w = k_w.T\n",
    "#         v_w = v_w.T\n",
    "\n",
    "#         x_a = feats.flatten(start_dim=2)\n",
    "#         x_b = torch.swapaxes(x_a,1,2)\n",
    "#         x_f = f_pos_encoding_additive(x_b,args).squeeze()\n",
    "\n",
    "#         x_r = x_f.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "#         x_p = a9.unsqueeze(2)*x_r\n",
    "#         x_pp = x_p.reshape(x_f.size())\n",
    "\n",
    "#         qp = x_pp @ q_w + q_b\n",
    "#         kp = x_pp @ k_w + k_b\n",
    "#         vp = x_pp @ v_w + v_b\n",
    "\n",
    "#         qpp = qp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "#         kpp = kp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "#         vpp = vp.reshape(args.batch_size, num_embed, self.nhead, head_dim).transpose(1, 2)\n",
    "\n",
    "#         ap = self.SM(qpp @ kpp.transpose(-1, -2) / np.sqrt(head_dim))\n",
    "#         pp = ap @ vpp\n",
    "\n",
    "#         pp_t = pp.transpose(1, 2).reshape(args.batch_size, num_embed, dim)\n",
    "\n",
    "#         op = self.mha1.out_proj(pp_t).transpose(1, 2)\n",
    "\n",
    "#         return op.reshape(feats.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_Enc_base(nn.Module):\n",
    "    def __init__(self, nhead, args):\n",
    "        super(Unet_Enc_base, self).__init__()\n",
    "\n",
    "        self.Enc1 = CNN_Enc(args, 1, 32, 64, 128,mode='none')\n",
    "    \n",
    "        self.ea0 = nn.Conv2d(args.d_attn0, args.d_attn1, kernel_size=4, stride=4, padding=0)\n",
    "        self.ea1 = nn.Conv2d(args.d_attn1, args.d_attn1, kernel_size=3, stride = 1, padding=1)\n",
    "        self.ea2 = nn.Conv2d(args.d_attn1, args.d_attn1, kernel_size=3, stride = 1, padding=1)\n",
    "        self.ea3 = nn.Conv2d(args.d_attn1, args.d_attn1, kernel_size=3, stride = 1, padding=1)\n",
    "        \n",
    "        self.l1 = nn.Linear(64**2,8**2).to(args.device)\n",
    "        self.te0u_1 = SparseTransformerEncoder(args.d_attn0, nhead, 8**2, 4, 50, args)\n",
    "        self.te0u_2 = SparseTransformerEncoder(args.d_attn0, nhead, 8**2, 4, 50, args)\n",
    "        self.l2 = nn.Linear(8**2,64**2).to(args.device)\n",
    "        \n",
    "        self.e0 = nn.Conv2d(args.d_attn1, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 136x136x256\n",
    "        self.e0a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 136x136x256\n",
    "        self.e0b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 136x136x256\n",
    "        self.e0c = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 136x136x256\n",
    "\n",
    "        self.pool0 = nn.MaxPool2d(kernel_size=4, stride=4).to(args.device) # output: 68x68x256\n",
    "\n",
    "        self.te1u_1 = SparseTransformerEncoder(args.d_attn1, nhead, 16**2, 8, 50, args)\n",
    "        self.te1u_2 = SparseTransformerEncoder(args.d_attn1, nhead, 16**2, 8, 50, args)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2).to(args.device) # output: 68x68x256\n",
    "\n",
    "        self.te2u_1 = SparseTransformerEncoder(args.d_attn2, nhead, 4**2, 16, 50, args)\n",
    "        self.te2u_2 = SparseTransformerEncoder(args.d_attn2, nhead, 4**2, 16, 50, args)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2).to(args.device) # output: 68x68x256\n",
    "\n",
    "#         self.e1 = nn.Conv2d(args.d_attn2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.e1a = nn.Conv2d(args.d_attn2*2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.e1b = nn.Conv2d(args.d_attn2*2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.e2 = nn.Conv2d(args.d_attn2*2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.e2a = nn.Conv2d(args.d_attn2*2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.e2b = nn.Conv2d(args.d_attn2*2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        \n",
    "#         self.C1 = Compress_Im_feats_v2(args, dim1=args.d_attn2*2, dim2 = 256, dim3 = 256).to(args.device)\n",
    "    \n",
    "#         self.DA1 = Sum_Domain_Adapter(args.num_tasks, args.d_attn1, args)\n",
    "#         self.DA2 = Sum_Domain_Adapter(args.num_tasks, args.d_attn2, args)\n",
    "\n",
    "#         self.DA_l3 = Domain_Adapter_lin_v1(args.num_tasks, args.d_attn2*2, args)\n",
    "    \n",
    "        self.e1 = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1)  # reduced output channels\n",
    "        self.e1a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1) # same\n",
    "        self.e1b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1) # same\n",
    "        self.e2 = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1)  # reduced back to args.d_attn2\n",
    "        self.e2a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1) # same\n",
    "        self.e2b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1) # same\n",
    "        \n",
    "        self.C1 = Compress_Im_feats_v2(args, dim1=args.d_attn2, dim2 = args.d_attn1, dim3 = args.d_attn1).to(args.device)\n",
    "        \n",
    "        self.DA1 = Sum_Domain_Adapter(args.num_tasks, args.d_attn1, args)\n",
    "        self.DA2 = Sum_Domain_Adapter(args.num_tasks, args.d_attn2, args)\n",
    "\n",
    "        self.DA_l3 = Domain_Adapter_lin_v1(args.num_tasks, args.d_attn2, args)\n",
    "    \n",
    "        self.ReLU = nn.ReLU()\n",
    "    \n",
    "    def forward(self, in_frames, one_hot_enc):\n",
    "\n",
    "        feats0u = self.Enc1(in_frames.squeeze().unsqueeze(1), one_hot_enc)\n",
    "\n",
    "        feats0u_a = feats0u.flatten(start_dim=2)\n",
    "        feats0u_a = torch.swapaxes(feats0u_a,1,2)\n",
    "        feats0u_a = f_pos_encoding_additive(feats0u_a,args).squeeze()\n",
    "        x1 = torch.swapaxes(self.l1(torch.swapaxes(feats0u_a,1,2)),1,2)\n",
    "        q1 = self.te0u_1(x1, x1, x1)\n",
    "        q2 = self.te0u_2(q1, q1, q1)\n",
    "        q3 = torch.swapaxes(q2,1,2)\n",
    "        q4 = self.l2(q3)\n",
    "        feats0u = feats0u + q4.reshape(feats0u.size())\n",
    "\n",
    "        feats1u = self.ea0(feats0u)        \n",
    "        feats1ua = self.ea1(feats1u)\n",
    "        feats1ub = self.ReLU(feats1ua) + feats1u\n",
    "        feats1uc = self.ea2(feats1ub)\n",
    "        feats1ud = self.ReLU(feats1uc) + feats1ub\n",
    "        feats1ue = self.ea3(feats1ud)  \n",
    "        feats1uf = self.ReLU(feats1ue) + feats1ud\n",
    "        \n",
    "        feats1u = self.DA1(feats1uf,one_hot_enc)\n",
    "\n",
    "        feats1u_a = feats1u.flatten(start_dim=2)\n",
    "        feats1u_a = torch.swapaxes(feats1u_a,1,2)\n",
    "\n",
    "        x1 = f_pos_encoding_additive(feats1u_a,args).squeeze()\n",
    "        q1 = self.te1u_1(x1, x1, x1)\n",
    "        q2 = self.te1u_2(q1, q1, q1)\n",
    "        q2 = torch.swapaxes(q2,1,2)\n",
    "        \n",
    "        feats1u = feats1u + q2.reshape(feats1u.size())\n",
    "\n",
    "        feats2u = self.pool0(self.e0(feats1u))\n",
    "        feats2ua = self.e0a(feats2u)\n",
    "        feats2ub = self.ReLU(feats2ua) + feats2u\n",
    "        feats2uc = self.e0b(feats2ub)\n",
    "        feats2ud = self.ReLU(feats2uc) + feats2ub\n",
    "        feats2ue = self.e0c(feats2ud)\n",
    "        feats2uf = self.ReLU(feats2ue) + feats2ud\n",
    "        \n",
    "        feats2u = self.DA2(feats2uf,one_hot_enc)\n",
    "\n",
    "        feats2u_a = feats2u.flatten(start_dim=2)\n",
    "        feats2u_a = torch.swapaxes(feats2u_a,1,2)\n",
    "\n",
    "        x1 = f_pos_encoding_additive(feats2u_a,args).squeeze()\n",
    "        q1 = self.te2u_1(x1, x1, x1)\n",
    "        q2 = self.te2u_2(q1,q1,q1)\n",
    "        q2 = torch.swapaxes(q2,1,2)\n",
    "        feats2u = feats2u + q2.reshape(feats2u.size())\n",
    "\n",
    "        x1 = self.e1(feats2u)\n",
    "        x2 = self.pool1(x1)\n",
    "        x2a = self.e1a(x2)\n",
    "        x2b = self.ReLU(x2a) + x2\n",
    "        \n",
    "        x3 = self.e2(x2b)\n",
    "        x4 = self.pool2(x3)\n",
    "        x4a = self.e2a(x4)\n",
    "        x4b = self.ReLU(x4a) + x4\n",
    "        x4c = self.e2b(x4b)\n",
    "        x4d = self.ReLU(x4c) + x4b\n",
    "\n",
    "        feats3u_f = x4d.flatten(start_dim=1)\n",
    "        \n",
    "        feats3u_f = self.DA_l3(feats3u_f, one_hot_enc)\n",
    "#         feats4u_f = self.C1(feats3u_f)\n",
    "        feats4u_f = self.C1(feats3u_f, one_hot_enc)\n",
    "        \n",
    "#         return feats0u, feats1u, feats2u, feats3u_f, feats4u_f, x4.size()\n",
    "        return feats0u, feats1u, feats2u, feats3u_f, feats4u_f, x4.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_Dec_v3(nn.Module):\n",
    "    def __init__(self, nhead, args):\n",
    "        super(Unet_Dec_v3, self).__init__()\n",
    "        \n",
    "# #         self.D1 = Compress_Im_feats(args, dim1=256, dim2 = 256, dim3 = args.d_attn2*2).to(args.device)\n",
    "#         self.D1 = Compress_Im_feats_v2(args, dim1=args.d_attn1, dim2 = args.d_attn1, dim3 = args.d_attn2*2).to(args.device)\n",
    "\n",
    "#         self.m1 = nn.ConvTranspose2d(args.d_attn2*2, args.d_attn2*2, kernel_size=2, stride=2).to(args.device)\n",
    "#         self.q0a = nn.Conv2d(args.d_attn2*2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.q0b = nn.Conv2d(args.d_attn2*2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.m2 = nn.ConvTranspose2d(args.d_attn2*2, args.d_attn2, kernel_size=2, stride=2).to(args.device)\n",
    "#         self.q1a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.q1b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "\n",
    "# #         self.ed0 = nn.Conv2d(args.d_attn0*args.fac, args.d_attn0, kernel_size=1, padding=0).to(args.device)\n",
    "#         self.ed1 = nn.Conv2d(args.d_attn1*args.fac, args.d_attn1, kernel_size=1, padding=0).to(args.device)\n",
    "#         self.ed2 = nn.Conv2d(args.d_attn2*args.fac, args.d_attn2, kernel_size=1, padding=0).to(args.device)\n",
    "#         self.d3 = nn.Linear(args.d_attn2*2*args.fac, args.d_attn2*2).to(args.device)\n",
    "\n",
    "        self.D1 = Compress_Im_feats_v2(args, dim1=args.d_attn1, dim2 = args.d_attn1, dim3 = args.d_attn2).to(args.device)\n",
    "\n",
    "        self.m1 = nn.ConvTranspose2d(args.d_attn2, args.d_attn2, kernel_size=2, stride=2).to(args.device)\n",
    "        self.q0a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        self.q0b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        self.m2 = nn.ConvTranspose2d(args.d_attn2, args.d_attn2, kernel_size=2, stride=2).to(args.device)\n",
    "        self.q1a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        self.q1b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        \n",
    "        #         self.ed0 = nn.Conv2d(args.d_attn0*args.fac, args.d_attn0, kernel_size=1, padding=0).to(args.device)\n",
    "        self.ed1 = nn.Conv2d(args.d_attn1*args.fac, args.d_attn1, kernel_size=1, padding=0).to(args.device)\n",
    "        self.ed2 = nn.Conv2d(args.d_attn2*args.fac, args.d_attn2, kernel_size=1, padding=0).to(args.device)\n",
    "        self.d3 = nn.Linear(args.d_attn2*args.fac, args.d_attn2).to(args.device)\n",
    "        \n",
    "#         self.te2d_1 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn2, nhead=nhead, dim_feedforward=args.d_attn2, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "#         self.te2d_2 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn2, nhead=nhead, dim_feedforward=args.d_attn2, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "        self.te2d_1 = SparseTransformerEncoder(args.d_attn2, nhead, 4**2, 16, 50, args)\n",
    "        self.te2d_2 = SparseTransformerEncoder(args.d_attn2, nhead, 4**2, 16, 50, args)\n",
    "        \n",
    "#         self.mha2 = torch.nn.MultiheadAttention(embed_dim=args.d_attn2, num_heads=nhead, batch_first=True).to(args.device)\n",
    "        self.mha2 = SparseTransformerEncoder(args.d_attn2, nhead, 4**2, 16, 50, args)\n",
    "\n",
    "        self.m3 = nn.ConvTranspose2d(args.d_attn2, args.d_attn1, kernel_size=4, stride=4).to(args.device)\n",
    "        \n",
    "#         self.te1d_1 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn1, nhead=nhead, dim_feedforward=args.d_attn2, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "#         self.te1d_2 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn1, nhead=nhead, dim_feedforward=args.d_attn2, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "        self.te1d_1 = SparseTransformerEncoder(args.d_attn1, nhead, 16**2, 8, 50, args)\n",
    "        self.te1d_2 = SparseTransformerEncoder(args.d_attn1, nhead, 16**2, 8, 50, args)\n",
    "        \n",
    "#         self.mha1 = torch.nn.MultiheadAttention(embed_dim=args.d_attn1, num_heads=nhead, batch_first=True).to(args.device)\n",
    "        self.mha1 = SparseTransformerEncoder(args.d_attn1, nhead, 16**2, 8, 50, args)\n",
    "        \n",
    "        self.l1 = nn.Linear(64**2,8**2).to(args.device)\n",
    "        self.te0d_1 = SparseTransformerEncoder(args.d_attn0, nhead, 8**2, 4, 50, args)\n",
    "        self.te0d_2 = SparseTransformerEncoder(args.d_attn0, nhead, 8**2, 4, 50, args)\n",
    "        self.l2 = nn.Linear(8**2,64**2).to(args.device)\n",
    "        \n",
    "        self.mha0 = SparseTransformerEncoder(args.d_attn0, nhead, 8**2, 4, 50, args)\n",
    "        \n",
    "#         self.ea = nn.Conv2d(args.d_attn0, args.d_attn1, kernel_size=4, stride=4, padding=0).to(args.device) # output: 136x136x256\n",
    "        self.m4 = nn.ConvTranspose2d(args.d_attn1, args.d_attn0*args.fac, kernel_size=4, stride=4).to(args.device)\n",
    "        \n",
    "#         self.Dec1 = VPTRDec(1, feat_dim = args.d_attn1, n_downsampling = 4, out_layer = 'Sigmoid').to(args.device)\n",
    "        self.Dec1 = CNN_Dec(args, args.d_attn0*args.fac, 64, 32, 1,'aux').to(args.device)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    "    \n",
    "    def forward(self, feats0u, feats1u, feats2u, feats3u_f, feats4u_f, sz4, mode):\n",
    "\n",
    "        feats4_n = feats4u_f*(mode>=0)\n",
    "        feats3_n = feats3u_f*(mode>=1)\n",
    "        feats2_n = feats2u*(mode>=2)\n",
    "        feats1_n = feats1u*(mode>=3)\n",
    "        feats0_n = feats0u*(mode>=3)\n",
    "        \n",
    "        feats3_n = self.d3(feats3_n)\n",
    "        feats2_n = self.ed2(feats2_n)\n",
    "        feats1_n = self.ed1(feats1_n)\n",
    "#         feats0_n = self.ed0(feats0_n)\n",
    "        sz = [args.batch_size, int(sz4[1]/args.fac), 1, 1]\n",
    "        \n",
    "#         feats3d_f = self.D1(feats4_n)\n",
    "        place_holder = torch.ones(args.batch_size,args.num_tasks).to(args.device)\n",
    "        feats3d_f = self.D1(feats4_n, place_holder)\n",
    "    \n",
    "        feats3d_f = feats3_n + feats3d_f\n",
    "\n",
    "        feats3d = torch.unflatten(feats3d_f,dim=1,sizes = sz[1:])\n",
    "\n",
    "        y2 = self.m1(feats3d)\n",
    "        y2a = self.q0a(y2)\n",
    "        y2b = self.ReLU(y2a) + y2\n",
    "        \n",
    "        y4 = self.m2(y2b)\n",
    "        y4a = self.q1a(y4)\n",
    "        feats2d = self.ReLU(y4a) + y4\n",
    "        \n",
    "        feats2d_a = feats2d.squeeze().flatten(start_dim=2)\n",
    "        feats2d_a = torch.swapaxes(feats2d_a,1,2)\n",
    "        x1 = f_pos_encoding_additive(feats2d_a,args).squeeze()\n",
    "        a1 = self.te2d_1(x1, x1, x1)\n",
    "        a2 = self.te2d_2(a1, a1, a1)\n",
    "        a3 = torch.swapaxes(a2,1,2)\n",
    "        feats2d = feats2d + a3.reshape(feats2_n.size())\n",
    "\n",
    "        feats2n_a = feats2_n.flatten(start_dim=2)\n",
    "        feats2n_a = torch.swapaxes(feats2n_a,1,2)\n",
    "        feats2n_a = f_pos_encoding_additive(feats2n_a,args).squeeze()\n",
    "\n",
    "        attn_output2 = self.mha2(a2, feats2n_a, feats2n_a)\n",
    "        attn_output2 = torch.swapaxes(attn_output2,1,2)\n",
    "        feats2d = feats2d + attn_output2.reshape(feats2d.size())\n",
    "\n",
    "        feats1d = self.m3(feats2_n + feats2d)\n",
    "\n",
    "        feats1d_a = feats1d.squeeze().flatten(start_dim=2)\n",
    "        feats1d_a = torch.swapaxes(feats1d_a,1,2)\n",
    "        x1 = f_pos_encoding_additive(feats1d_a,args).squeeze()\n",
    "        b1 = self.te1d_1(x1, x1, x1)\n",
    "        b2 = self.te1d_2(b1, b1, b1)\n",
    "        b3 = torch.swapaxes(b2,1,2)\n",
    "        feats1d = feats1d + b3.reshape(feats1d.size())\n",
    "\n",
    "        feats1n_a = feats1_n.flatten(start_dim=2)\n",
    "        feats1n_a = torch.swapaxes(feats1n_a,1,2)\n",
    "        feats1n_a = f_pos_encoding_additive(feats1n_a,args).squeeze()\n",
    "        attn_output1 = self.mha1(b2, feats1n_a, feats1n_a)\n",
    "        feats1d = feats1d + attn_output1.reshape(feats1d.size())\n",
    "        \n",
    "        feats0d = self.m4(feats1_n + feats1d)\n",
    "        \n",
    "        feats0d_a = feats0d.flatten(start_dim=2)\n",
    "        feats0d_a = torch.swapaxes(feats0d_a,1,2)\n",
    "        feats0d_a = f_pos_encoding_additive(feats0d_a,args).squeeze()\n",
    "        x1 = torch.swapaxes(self.l1(torch.swapaxes(feats0d_a,1,2)),1,2)\n",
    "        q1 = self.te0d_1(x1, x1, x1)\n",
    "        q2 = self.te0d_2(q1, q1, q1)\n",
    "        \n",
    "        feats0n_a = feats0_n.flatten(start_dim=2)\n",
    "        feats0n_a = torch.swapaxes(feats0n_a,1,2)\n",
    "        feats0n_a = f_pos_encoding_additive(feats0n_a,args).squeeze()\n",
    "        xa = torch.swapaxes(self.l1(torch.swapaxes(feats0n_a,1,2)),1,2)\n",
    "        q3 = q2 + self.mha0(q2, q2, xa)\n",
    "        q4 = self.l2(torch.swapaxes(q3,1,2))\n",
    "        feats0d = feats0d + q4.reshape(feats0d.size())\n",
    "\n",
    "        out_frames = self.Dec1(feats0d + feats0_n, []).unsqueeze(1)\n",
    "        \n",
    "        return out_frames, feats0_n, feats1_n, feats2_n, feats3_n, feats4_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_base\n",
    "class Unet_Dec_base(nn.Module):\n",
    "    def __init__(self, nhead, args):\n",
    "        super(Unet_Dec_base, self).__init__()\n",
    "        \n",
    "# #         self.D1 = Compress_Im_feats(args, dim1=256, dim2 = 256, dim3 = args.d_attn2*2).to(args.device)\n",
    "#         self.D1 = Compress_Im_feats_v2(args, dim1=256, dim2 = 256, dim3 = args.d_attn2*2).to(args.device)\n",
    "\n",
    "#         self.m1 = nn.ConvTranspose2d(args.d_attn2*2, args.d_attn2*2, kernel_size=2, stride=2).to(args.device)\n",
    "#         self.q0a = nn.Conv2d(args.d_attn2*2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.q0b = nn.Conv2d(args.d_attn2*2, args.d_attn2*2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.m2 = nn.ConvTranspose2d(args.d_attn2*2, args.d_attn2, kernel_size=2, stride=2).to(args.device)\n",
    "#         self.q1a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "#         self.q1b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        \n",
    "        self.D1 = Compress_Im_feats_v2(args, dim1=args.d_attn1, dim2 = args.d_attn1, dim3 = args.d_attn2).to(args.device)\n",
    "        self.m1 = nn.ConvTranspose2d(args.d_attn2, args.d_attn2, kernel_size=2, stride=2).to(args.device)\n",
    "        self.q0a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        self.q0b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        self.m2 = nn.ConvTranspose2d(args.d_attn2, args.d_attn2, kernel_size=2, stride=2).to(args.device)\n",
    "        self.q1a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        self.q1b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        \n",
    "#         self.te2d_1 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn2, nhead=nhead, dim_feedforward=args.d_attn2, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "#         self.te2d_2 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn2, nhead=nhead, dim_feedforward=args.d_attn2, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "        self.te2d_1 = SparseTransformerEncoder(args.d_attn2, nhead, 4**2, 16, 50, args)\n",
    "        self.te2d_2 = SparseTransformerEncoder(args.d_attn2, nhead, 4**2, 16, 50, args)\n",
    "        \n",
    "#         self.mha2 = torch.nn.MultiheadAttention(embed_dim=args.d_attn2, num_heads=nhead, batch_first=True).to(args.device)\n",
    "        self.mha2 = SparseTransformerEncoder(args.d_attn2, nhead, 4**2, 16, 50, args)\n",
    "\n",
    "        self.m3 = nn.ConvTranspose2d(args.d_attn2, args.d_attn1, kernel_size=4, stride=4).to(args.device)\n",
    "        self.q2a = nn.Conv2d(args.d_attn1, args.d_attn1, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "        self.q2b = nn.Conv2d(args.d_attn1, args.d_attn1, kernel_size=3, padding=1).to(args.device) # output: 138x138x256\n",
    "\n",
    "#         self.te1d_1 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn1, nhead=nhead, dim_feedforward=args.d_attn2, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "#         self.te1d_2 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn1, nhead=nhead, dim_feedforward=args.d_attn2, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "        self.te1d_1 = SparseTransformerEncoder(args.d_attn1, nhead, 16**2, 8, 50, args)\n",
    "        self.te1d_2 = SparseTransformerEncoder(args.d_attn1, nhead, 16**2, 8, 50, args)\n",
    "        \n",
    "#         self.mha1 = torch.nn.MultiheadAttention(embed_dim=args.d_attn1, num_heads=nhead, batch_first=True).to(args.device)\n",
    "        self.mha1 = SparseTransformerEncoder(args.d_attn1, nhead, 16**2, 8, 50, args)\n",
    "        \n",
    "        self.m4 = nn.ConvTranspose2d(args.d_attn1, args.d_attn0, kernel_size=4, stride=4).to(args.device)\n",
    "\n",
    "        self.l1 = nn.Linear(64**2,8**2).to(args.device)\n",
    "        self.te0d_1 = SparseTransformerEncoder(args.d_attn0, nhead, 8**2, 4, 50, args)\n",
    "        self.te0d_2 = SparseTransformerEncoder(args.d_attn0, nhead, 8**2, 4, 50, args)\n",
    "        self.l2 = nn.Linear(8**2,64**2).to(args.device)\n",
    "        \n",
    "        self.mha0 = SparseTransformerEncoder(args.d_attn0, nhead, 8**2, 4, 50, args)\n",
    "        \n",
    "#         self.Dec1 = VPTRDec(1, feat_dim = args.d_attn0, n_downsampling = 2, out_layer = 'Sigmoid').to(args.device)\n",
    "        self.Dec1 = CNN_Dec(args, 128, 64, 32, 1,'base').to(args.device)\n",
    "\n",
    "#         self.DA0u = Sum_Domain_Adapter(args.num_tasks, args.d_attn0, args)\n",
    "        self.DA1u = Sum_Domain_Adapter(args.num_tasks, args.d_attn1, args)\n",
    "        self.DA2u = Sum_Domain_Adapter(args.num_tasks, args.d_attn2, args)\n",
    "#         self.DA0d = Sum_Domain_Adapter(args.num_tasks, args.d_attn0, args)\n",
    "        self.DA1d = Sum_Domain_Adapter(args.num_tasks, args.d_attn1, args)\n",
    "        self.DA2d = Sum_Domain_Adapter(args.num_tasks, args.d_attn2, args)\n",
    "#         self.DA0u = Full_Domain_Adapter(args.num_tasks, args.d_attn0, nhead, args)\n",
    "#         self.DA1u = Full_Domain_Adapter(args.num_tasks, args.d_attn1, nhead, args)\n",
    "#         self.DA2u = Full_Domain_Adapter(args.num_tasks, args.d_attn2, nhead, args)\n",
    "#         self.DA0d = Full_Domain_Adapter(args.num_tasks, args.d_attn0, nhead, args)\n",
    "#         self.DA1d = Full_Domain_Adapter(args.num_tasks, args.d_attn1, nhead, args)\n",
    "#         self.DA2d = Full_Domain_Adapter(args.num_tasks, args.d_attn2, nhead, args)\n",
    "\n",
    "#         self.DA_l3u = Domain_Adapter_lin_v1(args.num_tasks, 1024, args)\n",
    "#         self.DA_l4u = Domain_Adapter_lin_v1(args.num_tasks, 256, args)   \n",
    "#         self.DA_l3d = Domain_Adapter_lin_v1(args.num_tasks, 1024, args)\n",
    "        self.DA_l3u = Domain_Adapter_lin_v1(args.num_tasks, args.d_attn2, args)\n",
    "        self.DA_l4u = Domain_Adapter_lin_v1(args.num_tasks, args.d_attn1, args)   \n",
    "        self.DA_l3d = Domain_Adapter_lin_v1(args.num_tasks, args.d_attn2, args)\n",
    "        \n",
    "#         self.SAE1 = Sparse_AE(args.d_attn1,8,50,args)\n",
    "#         self.SAE2 = Sparse_AE(args.d_attn2,16,50,args)\n",
    "#         self.SAE3 = Sparse_AE(args.d_attn1,8,50,args)\n",
    "#         self.SAE4 = Sparse_AE(args.d_attn2,16,50,args)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "    def forward(self, feats0u, feats1u, feats2u, feats3u_f, feats4u_f, x4_sz, one_hot_enc, mode):\n",
    "        \n",
    "        feats4_n = feats4u_f*(mode>=0)\n",
    "        feats3_n = feats3u_f*(mode>=1)\n",
    "        feats2_n = feats2u*(mode>=2)\n",
    "        feats1_n = feats1u*(mode>=3)\n",
    "        feats0_n = feats0u*(mode>=4)\n",
    "        \n",
    "        feats4_n = self.DA_l4u(feats4_n,one_hot_enc)\n",
    "        feats3_n = self.DA_l3u(feats3_n, one_hot_enc)\n",
    "        feats2_n = self.DA2u(feats2_n,one_hot_enc)\n",
    "        feats1_n = self.DA1u(feats1_n,one_hot_enc)\n",
    "#         feats0_n = self.DA0u(feats0_n,one_hot_enc)\n",
    "\n",
    "#         feats3d_f = self.D1(feats4_n)\n",
    "        feats3d_f = self.D1(feats4_n, one_hot_enc)\n",
    "        \n",
    "        feats3d_f = self.DA_l3d(feats3d_f, one_hot_enc)\n",
    "\n",
    "        feats3d_f = feats3_n + feats3d_f\n",
    "\n",
    "        feats3d = torch.unflatten(feats3d_f,dim=1,sizes = x4_sz[1:])\n",
    "\n",
    "        y2 = self.m1(feats3d)\n",
    "        y2a = self.q0a(y2)\n",
    "        y2b = self.ReLU(y2a) + y2\n",
    "        y2c = self.q0b(y2b)\n",
    "        y2d = self.ReLU(y2c) + y2b\n",
    "        \n",
    "        y4 = self.m2(y2d)\n",
    "        y4a = self.q1a(y4)\n",
    "        y4b = self.ReLU(y4a) + y4\n",
    "        y4c = self.q1b(y4b)\n",
    "        feats2d = self.ReLU(y4c) + y4b\n",
    "        \n",
    "        feats2d = self.DA2d(feats2d,one_hot_enc)\n",
    "\n",
    "        feats2d_a = feats2d.squeeze().flatten(start_dim=2)\n",
    "        feats2d_a = torch.swapaxes(feats2d_a,1,2)\n",
    "        x1 = f_pos_encoding_additive(feats2d_a,args).squeeze()\n",
    "        a1 = self.te2d_1(x1, x1, x1)\n",
    "        a2 = self.te2d_2(a1, a1, a1)\n",
    "        a3 = torch.swapaxes(a2,1,2)\n",
    "        feats2d = feats2d + a3.reshape(feats2u.size())\n",
    "\n",
    "        feats2n_a = feats2_n.flatten(start_dim=2)\n",
    "        feats2n_a = torch.swapaxes(feats2n_a,1,2)\n",
    "        feats2n_a = f_pos_encoding_additive(feats2n_a,args).squeeze()\n",
    "\n",
    "        at_2 = self.mha2(a2, feats2n_a, feats2n_a)\n",
    "        at_2 = torch.swapaxes(at_2,1,2)\n",
    "        feats2d = feats2d + at_2.reshape(feats2d.size())\n",
    "\n",
    "        feats1d = self.m3(feats2_n + feats2d)\n",
    "        za = self.q2a(feats1d)\n",
    "        zb = self.ReLU(za) + feats1d\n",
    "        zc = self.q2b(zb)\n",
    "        feats1d = self.ReLU(zc) + zb\n",
    "        \n",
    "        feats1d = self.DA1d(feats1d,one_hot_enc)\n",
    "\n",
    "        feats1d_a = feats1d.squeeze().flatten(start_dim=2)\n",
    "        feats1d_a = torch.swapaxes(feats1d_a,1,2)\n",
    "        x1 = f_pos_encoding_additive(feats1d_a,args).squeeze()\n",
    "        b1 = self.te1d_1(x1, x1, x1)\n",
    "        b2 = self.te1d_2(b1, b1, b1)\n",
    "        b3 = torch.swapaxes(b2,1,2)\n",
    "        feats1d = feats1d + b3.reshape(feats1d.size())\n",
    "\n",
    "        feats1n_a = feats1_n.flatten(start_dim=2)\n",
    "        feats1n_a = torch.swapaxes(feats1n_a,1,2)\n",
    "        feats1n_a = f_pos_encoding_additive(feats1n_a,args).squeeze()\n",
    "        at_1 = self.mha1(b2, feats1n_a, feats1n_a)\n",
    "        feats1d = feats1d + at_1.reshape(feats1d.size())\n",
    "\n",
    "        feats0d = self.m4(feats1_n + feats1d)\n",
    "        \n",
    "        feats0d_a = feats0d.flatten(start_dim=2)\n",
    "        feats0d_a = torch.swapaxes(feats0d_a,1,2)\n",
    "        feats0d_a = f_pos_encoding_additive(feats0d_a,args).squeeze()\n",
    "        x1 = torch.swapaxes(self.l1(torch.swapaxes(feats0d_a,1,2)),1,2)\n",
    "        q1 = self.te0d_1(x1, x1, x1)\n",
    "        q2 = self.te0d_2(q1, q1, q1)\n",
    "        \n",
    "        feats0n_a = feats0_n.flatten(start_dim=2)\n",
    "        feats0n_a = torch.swapaxes(feats0n_a,1,2)\n",
    "        feats0n_a = f_pos_encoding_additive(feats0n_a,args).squeeze()\n",
    "        xa = torch.swapaxes(self.l1(torch.swapaxes(feats0n_a,1,2)),1,2)\n",
    "        q3 = q2 + self.mha0(q2, q2, xa)\n",
    "        q4 = self.l2(torch.swapaxes(q3,1,2))\n",
    "        feats0d = feats0d + q4.reshape(feats0d.size())\n",
    "        \n",
    "        out_frames = self.Dec1(feats0_n + feats0d, one_hot_enc).unsqueeze(1)\n",
    "        \n",
    "        return out_frames, feats0_n, feats1_n, feats2_n, feats3_n, feats4_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_Net_F(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(U_Net_F, self).__init__()\n",
    "        \n",
    "        self.E1 = Unet_Enc(args)\n",
    "        self.D1 = Unet_Dec(args)\n",
    "        \n",
    "    def forward(self, in_frames):\n",
    "        feats1u, feats2u, feats4u_f, feats5_f, x4_sz = self.E1(in_frames)\n",
    "        out_frames, feats1n, feats2n, feats4n, feats5n = self.D1(feats1u, feats2u, feats4u_f, feats5_f, x4_sz)\n",
    "        \n",
    "        return out_frames, feats1n, feats2n, feats4n, feats5n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dice_loss:\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return self.forward(y_true, y_pred)\n",
    "    \n",
    "    def dsc(self, y_true, y_pred):\n",
    "        smooth = 1.\n",
    "        y_true_f = torch.flatten(y_true)\n",
    "        y_pred_f = torch.flatten(y_pred)\n",
    "        mask = y_true_f * y_pred_f\n",
    "        intersection = torch.sum(mask)\n",
    "        score = (2. * intersection + smooth) / (torch.sum(y_true_f) + torch.sum(y_pred_f) + smooth)\n",
    "        return score\n",
    "    \n",
    "    def forward(self, y_true, y_pred):\n",
    "        return (1 - self.dsc(y_true, y_pred)) + nn.functional.binary_cross_entropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_pos_encoding_additive(features,args):\n",
    "    pos = (torch.arange(features.size()[-1])/features.size()[-1]).to(args.device)\n",
    "    return features + pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_iter_AE(Enc, Dec, optimizer, loss, loss2, in_frames, target_frames, one_hot_enc, args, train_flag = True, w_p = 1):\n",
    "\n",
    "#     for i in range(len(in_frames)):\n",
    "#         frame = in_frames[i].detach().cpu().numpy().squeeze()\n",
    "#         plt.imshow(frame)\n",
    "#         plt.show()\n",
    "    \n",
    "    optimizer.zero_grad() # Zero out gradients\n",
    "\n",
    "#     feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = Enc(in_frames)\n",
    "    feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = Enc(in_frames, one_hot_enc)\n",
    "    \n",
    "#     rec_frames_0, _, _, _, _, _ = Dec(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz,mode=0)\n",
    "#     rec_frames_1, _, _, _, _, _ = Dec(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz,mode=1)\n",
    "#     rec_frames_2, _, _, _, _, _ = Dec(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz,mode=2)\n",
    "#     rec_frames_3, _, _, _, _, _ = Dec(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz,mode=3)\n",
    "    rec_frames_4, _, _, _, _, _ = Dec(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=4)\n",
    "\n",
    "    #     loss_i = loss(rec_frames, in_masks)\n",
    "#     loss_i = dice_loss(rec_frames, in_frames)\n",
    "\n",
    "#     loss_0 = loss(rec_frames_0, target_frames)\n",
    "#     loss_1 = loss(rec_frames_1, target_frames)\n",
    "#     loss_2 = loss(rec_frames_2, target_frames)\n",
    "#     loss_3 = loss(rec_frames_3, target_frames)\n",
    "    loss_4 = loss(rec_frames_4, target_frames)\n",
    "    \n",
    "#     loss_i = loss_0/8 + loss_1/4 + loss_2/2 + loss_3/1.5 + loss_4\n",
    "    loss_i = loss_4\n",
    "\n",
    "#     noise_mode = 0\n",
    "#     if noise_mode == 1:\n",
    "#         w_p = 0.1\n",
    "#         penalty = loss2(feats1_n.flatten(start_dim=1),torch.zeros_like(feats1_n.flatten(start_dim=1)))\n",
    "#         penalty += loss2(feats2_n.flatten(start_dim=1),torch.zeros_like(feats2_n.flatten(start_dim=1)))\n",
    "#         penalty += loss2(feats4_n,torch.zeros_like(feats4_n))\n",
    "#         penalty += loss2(feats5_n,torch.zeros_like(feats5_n))\n",
    "#         loss_i += w_p*penalty\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "    lambda0 = 1\n",
    "    lambda1 = 1/2\n",
    "    lambda2 = 1/4\n",
    "#     lambda3 = 1/8\n",
    "    \n",
    "    p1 = f_L1(Enc.te0u_1.parameters()) + f_L1(Enc.te0u_2.parameters())\n",
    "    p2 = f_L1(Enc.te1u_1.parameters()) + f_L1(Enc.te1u_2.parameters())\n",
    "    p3 = f_L1(Enc.te2u_1.parameters()) + f_L1(Enc.te2u_2.parameters())\n",
    "    p4 = f_L1(Dec.te0d_1.parameters()) + f_L1(Dec.te0d_2.parameters()) + f_L1(Dec.mha0.parameters())\n",
    "    p5 = f_L1(Dec.te1d_1.parameters()) + f_L1(Dec.te1d_2.parameters()) + f_L1(Dec.mha1.parameters()) \n",
    "    p6 = f_L1(Dec.te2d_1.parameters()) + f_L1(Dec.te2d_2.parameters()) + f_L1(Dec.mha2.parameters())\n",
    "#     p7 = f_L1(Enc.parameters()) + f_L1(Dec.parameters())\n",
    "    \n",
    "    penalty = lambda0*(p1+p4) + lambda1*(p2+p5) + lambda2*(p3+p6)\n",
    "    loss_i += penalty\n",
    "\n",
    "    loss_i.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(params_list, 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_epoch_AE(Train_Data, Target_Data, Enc, Dec, one_hot_enc, optimizer, loss, loss2, params_list, args):\n",
    "    \n",
    "    random_idxs = np.arange(len(Train_Data))\n",
    "    np.random.shuffle(random_idxs)\n",
    "    train_data_shuffle = Train_Data[random_idxs]\n",
    "    target_data_shuffle = Target_Data[random_idxs]\n",
    "\n",
    "    epoch_losses = np.zeros(args.num_batches)\n",
    "\n",
    "    for it in range(args.num_batches):\n",
    "\n",
    "        in_frames = train_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "        target_frames = target_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "\n",
    "        epoch_losses[it] = single_iter_AE(Enc, Dec, optimizer, loss, loss2, in_frames, target_frames, one_hot_enc, params_list, args)\n",
    "        \n",
    "    return epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def single_iter_AE(enc_base, dec_base, optimizer, loss, loss2, in_frames, target_frames, one_hot_enc, args, train_flag = True, w_p = 1):\n",
    "\n",
    "#     optimizer.zero_grad() # Zero out gradients\n",
    "\n",
    "#     feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = enc_base(in_frames, one_hot_enc)\n",
    "    \n",
    "# #     rec_frames_base_0, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=0)\n",
    "# #     rec_frames_base_1, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=1)\n",
    "# #     rec_frames_base_2, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=2)\n",
    "# #     rec_frames_base_3, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=3)\n",
    "#     rec_frames_base_4, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=4)\n",
    "\n",
    "# #     loss_base_target_0 = loss(rec_frames_base_0, target_frames)\n",
    "# #     loss_base_target_1 = loss(rec_frames_base_1, target_frames)\n",
    "# #     loss_base_target_2 = loss(rec_frames_base_2, target_frames)\n",
    "# #     loss_base_target_3 = loss(rec_frames_base_3, target_frames)\n",
    "#     loss_base_target_4 = loss(rec_frames_base_4, target_frames)\n",
    "# #     loss_base_target = loss_base_target_0/12 + loss_base_target_1/8 + loss_base_target_2/4 + loss_base_target_3/2 + loss_base_target_4\n",
    "#     loss_base_target = loss_base_target_4\n",
    "\n",
    "#     loss_i = loss_base_target\n",
    "    \n",
    "#     loss_i.backward()\n",
    "# #     params_list = list(Enc_base.parameters()) + list(Dec_base.parameters())\n",
    "#     torch.nn.utils.clip_grad_norm_(params_list, 1)\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     return loss_i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def single_epoch_AE(Train_Data, Target_Data, enc_base, dec_base, one_hot_enc, optimizer, loss, loss2, args):\n",
    "    \n",
    "#     random_idxs = np.arange(len(Train_Data))\n",
    "#     np.random.shuffle(random_idxs)\n",
    "    \n",
    "#     num_batches = int(len(Train_Data)/args.batch_size)\n",
    "    \n",
    "#     train_data_shuffle = Train_Data[random_idxs]\n",
    "#     target_data_shuffle = Target_Data[random_idxs]\n",
    "    \n",
    "#     epoch_losses = np.zeros(num_batches)\n",
    "#     for it in np.arange(num_batches):\n",
    "\n",
    "#         in_frames = train_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "#         target_frames = target_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "\n",
    "#         epoch_losses[it] = single_iter_AE(enc_base, dec_base, optimizer, loss, loss2, in_frames, target_frames, one_hot_enc, args)\n",
    "        \n",
    "#     return epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_iter_FAZ(enc_base, dec_base, dec_aux, optimizer, loss, loss2, in_frames, target_frames, one_hot_enc, args, params_list, train_flag = True, w_p = 1):\n",
    "\n",
    "    optimizer.zero_grad() # Zero out gradients\n",
    "\n",
    "    feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = enc_base(in_frames, one_hot_enc)\n",
    "    \n",
    "#     rec_frames_base, feats1n_base, feats2n_base, feats4n_base, feats5n_base = dec_base(feats0u, feats1u, feats2u, feats4u_f, feats5_f, x4_sz, one_hot_enc)\n",
    "#     rec_frames_aux, feats1n_aux, feats2n_aux, feats4n_aux, feats5n_aux      = dec_aux(feats0u, feats1u, feats2u, feats4u_f, feats5_f, x4_sz)\n",
    "\n",
    "    rec_frames_base_0, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=0)\n",
    "    rec_frames_base_1, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=1)\n",
    "    rec_frames_base_2, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=2)\n",
    "    rec_frames_base_3, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=3)\n",
    "    rec_frames_base_4, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=4)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "    rec_frames_aux_0, _, _, _, _, _ = dec_aux(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, mode=0)\n",
    "    rec_frames_aux_1, _, _, _, _, _ = dec_aux(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, mode=1)\n",
    "    rec_frames_aux_2, _, _, _, _, _ = dec_aux(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, mode=2)\n",
    "    rec_frames_aux_3, _, _, _, _, _ = dec_aux(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, mode=3)\n",
    "    rec_frames_aux_4, _, _, _, _, _ = dec_aux(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, mode=4)\n",
    "\n",
    "#     loss_base_target_0 = loss(rec_frames_base_0, target_frames)\n",
    "#     loss_base_target_1 = loss(rec_frames_base_1, target_frames)\n",
    "#     loss_base_target_2 = loss(rec_frames_base_2, target_frames)\n",
    "#     loss_base_target_3 = loss(rec_frames_base_3, target_frames)\n",
    "    loss_base_target_4 = loss(rec_frames_base_4, target_frames)\n",
    "#     loss_base_target = loss_base_target_0/12 + loss_base_target_1/8 + loss_base_target_2/4 + loss_base_target_3/2 + loss_base_target_4\n",
    "    loss_base_target = loss_base_target_4\n",
    "    \n",
    "#     loss_aux_target_0 = loss(rec_frames_aux_0, target_frames)\n",
    "#     loss_aux_target_1 = loss(rec_frames_aux_1, target_frames)\n",
    "#     loss_aux_target_2 = loss(rec_frames_aux_2, target_frames)\n",
    "#     loss_aux_target_3 = loss(rec_frames_aux_3, target_frames)\n",
    "    loss_aux_target_4 = loss(rec_frames_aux_4, target_frames)\n",
    "#     loss_aux_target = loss_aux_target_0/12 + loss_aux_target_1/8 + loss_aux_target_2/4 + loss_aux_target_3/2 + loss_aux_target_4\n",
    "#     loss_aux_target = loss_aux_target_2/4 + loss_aux_target_4\n",
    "    loss_aux_target  = loss_aux_target_4\n",
    "\n",
    "#     loss_base_aux_0 = loss(rec_frames_base_0, rec_frames_aux_0.detach())\n",
    "#     loss_base_aux_1 = loss(rec_frames_base_1, rec_frames_aux_1.detach())\n",
    "#     loss_base_aux_2 = loss(rec_frames_base_2, rec_frames_aux_2.detach())\n",
    "#     loss_base_aux_3 = loss(rec_frames_base_3, rec_frames_aux_3.detach())\n",
    "    loss_base_aux_4 = loss(rec_frames_base_4, rec_frames_aux_4.detach())\n",
    "#     loss_base_aux = loss_base_aux_0/12 + loss_base_aux_1/8 + loss_base_aux_2/4 + loss_base_aux_3/2 + loss_base_aux_4\n",
    "    loss_base_aux = loss_base_aux_4\n",
    "    \n",
    "#     loss_base_target = loss_base_target_3\n",
    "#     loss_aux_target = loss_aux_target_3\n",
    "#     loss_base_aux = loss_base_aux_3\n",
    "    \n",
    "#     loss_base_aux = dice_loss(rec_frames_base, rec_frames_aux.detach())\n",
    "    loss_i = loss_base_target + 0.5*loss_aux_target + 0.25*loss_base_aux\n",
    "#     loss_i = loss_base_target + 0.5*loss_base_aux\n",
    "#     loss_i = loss_base_target\n",
    "\n",
    "#     U = torch.cat((u_enc, u_dec, u_aux),dim=1)\n",
    "#     Z = torch.zeros_like(U).to(args.device)\n",
    "#     penalty = loss2(U,Z)\n",
    "#     penalty = (u_enc + u_dec + u_aux)/3\n",
    "#     print(loss_i)\n",
    "#     print(penalty)\n",
    "#     loss_i += 0.5*penalty\n",
    "\n",
    "#     loss_i = 0\n",
    "#     for j in np.arange(5):\n",
    "#         rec_frames_base_j = rec_frames_base[j]\n",
    "#         rec_frames_aux_j = rec_frames_aux[j]\n",
    "#         loss_base_target_j = dice_loss(rec_frames_base_j, target_frames)\n",
    "#         loss_aux_target_j = dice_loss(rec_frames_aux_j, target_frames)\n",
    "#         if j < 4:\n",
    "#             loss_base_aux_j = dice_loss(rec_frames_base_j, rec_frames_aux_j.detach())\n",
    "#         else:\n",
    "#             loss_base_aux_j = 0\n",
    "#         loss_j = loss_base_target_j + 0.5*loss_aux_target_j + 0.5*loss_base_aux_j\n",
    "#         loss_i += loss_j/(4-j)**2\n",
    "\n",
    "    lambda0 = 1\n",
    "    lambda1 = 1/2\n",
    "    lambda2 = 1/4\n",
    "    \n",
    "    p1 = f_L1(enc_base.te0u_1.parameters()) + f_L1(enc_base.te0u_2.parameters())\n",
    "    p2 = f_L1(enc_base.te1u_1.parameters()) + f_L1(enc_base.te1u_2.parameters())\n",
    "    p3 = f_L1(enc_base.te2u_1.parameters()) + f_L1(enc_base.te2u_2.parameters())\n",
    "    p4 = f_L1(dec_base.te0d_1.parameters()) + f_L1(dec_base.te0d_2.parameters()) + f_L1(dec_base.mha0.parameters())\n",
    "    p5 = f_L1(dec_base.te1d_1.parameters()) + f_L1(dec_base.te1d_2.parameters()) + f_L1(dec_base.mha1.parameters()) \n",
    "    p6 = f_L1(dec_base.te2d_1.parameters()) + f_L1(dec_base.te2d_2.parameters()) + f_L1(dec_base.mha2.parameters())\n",
    "    \n",
    "    penalty = lambda0*(p1+p4) + lambda1*(p2+p5) + lambda2*(p3+p6)\n",
    "    loss_i += penalty\n",
    "    \n",
    "    loss_i.backward()\n",
    "#     params_list = list(Enc_base.parameters()) + list(Dec_base.parameters())\n",
    "    torch.nn.utils.clip_grad_norm_(params_list, 1)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss_i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_epoch_FAZ(Train_Data, Target_Data, enc_base, dec_base, dec_aux, one_hot_enc, optimizer, loss, loss2, args, params_list):\n",
    "    \n",
    "    random_idxs = np.arange(len(Train_Data))\n",
    "    np.random.shuffle(random_idxs)\n",
    "    \n",
    "#     if one_hot_enc[0][0][0] == 1:\n",
    "#         random_idxs = random_idxs[0:len(Train_Data)]\n",
    "#         num_batches = int(len(Train_Data)/args.batch_size)\n",
    "#     else:\n",
    "#         random_idxs = random_idxs[0:args.sz_min]    \n",
    "#         num_batches = int(args.sz_min/args.batch_size) \n",
    "    num_batches = int(len(Train_Data)/args.batch_size)\n",
    "    \n",
    "#     random_idxs = random_idxs[0:args.sz_min]\n",
    "    train_data_shuffle = Train_Data[random_idxs]\n",
    "    target_data_shuffle = Target_Data[random_idxs]\n",
    "\n",
    "#     num_batches = args.num_batches\n",
    "#     num_batches = int(len(Train_Data)/args.batch_size)\n",
    "#     print(num_batches)\n",
    "    \n",
    "#     # Use twice as many training examples on first task (photocoagulation)\n",
    "#     if one_hot_enc[0][0][0] == 1:\n",
    "#         num_batches = int(2*num_batches)\n",
    "    \n",
    "    epoch_losses = np.zeros(num_batches)\n",
    "    for it in np.arange(num_batches):\n",
    "        \n",
    "#         print(it)\n",
    "\n",
    "        in_frames = train_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "        target_frames = target_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "        \n",
    "#         for i in np.arange(len(in_frames)):\n",
    "#             plt.imshow(in_frames[i].detach().cpu().numpy().squeeze())\n",
    "#             plt.show()\n",
    "#             plt.imshow(target_frames[i].detach().cpu().numpy().squeeze())\n",
    "#             plt.show()\n",
    "        \n",
    "        epoch_losses[it] = single_iter_FAZ(enc_base, dec_base, dec_aux, optimizer, loss, loss2, in_frames, target_frames, one_hot_enc, args, params_list)\n",
    "        \n",
    "    return epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_idxs = np.arange(len(Train_Data_aug))\n",
    "# np.random.shuffle(random_idxs)\n",
    "# train_data_shuffle = Train_Data_aug[random_idxs]\n",
    "# nhead = 16\n",
    "\n",
    "# epoch_losses = np.zeros(args.num_batches)\n",
    "\n",
    "# it = 0\n",
    "# in_frames = train_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "\n",
    "# Enc1 = CNN_Enc(args, 1, 32, 64, 128,mode='non').to(args.device)\n",
    "\n",
    "# ea0 = nn.Conv2d(args.d_attn0, args.d_attn1, kernel_size=4, stride=4, padding=0).to(args.device)\n",
    "# ea1 = nn.Conv2d(args.d_attn1, args.d_attn1, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# ea2 = nn.Conv2d(args.d_attn1, args.d_attn1, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "# ea3 = nn.Conv2d(args.d_attn1, args.d_attn1, kernel_size=3, stride = 1, padding=1).to(args.device)\n",
    "\n",
    "# e0 = nn.Conv2d(args.d_attn1, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 136x136x256\n",
    "# e0a = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 136x136x256\n",
    "# e0b = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 136x136x256\n",
    "# e0c = nn.Conv2d(args.d_attn2, args.d_attn2, kernel_size=3, padding=1).to(args.device) # output: 136x136x256\n",
    "\n",
    "# pool0 = nn.MaxPool2d(kernel_size=4, stride=4).to(args.device) # output: 68x68x256\n",
    "\n",
    "# te1u_1 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn1, nhead=nhead, dim_feedforward=args.d_attn1, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "# te1u_2 = torch.nn.TransformerEncoderLayer(d_model=args.d_attn1, nhead=nhead, dim_feedforward=args.d_attn1, dropout=0, layer_norm_eps=1e-05, batch_first=True).to(args.device)\n",
    "\n",
    "# DA1 = Sum_Domain_Adapter(args.num_tasks, args.d_attn1, args).to(args.device)\n",
    "\n",
    "# dim = 256\n",
    "# SAE1 = Sparse_AE(dim,4,50,args)\n",
    "\n",
    "# ReLU = nn.ReLU()\n",
    "\n",
    "# feats0u = Enc1(in_frames.squeeze().unsqueeze(1), one_hot_enc)\n",
    "\n",
    "# feats1u = ea0(feats0u)        \n",
    "# feats1ua = ea1(feats1u)\n",
    "# feats1ub = ReLU(feats1ua) + feats1u\n",
    "# feats1uc = ea2(feats1ub)\n",
    "# feats1ud = ReLU(feats1uc) + feats1ub\n",
    "# feats1ue = ea3(feats1ud)  \n",
    "# feats1uf = ReLU(feats1ue) + feats1ud\n",
    "\n",
    "# feats1u = DA1(feats1uf,one_hot_enc)\n",
    "\n",
    "# feats1u_a = feats1u.flatten(start_dim=2)\n",
    "# feats1u_a = torch.swapaxes(feats1u_a,1,2)\n",
    "# feats1u_a = f_pos_encoding_additive(feats1u_a,args).squeeze()\n",
    "# q1 = te1u_1(feats1u_a)\n",
    "# q2 = te1u_2(q1)\n",
    "\n",
    "# SAE1(q2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # num_params(te1u_1)\n",
    "# SAE1 = Sparse_AE(256,4,50,args)\n",
    "# print(num_params(SAE1))\n",
    "\n",
    "# SAE2 = Sparse_AE(512,8,50,args)\n",
    "# num_params(SAE2)\n",
    "\n",
    "# 64*50*2\n",
    "# 54*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_AE(train_data, target_data, enc_base, dec_base, one_hot_enc, args, i=0):\n",
    "    \n",
    "    random_idxs = np.arange(len(train_data.data))\n",
    "    np.random.shuffle(random_idxs)\n",
    "    train_data_shuffle = train_data.data[random_idxs]\n",
    "    target_data_shuffle = target_data[random_idxs]\n",
    "    it = 0\n",
    "    in_frames = train_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "    target_frames = target_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = enc_base(in_frames, one_hot_enc)\n",
    "\n",
    "        rec_frames_base_4, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=4)\n",
    "\n",
    "    plt.imshow(in_frames[i,0,0,:,:].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "    plt.imshow(target_frames[i,0,0,:,:].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(rec_frames_base_4[i,0,0,:,:].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "#         plt.imshow((1.0*(rec_frames_base_4[i,0,0,:,:]>0.5)).detach().cpu().numpy())\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_FAZ(train_data, target_data, enc_base, dec_base, one_hot_enc, args, i=0):\n",
    "    \n",
    "    random_idxs = np.arange(len(train_data.data))\n",
    "    np.random.shuffle(random_idxs)\n",
    "    train_data_shuffle = train_data.data[random_idxs]\n",
    "    target_data_shuffle = target_data[random_idxs]\n",
    "    it = 0\n",
    "    in_frames = train_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "    target_frames = target_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = enc_base(in_frames, one_hot_enc)\n",
    "#         rec_frames, feats1n_base, feats2n_base, feats4n_base, feats5n_base = dec_base(feats1u, feats2u, feats4u_f, feats5_f, x4_sz, one_hot_enc)\n",
    "#         rec_frames_aux, feats1n_aux, feats2n_aux, feats4n_aux, feats5n_aux      = dec_aux(feats1u, feats2u, feats4u_f, feats5_f, x4_sz)\n",
    "\n",
    "        rec_frames_base_0, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=0)\n",
    "        rec_frames_base_1, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=1)\n",
    "        rec_frames_base_2, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=2)\n",
    "        rec_frames_base_3, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=3)\n",
    "        rec_frames_base_4, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=4)\n",
    "\n",
    "    plt.imshow(in_frames[i,0,0,:,:].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "    plt.imshow(target_frames[i,0,0,:,:].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "#         plt.imshow(rec_frames[i,0,0,:,:].detach().cpu().numpy())\n",
    "#         plt.show()\n",
    "#         plt.imshow((in_frames[i,0,0,:,:] + rec_frames[i,0,0,:,:]).detach().cpu().numpy())\n",
    "#         plt.show()\n",
    "\n",
    "#     plt.imshow(rec_frames_base_0[i,0,0,:,:].detach().cpu().numpy())\n",
    "#     plt.show()\n",
    "#     plt.imshow(rec_frames_base_1[i,0,0,:,:].detach().cpu().numpy())\n",
    "#     plt.show()\n",
    "#     plt.imshow(rec_frames_base_2[i,0,0,:,:].detach().cpu().numpy())\n",
    "#     plt.show()\n",
    "#     plt.imshow(rec_frames_base_3[i,0,0,:,:].detach().cpu().numpy())\n",
    "#     plt.show()\n",
    "    plt.imshow(rec_frames_base_4[i,0,0,:,:].detach().cpu().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_display_all(data, target_data, enc_base, dec_base, one_hot_enc, test_split, args, test_folder):\n",
    "\n",
    "#     random_idxs = np.arange(len(data))\n",
    "#     np.random.shuffle(random_idxs)\n",
    "#     data_shuffle = data[random_idxs]\n",
    "#     target_data_shuffle = target_data[random_idxs]\n",
    "\n",
    "    data_shuffle = data\n",
    "    target_data_shuffle = target_data\n",
    "\n",
    "    bs = args.batch_size\n",
    "    LD = len(data)\n",
    "#     Lb = int(LD/2)\n",
    "    Lb = LD\n",
    "    NN = int(LD/bs)\n",
    "#     NN = int(np.ceil(len(data)/bs))\n",
    "    dice_v = []\n",
    "    dices_v = []\n",
    "    target_area_v = []\n",
    "    \n",
    "    dice_tot = 0\n",
    "    dice_tot_s = 0\n",
    "    target_area_tot = 0\n",
    "    for it in range(NN):\n",
    "\n",
    "        in_frames = data_shuffle[it*bs:(it+1)*bs,:,:,:,:]\n",
    "        target_frames = target_data_shuffle[it*bs:(it+1)*bs,:,:,:,:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = enc_base(in_frames, one_hot_enc)\n",
    "\n",
    "            rec_frames, _, _, _, _, _ = dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=4)\n",
    "\n",
    "        for i in np.arange(args.batch_size):\n",
    "\n",
    "            in_frame = in_frames[i,0,0,:,:].detach().cpu().numpy()\n",
    "            target_frame = target_frames[i,0,0,:,:].detach().cpu().numpy()\n",
    "            rec_frame = (rec_frames[i,0,0,:,:]).detach().cpu().numpy()\n",
    "\n",
    "#             plt.imshow(in_frame)\n",
    "#             plt.savefig(test_folder + '/' + str(i) + '_a_in_frame' + '.png')\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.imshow(target_frame)\n",
    "#             plt.savefig(test_folder + '/' + str(i) + '_b_ground_truth' + '.png')\n",
    "#             plt.show()\n",
    "            \n",
    "#             plt.imshow(rec_frame)\n",
    "#             plt.savefig(test_folder + '/' + str(i) + '_b_pred_frame' + '.png')\n",
    "#             plt.show()\n",
    "            \n",
    "    #         target_frame_d = target_frame\n",
    "    #         rec_frame_d = rec_frame\n",
    "            target_frame_d = 1.*(target_frame>0.5)\n",
    "            rec_frame_d = 1.*(rec_frame>0.5)\n",
    "\n",
    "            dice_i, _ = f_dice_jac(target_frame_d,rec_frame_d)\n",
    "            dice_s, _ = f_dice_jac_scaled(target_frame_d,rec_frame_d)\n",
    "            dice_v.append(dice_i)\n",
    "            dices_v.append(dice_s)\n",
    "#             dice_tot += dice_i\n",
    "#             dice_tot_s += dice_s\n",
    "            target_area_i = np.sum(target_frame_d)\n",
    "            target_area_v.append(target_area_i)\n",
    "#             target_area_tot += target_area_i\n",
    "#             dices.append(dice_i)\n",
    "#             print(dice_i)\n",
    "\n",
    "#             if dice_i < 0.5:\n",
    "#                 print(dice_i)\n",
    "        \n",
    "#                 plt.imshow(in_frame)\n",
    "#                 plt.show()\n",
    "                \n",
    "#                 plt.imshow(target_frame)\n",
    "#                 plt.show()\n",
    "            \n",
    "#                 plt.imshow(rec_frame)\n",
    "#                 plt.show()\n",
    "                \n",
    "#     dice_tot_s = np.sum(dices_v)\n",
    "#     target_area_tot = np.sum(target_area_v)\n",
    "\n",
    "#     plt.plot(dice_v)\n",
    "#     plt.grid()\n",
    "#     print('Mean Dice =', np.mean(dice_v))\n",
    "#     print('Mean Dice (scaled by area) =', np.sum(dices_v)/np.sum(target_area_v))\n",
    "#     plt.show()\n",
    "\n",
    "#     print(dice_v)\n",
    "    \n",
    "    plt.plot(dice_v[0:Lb])\n",
    "    plt.grid()\n",
    "    print('Mean Dice =', np.mean(dice_v[0:Lb]))\n",
    "    print('Mean Dice (scaled by area) =', np.sum(dices_v[0:Lb])/np.sum(target_area_v[0:Lb]))\n",
    "    plt.show()\n",
    "    \n",
    "    print(np.array(dice_v[0:Lb]))\n",
    "    \n",
    "    med = np.median(np.array(dice_v))\n",
    "#     med = 0.4\n",
    "    print(med)\n",
    "    TF = np.array(dice_v) > med\n",
    "    print(TF)\n",
    "    \n",
    "    filtered_vals = [v for v, f in zip(test_split, TF) if f]\n",
    "    \n",
    "    print(np.sum(TF*np.array(dice_v))/np.sum(TF))\n",
    "    \n",
    "    return np.array(filtered_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_encode(feats1u,args):\n",
    "    feats1u_a = feats1u.flatten(start_dim=2)\n",
    "    feats1u_b = torch.swapaxes(feats1u_a,1,2)\n",
    "    feats1u_c = f_pos_encoding_additive(feats1u_b,args).squeeze()\n",
    "    return feats1u_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dice_jac(mask1,mask2):\n",
    "\n",
    "    union = 1*((mask1 + mask2) > 0)\n",
    "\n",
    "    intersect = (mask1*mask2)\n",
    "\n",
    "    sum1 = np.sum(mask1) + np.sum(mask2)\n",
    "\n",
    "    dice = 2*np.sum(intersect)/sum1\n",
    "    jaccard = np.sum(intersect)/np.sum(union)\n",
    "\n",
    "#     return dice, jaccard, union, np.sum(intersect), sum1\n",
    "    return dice, jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dice_jac_scaled(mask1,mask2):\n",
    "\n",
    "    union = 1*((mask1 + mask2) > 0)\n",
    "\n",
    "    intersect = (mask1*mask2)\n",
    "\n",
    "    sum1 = np.sum(mask1) + np.sum(mask2)\n",
    "\n",
    "    dice = 2*np.sum(intersect)/sum1\n",
    "    jaccard = np.sum(intersect)/np.sum(union)\n",
    "\n",
    "#     return dice, jaccard, union, np.sum(intersect), sum1\n",
    "    return dice*np.sum(mask1), jaccard*np.sum(mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_Tot_Dice(Data, Target_Data, Enc_base, Dec_base, one_hot_enc, args):\n",
    "\n",
    "    Target_Data = 1.*(Target_Data > 0.5)\n",
    "    \n",
    "    LD = len(Data)\n",
    "    num_batches = int(LD/args.batch_size)\n",
    "\n",
    "#     dice_tot = 0\n",
    "#     dice_tot_s = 0\n",
    "#     target_area_tot = 0\n",
    "    \n",
    "    dice_v = []\n",
    "    dices_v = []\n",
    "    target_area_v = []\n",
    "    \n",
    "    L = 0\n",
    "    for it in np.arange(num_batches):\n",
    "\n",
    "        in_frames = Data[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "        target_frames = Target_Data[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = Enc_base(in_frames, one_hot_enc)\n",
    "            rec_frames, _, _, _, _, _ = Dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=4)\n",
    "\n",
    "        rec_frames = 1.*(rec_frames > 0.5)\n",
    "        \n",
    "        for i in np.arange(args.batch_size):\n",
    "            if torch.sum(target_frames[i]) > 0:\n",
    "                in_frame =  in_frames.detach().cpu().numpy().squeeze()[i]\n",
    "                target_frame = target_frames.detach().cpu().numpy().squeeze()[i]\n",
    "                rec_frame = rec_frames.detach().cpu().numpy().squeeze()[i]\n",
    "\n",
    "                dice_i, _ = f_dice_jac(target_frame,rec_frame)\n",
    "                dice_is, _ = f_dice_jac_scaled(target_frame,rec_frame)\n",
    "                dice_v.append(dice_i)\n",
    "                dices_v.append(dice_is)\n",
    "#                 dice_tot += dice_i\n",
    "#                 dice_tot_s += dice_is\n",
    "                target_area_i = np.sum(target_frame)\n",
    "                target_area_v.append(target_area_i)\n",
    "#                 target_area_tot += target_area_i\n",
    "                L += 1\n",
    "        \n",
    "    #     plt.imshow(in_frame)\n",
    "    #     plt.show()\n",
    "    #     plt.imshow(target_frame)\n",
    "    #     plt.show()\n",
    "    #     plt.imshow(rec_frame)\n",
    "    #     plt.show()\n",
    "    #     plt.imshow(rec_frame - target_frame)\n",
    "    #     plt.show()\n",
    "\n",
    "    dice_tot = np.sum(dice_v[0:LD])\n",
    "    dice_tot_s = np.sum(dices_v[0:LD])\n",
    "    target_area_tot = np.sum(target_area_v[0:LD])\n",
    "    \n",
    "#     return dice_tot/L\n",
    "    return dice_tot_s/target_area_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####################Training loop ###########################\n",
    "\n",
    "# # args.mode = 1\n",
    "\n",
    "# for task_idx in tqdm(np.arange(args.num_tasks)):\n",
    "\n",
    "#     Enc = Enc_base\n",
    "\n",
    "#     Dec = Dec_aux_list[task_idx]\n",
    "#     Dec_name = Dec_name_list[task_idx]\n",
    "\n",
    "#     Train_Data  = Train_Data_list[task_idx]\n",
    "#     Train_Target_Data = Target_Data_list[task_idx]\n",
    "#     args.num_batches = int(len(Train_Data)/args.N)\n",
    "\n",
    "#     args.training_mode = 1\n",
    "#     args.num_batches = int(len(Train_Data)/args.N)\n",
    "\n",
    "#     # RM_path_save = resume_AE_ckpt.joinpath('FAZ_RM_ckpt')\n",
    "\n",
    "#     args.num_epochs = 100\n",
    "#     args.show_example_epochs = 1\n",
    "#     args.save_epochs = 1\n",
    "\n",
    "#     log_mean_epoch_losses = np.zeros(args.num_epochs)\n",
    "\n",
    "#     loss = nn.BCELoss() # <-- Use this one\n",
    "#     loss2 = nn.L1Loss()\n",
    "\n",
    "#     lr = 1E-4\n",
    "#     params_list = list(Enc.parameters()) + list(Dec.parameters())\n",
    "#     optimizer = torch.optim.Adam(params_list, lr=lr, betas=(0.9, 0.999))\n",
    "    \n",
    "#     one_hot_enc = torch.zeros(args.num_tasks).to(args.device)\n",
    "#     one_hot_enc[task_idx] = 1\n",
    "\n",
    "#     # train_dice_v = []\n",
    "#     # train_dice_v2 = []\n",
    "#     # test_dice_v = []\n",
    "#     # test_dice_v2 = []\n",
    "\n",
    "#     # Train for a maximum of max_epochs:\n",
    "#     for epoch in tqdm(np.arange(args.num_epochs), desc=\"Training progress...\"):\n",
    "        \n",
    "#         epoch_losses = single_epoch_AE(Train_Data, Target_Data, Enc, Dec, one_hot_enc, optimizer, loss, loss2, args)\n",
    "#         log_mean_epoch_losses[epoch] = np.log(np.mean(epoch_losses))\n",
    "#     #     coord_errors[epoch] = f_coord_error(train_data,train_data_traj,VPTR_Enc, C1, args)\n",
    "\n",
    "#         if np.mod(epoch,args.show_example_epochs) == 0:\n",
    "#             display_AE(Train_Data, Target_Data, Enc, Dec, one_hot_enc, args)\n",
    "\n",
    "#             plt.plot(log_mean_epoch_losses[0:epoch])\n",
    "#             plt.grid()\n",
    "#             plt.show()\n",
    "\n",
    "#     #         train_dice = f_Tot_Dice(Train_Data,args)\n",
    "#     #         print(train_dice)\n",
    "#     #         train_dice_v.append(train_dice)\n",
    "#     #         plt.plot(train_dice_v)\n",
    "#     #         plt.grid()\n",
    "#     #         plt.show()\n",
    "\n",
    "#     #         test_dice, test_dice2 = f_Tot_Dice(Test_Data,args)\n",
    "#     #         print(test_dice)\n",
    "#     #         print(test_dice2)\n",
    "#     #         test_dice_v.append(test_dice)\n",
    "#     #         test_dice_v2.append(test_dice2)\n",
    "#     #         plt.plot(test_dice_v)\n",
    "#     #         plt.plot(test_dice_v2)\n",
    "#     #         plt.grid()\n",
    "#     #         plt.show()\n",
    "\n",
    "#     #         plt.plot(coord_errors[0:epoch])\n",
    "#     #         plt.grid()\n",
    "#     #         plt.show()\n",
    "#     #     if np.mod(epoch,args.save_epochs) == 0:\n",
    "#     #         torch.save(model.state_dict(), RM_path_save)\n",
    "\n",
    "# #     Dec_aux_load = resume_AE_ckpt.joinpath(Dec_name)\n",
    "# #     torch.save(Dec.state_dict(), Dec_aux_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(Enc_base, Dec_base, Dec_aux_list, Dec_name_list, text_idx, model_folder):\n",
    "\n",
    "    newfolder = model_folder + '/test_idx_' + str(test_idx)\n",
    "    if not os.path.exists(newfolder):\n",
    "        os.makedirs(newfolder)\n",
    "\n",
    "    date = datetime.date.today()\n",
    "    date_str = str(date.year) + '_' + str(date.month) + '_' + str(date.day)\n",
    "\n",
    "    model = Enc_base\n",
    "    model_name = 'Enc_base'\n",
    "    save_path = model_folder + '/test_idx_' + str(test_idx) + '/' + model_name + '__' + 'aya' + '__' + date_str\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    model = Dec_base\n",
    "    model_name = 'Dec_base'\n",
    "    save_path = model_folder + '/test_idx_' + str(test_idx) + '/' + model_name + '__' + 'aya' + '__' + date_str\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    if len(Dec_aux_list) > 0:\n",
    "    \n",
    "        for i in range(len(Dec_aux_list)):\n",
    "            model = Dec_aux_list[i]\n",
    "            model_name = Dec_name_list[i]\n",
    "            save_path = model_folder + '/test_idx_' + str(test_idx) + '/' + model_name + '__' + 'aya' + '__' + date_str\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_AE(Enc_base, Dec_base, test_idx, model_folder, date_str):\n",
    "    \n",
    "#     date = datetime.date.today()\n",
    "#     date_str = str(date.year) + '_' + str(date.month) + '_' + str(date.day)\n",
    "    \n",
    "    model = Enc_base\n",
    "    model_name = 'Enc_base'\n",
    "    load_path = model_folder + '/test_idx_' + str(test_idx) + '/' + model_name + '__' + 'aya' + '__' + date_str\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "\n",
    "    model = Dec_base\n",
    "    model_name = 'Dec_base'\n",
    "    load_path = model_folder + '/test_idx_' + str(test_idx) + '/' + model_name + '__' + 'aya' + '__' + date_str\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models_FAZ(Enc_base, Dec_base, Dec_aux_list, Dec_name_list, test_idx, model_folder, date_str):\n",
    "    \n",
    "#     date = datetime.date.today()\n",
    "#     date_str = str(date.year) + '_' + str(date.month) + '_' + str(date.day)\n",
    "    \n",
    "    model = Enc_base\n",
    "    model_name = 'Enc_base'\n",
    "    load_path = model_folder + '/test_idx_' + str(test_idx) + '/' + model_name + '__' + 'aya' + '__' + date_str\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "\n",
    "    model = Dec_base\n",
    "    model_name = 'Dec_base'\n",
    "    load_path = model_folder + '/test_idx_' + str(test_idx) + '/' + model_name + '__' + 'aya' + '__' + date_str\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "\n",
    "    for i in range(len(Dec_aux_list)):\n",
    "        model = Dec_aux_list[i]\n",
    "        model_name = Dec_name_list[i]\n",
    "        load_path = model_folder + '/test_idx_' + str(test_idx) + '/' + model_name + '__' + 'aya' + '__' + date_str\n",
    "        model.load_state_dict(torch.load(load_path))\n",
    "\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total Variation (TV) regularization helps promote spatial smoothness and connectivity.\n",
    "# def total_variation_loss(mask):\n",
    "#     dx = np.diff(mask, axis=0)  # Differences along the x-axis\n",
    "#     dy = np.diff(mask, axis=1)  # Differences along the y-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_normalize(x):\n",
    "    m1, _ = torch.max(x,axis=1)\n",
    "    m2, _ = torch.max(m1,axis=1)\n",
    "    return (x.T/m2).T\n",
    "\n",
    "################## LOAD IN DATA ######################\n",
    "\n",
    "############\n",
    "a_n_mode = 0 # Use Aya data\n",
    "# a_n_mode = 1 # Use Nathan data\n",
    "############\n",
    "\n",
    "## Photocoagulation Data\n",
    "\n",
    "%cd Y:/FAZ/Photocoagulation/Laser and Mask - All-orig-extractedImages/mats\n",
    "\n",
    "Photocoag_Imgs = torch.from_numpy(sio.loadmat('resized.mat')[\"Imgs_rsz\"].astype(np.float32))\n",
    "Photocoag_Masks = torch.from_numpy(sio.loadmat('real_masks.mat')[\"Imgs_mask\"].astype(np.float32))\n",
    "\n",
    "# Photocoag_Imgs /= torch.max(Photocoag_Imgs)\n",
    "# Photocoag_Masks /= torch.max(Photocoag_Masks)\n",
    "\n",
    "Photocoag_Imgs = f_normalize(Photocoag_Imgs)\n",
    "Photocoag_Masks = f_normalize(Photocoag_Masks)\n",
    "\n",
    "# L = len(Photocoag_Masks)\n",
    "# for i in np.arange(L):\n",
    "#     x = (Photocoag_Imgs + Photocoag_Masks)[i].detach().cpu().numpy().squeeze()\n",
    "#     plt.imshow(x)\n",
    "#     plt.show()\n",
    "\n",
    "## Healthy Data\n",
    "\n",
    "%cd Y:\\FAZ\\FAZ-cropped-SVC-graded\\Healthy\\all_Healthy\\PR\\mats\n",
    "\n",
    "imgs_SVC = torch.from_numpy(sio.loadmat('SVC_resized.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_SVC_aya = torch.from_numpy(sio.loadmat('SVC_real_masks_aya.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_SVC_nathan = torch.from_numpy(sio.loadmat('SVC_real_masks_nathan.mat')[\"Imgs\"].astype(np.float32))\n",
    "\n",
    "# imgs_SVC /= torch.max(imgs_SVC)\n",
    "# masks_SVC_aya /= torch.max(masks_SVC_aya)\n",
    "# masks_SVC_nathan /= torch.max(masks_SVC_nathan)\n",
    "imgs_SVC = f_normalize(imgs_SVC)\n",
    "masks_SVC_aya = f_normalize(masks_SVC_aya)\n",
    "masks_SVC_nathan = f_normalize(masks_SVC_nathan)\n",
    "# masks_SVC_aya = 1.0*(masks_SVC_aya > 0.1)\n",
    "# masks_SVC_nathan = 1.0*(masks_SVC_nathan > 0.1)\n",
    "\n",
    "# masks_SVC = (masks_SVC_aya + masks_SVC_nathan)/2\n",
    "if a_n_mode == 0:\n",
    "    masks_SVC = masks_SVC_aya\n",
    "else:\n",
    "    masks_SVC = masks_SVC_nathan\n",
    "\n",
    "# Healthy_Imgs_SVC = imgs_SVC\n",
    "# Healthy_Masks_SVC = masks_SVC\n",
    "\n",
    "Healthy_Imgs_SVC = imgs_SVC\n",
    "Healthy_Masks_SVC = masks_SVC_aya\n",
    "Healthy_Masks_SVC_alt = masks_SVC_nathan\n",
    "\n",
    "# L = len(masks_SVC)\n",
    "# for i in np.arange(L):\n",
    "#     x = masks_SVC[i].detach().cpu().numpy().squeeze()\n",
    "#     plt.imshow(x)\n",
    "#     plt.show()\n",
    "    \n",
    "## ALZ Data\n",
    "\n",
    "%cd Y:\\FAZ\\FAZ-cropped-SVC-graded\\Alz\\all_Alz\\PR\\mats\n",
    "\n",
    "imgs_SVC = torch.from_numpy(sio.loadmat('SVC_resized.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_SVC_aya = torch.from_numpy(sio.loadmat('SVC_real_masks_aya.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_SVC_nathan = torch.from_numpy(sio.loadmat('SVC_real_masks_nathan.mat')[\"Imgs\"].astype(np.float32))\n",
    "\n",
    "# imgs_SVC /= torch.max(imgs_SVC)\n",
    "# masks_SVC_aya /= torch.max(masks_SVC_aya)\n",
    "# masks_SVC_nathan /= torch.max(masks_SVC_nathan)\n",
    "imgs_SVC = f_normalize(imgs_SVC)\n",
    "masks_SVC_aya = f_normalize(masks_SVC_aya)\n",
    "masks_SVC_nathan = f_normalize(masks_SVC_nathan)\n",
    "# masks_SVC_aya = 1.0*(masks_SVC_aya > 0.1)\n",
    "# masks_SVC_nathan = 1.0*(masks_SVC_nathan > 0.1)\n",
    "\n",
    "# masks_SVC = (masks_SVC_aya + masks_SVC_nathan)/2\n",
    "if a_n_mode == 0:\n",
    "    masks_SVC = masks_SVC_aya\n",
    "else:\n",
    "    masks_SVC = masks_SVC_nathan\n",
    "\n",
    "# ALZ_Imgs_SVC = imgs_SVC\n",
    "# ALZ_Masks_SVC = masks_SVC\n",
    "\n",
    "ALZ_Imgs_SVC = imgs_SVC\n",
    "ALZ_Masks_SVC = masks_SVC_aya\n",
    "ALZ_Masks_SVC_alt = masks_SVC_nathan\n",
    "\n",
    "# L = len(masks_SVC)\n",
    "# for i in np.arange(L):\n",
    "#     x = masks_SVC[i].detach().cpu().numpy().squeeze()\n",
    "#     plt.imshow(x)\n",
    "#     plt.show()\n",
    "    \n",
    "## AMD Data\n",
    "\n",
    "%cd Y:\\FAZ\\FAZ-cropped-SVC-graded\\AMD\\all_AMD\\PR\\mats\n",
    "\n",
    "imgs_SVC = torch.from_numpy(sio.loadmat('SVC_resized.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_SVC_aya = torch.from_numpy(sio.loadmat('SVC_real_masks_aya.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_SVC_nathan = torch.from_numpy(sio.loadmat('SVC_real_masks_nathan.mat')[\"Imgs\"].astype(np.float32))\n",
    "\n",
    "# imgs_SVC /= torch.max(imgs_SVC)\n",
    "# masks_SVC_aya /= torch.max(masks_SVC_aya)\n",
    "# masks_SVC_nathan /= torch.max(masks_SVC_nathan)\n",
    "imgs_SVC = f_normalize(imgs_SVC)\n",
    "masks_SVC_aya = f_normalize(masks_SVC_aya)\n",
    "masks_SVC_nathan = f_normalize(masks_SVC_nathan)\n",
    "# masks_SVC_aya = 1.0*(masks_SVC_aya > 0.1)\n",
    "# masks_SVC_nathan = 1.0*(masks_SVC_nathan > 0.1)\n",
    "\n",
    "# masks_SVC = (masks_SVC_aya + masks_SVC_nathan)/2\n",
    "# masks_SVC = masks_SVC_aya\n",
    "if a_n_mode == 0:\n",
    "    masks_SVC = masks_SVC_aya\n",
    "else:\n",
    "    masks_SVC = masks_SVC_nathan\n",
    "\n",
    "# AMD_Imgs_SVC = imgs_SVC\n",
    "# AMD_Masks_SVC = masks_SVC\n",
    "\n",
    "AMD_Imgs_SVC = imgs_SVC\n",
    "AMD_Masks_SVC = masks_SVC_aya\n",
    "AMD_Masks_SVC_alt = masks_SVC_nathan\n",
    "\n",
    "# L = len(masks_SVC)\n",
    "# for i in np.arange(L):\n",
    "#     x = masks_SVC[i].detach().cpu().numpy().squeeze()\n",
    "#     plt.imshow(x)\n",
    "#     plt.show()\n",
    "    \n",
    "## DR Data\n",
    "\n",
    "%cd Y:\\FAZ\\FAZ-cropped-SVC-graded\\DR\\all_DR\\PR\\mats\n",
    "    \n",
    "imgs_SVC = torch.from_numpy(sio.loadmat('SVC_resized.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_SVC_aya = torch.from_numpy(sio.loadmat('SVC_real_masks_aya.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_SVC_nathan = torch.from_numpy(sio.loadmat('SVC_real_masks_nathan.mat')[\"Imgs\"].astype(np.float32))\n",
    "\n",
    "# imgs_SVC /= torch.max(imgs_SVC)\n",
    "# masks_SVC_aya /= torch.max(masks_SVC_aya)\n",
    "# masks_SVC_nathan /= torch.max(masks_SVC_nathan)\n",
    "imgs_SVC = f_normalize(imgs_SVC)\n",
    "masks_SVC_aya = f_normalize(masks_SVC_aya)\n",
    "masks_SVC_nathan = f_normalize(masks_SVC_nathan)\n",
    "# masks_SVC_aya = 1.0*(masks_SVC_aya > 0.1)\n",
    "# masks_SVC_nathan = 1.0*(masks_SVC_nathan > 0.1)\n",
    "\n",
    "# masks_SVC = (masks_SVC_aya + masks_SVC_nathan)/2\n",
    "if a_n_mode == 0:\n",
    "    masks_SVC = masks_SVC_aya\n",
    "else:\n",
    "    masks_SVC = masks_SVC_nathan\n",
    "\n",
    "# DR_Imgs_SVC = imgs_SVC\n",
    "# DR_Masks_SVC = masks_SVC\n",
    "\n",
    "DR_Imgs_SVC = imgs_SVC\n",
    "DR_Masks_SVC = masks_SVC_aya\n",
    "DR_Masks_SVC_alt = masks_SVC_nathan\n",
    "\n",
    "# masks_SVC = 1.*(masks_SVC>0.5)\n",
    "\n",
    "# L = len(masks_SVC)\n",
    "# for i in np.arange(L):\n",
    "#     x = masks_SVC[i].detach().cpu().numpy().squeeze()\n",
    "#     plt.imshow(x)\n",
    "#     plt.show()\n",
    "\n",
    "print('Healthy Size:')\n",
    "print(Healthy_Imgs_SVC.size())\n",
    "print('ALZ Size:')\n",
    "print(ALZ_Imgs_SVC.size())\n",
    "print('AMD Size:')\n",
    "print(AMD_Imgs_SVC.size())\n",
    "print('DR Size:')\n",
    "print(DR_Imgs_SVC.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_L1(params):\n",
    "    return torch.mean(torch.abs(torch.cat([x.view(-1) for x in params])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(size: int, sigma: float) -> torch.Tensor:\n",
    "    \"\"\"Generates a Gaussian kernel.\"\"\"\n",
    "    # Create a 2D Gaussian kernel\n",
    "    kernel = torch.tensor(\n",
    "        [[(1 / (2 * np.pi * sigma ** 2)) * \n",
    "          np.exp(-((x - size // 2) ** 2 + (y - size // 2) ** 2) / (2 * sigma ** 2))\n",
    "          for y in range(size)] for x in range(size)]\n",
    "    )\n",
    "    # Normalize the kernel\n",
    "    kernel /= kernel.sum()\n",
    "    return kernel.unsqueeze(0).unsqueeze(0)  # Shape (1, 1, size, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_interpolate(inmask1, inmask2, args):\n",
    "    mask1 = 1.*inmask1.unsqueeze(1)\n",
    "    mask2 = 1.*inmask2.unsqueeze(1)\n",
    "\n",
    "    beta = np.random.beta(0.5, 0.5)\n",
    "    pflip = np.random.uniform(0,1)\n",
    "\n",
    "    one_hot = torch.zeros(args.num_tasks).to(args.device)\n",
    "#     beta = beta_v[epoch]\n",
    "#     pflip = pflip_v[epoch]\n",
    "    if pflip < 0.5:\n",
    "        if pflip < 0.25:\n",
    "            out = inmask1\n",
    "            one_hot[task_idx] = 1\n",
    "            \n",
    "        else:\n",
    "            out = inmask2\n",
    "            one_hot[task_idx+int(args.num_tasks/2)-1] = 1\n",
    "    else:\n",
    "        one_hot[task_idx] = beta\n",
    "        one_hot[task_idx+int(args.num_tasks/2)-1] = 1 - beta\n",
    "        \n",
    "#         interpolated = beta*mask1 + (1-beta)*mask2\n",
    "#         kernel_size = 25\n",
    "#         sigma = 30\n",
    "#         kernel = gaussian_kernel(kernel_size, sigma).to(torch.float32)\n",
    "#         smoothed1 = (mask2>0.5)*((1-mask1)>0.5)*torch.nn.functional.conv2d(mask1, kernel, padding=kernel_size // 2, groups=1)\n",
    "#         smoothed_border = 1*smoothed1/torch.max(smoothed1)\n",
    "# #         smoothed_border = torch.where(smoothed_border > 1, torch.tensor(1.0), smoothed_border)\n",
    "#         smoothed_mask1 = smoothed_border + mask1\n",
    "#         out = beta*smoothed_mask1 + (1-beta)*mask2\n",
    "\n",
    "        out = beta*mask1 + (1-beta)*mask2\n",
    "        \n",
    "    ones = torch.ones(args.batch_size,1,args.num_tasks).to(args.device)\n",
    "    one_hot_enc = ones*one_hot\n",
    "\n",
    "    return out.squeeze(1), one_hot_enc\n",
    "\n",
    "# task_idx = 0\n",
    "\n",
    "# Train_Target_Data = Train_Target_Data_list[task_idx]\n",
    "\n",
    "# # Train_Target_Data = Train_Target_Data > 0.5\n",
    "\n",
    "# Train_Target_Data_alt = Train_Target_Data_list_alt[task_idx]\n",
    "\n",
    "# Train_Target_Data, one_hot_enc = f_interpolate(Train_Target_Data, Train_Target_Data_alt, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd Y:\\FAZ\\Models\\Models New\\Models New New\\AE\n",
    "\n",
    "# filt_idxs0 = np.loadtxt('filt_v_test_idx_0.csv', delimiter=',')\n",
    "# filt_idxs1 = np.loadtxt('filt_v_test_idx_1.csv', delimiter=',')\n",
    "\n",
    "# filt_idxs = np.sort(np.concatenate((filt_idxs0,filt_idxs1)))\n",
    "\n",
    "# L_PC = len(Photocoag_Imgs)\n",
    "# bad_idxs = [x for x in range(L_PC) if x not in filt_idxs]\n",
    "\n",
    "# print(len(bad_idxs))\n",
    "# print(len(filt_idxs))\n",
    "# print(L_PC)\n",
    "\n",
    "# # Photocoag_Imgs = Photocoag_Imgs[bad_idxs]\n",
    "# # Photocoag_Masks = Photocoag_Masks[bad_idxs]\n",
    "# Photocoag_Imgs = Photocoag_Imgs[filt_idxs]\n",
    "# Photocoag_Masks = Photocoag_Masks[filt_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## jump\n",
    "\n",
    "## AE Loop\n",
    "\n",
    "## DEFINE MODELS\n",
    "\n",
    "args.num_tasks = 4*1\n",
    "np.random.seed(2024)\n",
    "num_splits = 2 # Two fold cross validation\n",
    "args.num_aug = 2\n",
    "\n",
    "args.num_epochs = 1000\n",
    "args.show_example_epochs = 1\n",
    "args.save_epochs = int(args.num_epochs/5)\n",
    "\n",
    "task_names = ['Healthy', 'ALZ', 'AMD', 'DR', 'Photocoag']\n",
    "\n",
    "## TRAIN TEST SPLIT\n",
    "for test_idx in tqdm(np.arange(num_splits)):\n",
    "# for test_idx in [1]:\n",
    "\n",
    "#     for task_idx in tqdm(np.arange(args.num_tasks)):\n",
    "#     for task_idx in tqdm(np.arange(int(args.num_tasks/2))):\n",
    "    for task_idx in np.arange(4):\n",
    "#     for task_idx in [4]:\n",
    "\n",
    "#         model_folder = 'Y:/FAZ/Models/Models New/Models New New/AE/' + task_names[task_idx]\n",
    "#         model_folder = 'Y:/FAZ/Models/Models New/Models New New/AE_with_2_annotations, with pretraining/' + task_names[task_idx]\n",
    "\n",
    "        model_folder = 'Y:/FAZ/Models/Models New/Models New New/AE2/' + task_names[task_idx]\n",
    "#         model_folder = 'Y:/FAZ/Models/Models New/Models New New/AE filtered 2_annotations/' + task_names[task_idx]\n",
    "\n",
    "#         if task_idx == 0:\n",
    "#             %cd Y:\\FAZ\\Models\\Models New\\AE\\Healthy\n",
    "#         if task_idx == 1:\n",
    "#             %cd Y:\\FAZ\\Models\\Models New\\AE\\AMD\n",
    "#         if task_idx == 2:\n",
    "#             %cd Y:\\FAZ\\Models\\Models New\\AE\\ALZ\n",
    "#         if task_idx == 3:\n",
    "#             %cd Y:\\FAZ\\Models\\Models New\\AE\\DR\n",
    "#         if task_idx == 4:\n",
    "#             %cd Y:\\FAZ\\Models\\Models New\\AE\\PC\n",
    "\n",
    "        save_name = '_test_idx_' + str(test_idx)\n",
    "        test_folder = model_folder + '/Test_Results_' + str(test_idx)\n",
    "        if not os.path.exists(model_folder):\n",
    "            os.mkdir(model_folder)\n",
    "        if not os.path.exists(test_folder):\n",
    "            os.mkdir(test_folder)\n",
    "        \n",
    "        np.random.seed(2024)\n",
    "\n",
    "#         splits = get_train_test_splits(Photocoag_Imgs,split=num_splits)\n",
    "#         Photocoag_Imgs_train, Photocoag_Imgs_test, Photocoag_Masks_train, Photocoag_Masks_test = train_test_split(Photocoag_Imgs, Photocoag_Masks,splits,test_idx)\n",
    "        Photocoag_Imgs_train = Photocoag_Imgs\n",
    "        Photocoag_Imgs_test = Photocoag_Imgs\n",
    "        Photocoag_Masks_train = Photocoag_Masks\n",
    "        Photocoag_Masks_test = Photocoag_Masks\n",
    "        \n",
    "        splits = get_train_test_splits(Healthy_Imgs_SVC,split=num_splits)\n",
    "        Healthy_Imgs_SVC_train, Healthy_Imgs_SVC_test, Healthy_RealMasks_SVC_train, Healthy_RealMasks_SVC_test = train_test_split(Healthy_Imgs_SVC, Healthy_Masks_SVC,splits,test_idx)\n",
    "        Healthy_Imgs_SVC_train_alt, Healthy_Imgs_SVC_test_alt, Healthy_RealMasks_SVC_train_alt, Healthy_RealMasks_SVC_test_alt = train_test_split(Healthy_Imgs_SVC, Healthy_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "        splits = get_train_test_splits(ALZ_Imgs_SVC,split=num_splits)\n",
    "        ALZ_Imgs_SVC_train, ALZ_Imgs_SVC_test, ALZ_RealMasks_SVC_train, ALZ_RealMasks_SVC_test = train_test_split(ALZ_Imgs_SVC, ALZ_Masks_SVC,splits,test_idx)\n",
    "        ALZ_Imgs_SVC_train_alt, ALZ_Imgs_SVC_test_alt, ALZ_RealMasks_SVC_train_alt, ALZ_RealMasks_SVC_test_alt = train_test_split(ALZ_Imgs_SVC, ALZ_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "        splits = get_train_test_splits(AMD_Imgs_SVC,split=num_splits)\n",
    "        AMD_Imgs_SVC_train, AMD_Imgs_SVC_test, AMD_RealMasks_SVC_train, AMD_RealMasks_SVC_test = train_test_split(AMD_Imgs_SVC, AMD_Masks_SVC,splits,test_idx)\n",
    "        AMD_Imgs_SVC_train_alt, AMD_Imgs_SVC_test_alt, AMD_RealMasks_SVC_train_alt, AMD_RealMasks_SVC_test_alt = train_test_split(AMD_Imgs_SVC, AMD_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "        splits = get_train_test_splits(DR_Imgs_SVC,split=num_splits)\n",
    "        DR_Imgs_SVC_train, DR_Imgs_SVC_test, DR_RealMasks_SVC_train, DR_RealMasks_SVC_test = train_test_split(DR_Imgs_SVC, DR_Masks_SVC,splits,test_idx)\n",
    "        DR_Imgs_SVC_train_alt, DR_Imgs_SVC_test_alt, DR_RealMasks_SVC_train_alt, DR_RealMasks_SVC_test_alt = train_test_split(DR_Imgs_SVC, DR_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "        np.random.seed(None)\n",
    "\n",
    "        # (For the test data, this is to bring everything to the appropriate length, it doesn't actually augment it):\n",
    "    #         Photocoag_Imgs_test, Photocoag_Masks_test = f_augment_all_single(Photocoag_Imgs_test, Photocoag_Masks_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=0, N = 1, mode=1)\n",
    "        Healthy_Imgs_SVC_test, Healthy_RealMasks_SVC_test = f_augment_all_single(Healthy_Imgs_SVC_test, Healthy_RealMasks_SVC_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "        ALZ_Imgs_SVC_test, ALZ_RealMasks_SVC_test = f_augment_all_single(ALZ_Imgs_SVC_test, ALZ_RealMasks_SVC_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "        AMD_Imgs_SVC_test, AMD_RealMasks_SVC_test = f_augment_all_single(AMD_Imgs_SVC_test, AMD_RealMasks_SVC_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "        DR_Imgs_SVC_test, DR_RealMasks_SVC_test = f_augment_all_single(DR_Imgs_SVC_test, DR_RealMasks_SVC_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "\n",
    "        _, Healthy_RealMasks_SVC_test_alt = f_augment_all_single(Healthy_Imgs_SVC_test_alt, Healthy_RealMasks_SVC_test_alt, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "        _, ALZ_RealMasks_SVC_test_alt = f_augment_all_single(ALZ_Imgs_SVC_test_alt, ALZ_RealMasks_SVC_test_alt, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "        _, AMD_RealMasks_SVC_test_alt = f_augment_all_single(AMD_Imgs_SVC_test_alt, AMD_RealMasks_SVC_test_alt, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "        _, DR_RealMasks_SVC_test_alt = f_augment_all_single(DR_Imgs_SVC_test_alt, DR_RealMasks_SVC_test_alt, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "\n",
    "        Photocoag_Imgs_test = Photocoag_Imgs_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        Photocoag_Masks_test = Photocoag_Masks_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        Healthy_Imgs_SVC_test = Healthy_Imgs_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        Healthy_RealMasks_SVC_test = Healthy_RealMasks_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        ALZ_Imgs_SVC_test = ALZ_Imgs_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        ALZ_RealMasks_SVC_test = ALZ_RealMasks_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        AMD_Imgs_SVC_test = AMD_Imgs_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        AMD_RealMasks_SVC_test = AMD_RealMasks_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        DR_Imgs_SVC_test = DR_Imgs_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        DR_RealMasks_SVC_test = DR_RealMasks_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "        Healthy_RealMasks_SVC_test_alt = Healthy_RealMasks_SVC_test_alt.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        ALZ_RealMasks_SVC_test_alt = ALZ_RealMasks_SVC_test_alt.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        AMD_RealMasks_SVC_test_alt = AMD_RealMasks_SVC_test_alt.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        DR_RealMasks_SVC_test_alt = DR_RealMasks_SVC_test_alt.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "        Train_Data_list = [Healthy_Imgs_SVC_train, ALZ_Imgs_SVC_train, AMD_Imgs_SVC_train, DR_Imgs_SVC_train, Photocoag_Imgs_train]\n",
    "        Train_Target_Data_list = [Healthy_RealMasks_SVC_train, ALZ_RealMasks_SVC_train, AMD_RealMasks_SVC_train, DR_RealMasks_SVC_train, Photocoag_Masks_train]\n",
    "        Test_Data_list = [Healthy_Imgs_SVC_test, ALZ_Imgs_SVC_test, AMD_Imgs_SVC_test, DR_Imgs_SVC_test, Photocoag_Imgs_test]\n",
    "        Test_Target_Data_list = [Healthy_RealMasks_SVC_test, ALZ_RealMasks_SVC_test, AMD_RealMasks_SVC_test, DR_RealMasks_SVC_test, Photocoag_Masks_test]\n",
    "    #         Dec_aux_list = [Dec_aux_healthy_mask, Dec_aux_ALZ_mask, Dec_aux_AMD_mask, Dec_aux_DR_mask]\n",
    "    #         Dec_name_list = ['Dec_aux_healthy_mask', 'Dec_aux_ALZ_mask', 'Dec_aux_AMD_mask', 'Dec_aux_DR_mask']\n",
    "\n",
    "        Train_Target_Data_list_alt = [Healthy_RealMasks_SVC_train_alt, ALZ_RealMasks_SVC_train_alt, AMD_RealMasks_SVC_train_alt, DR_RealMasks_SVC_train_alt, Photocoag_Masks_train]\n",
    "        Test_Target_Data_list_alt = [Healthy_RealMasks_SVC_test_alt, ALZ_RealMasks_SVC_test_alt, AMD_RealMasks_SVC_test_alt, DR_RealMasks_SVC_test_alt, Photocoag_Masks_test]\n",
    "\n",
    "        ##################################\n",
    "\n",
    "        # args.fac = 2\n",
    "\n",
    "        args.d_attn0 = 128\n",
    "        args.d_attn1 = 256\n",
    "        args.d_attn2 = 512\n",
    "\n",
    "    #         args.d_attn0 = 64\n",
    "    #         args.d_attn1 = 128\n",
    "    #         args.d_attn2 = 256\n",
    "\n",
    "        nhead_base = 8\n",
    "        # nhead = int(nhead_base/args.fac)\n",
    "        # args.nhead = nhead\n",
    "\n",
    "        Enc_base = Unet_Enc_base(nhead_base, args).to(args.device)\n",
    "        Dec_base = Unet_Dec_base(nhead_base, args).to(args.device)\n",
    "        \n",
    "#         #################\n",
    "#         # Load weights\n",
    "# #         load_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\AE\\Photocoag'\n",
    "# #         load_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\PC Pretrain'\n",
    "# #         load_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\PC Pretrain filtered'\n",
    "# #         load_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\PC Pretrain bad_idxs'\n",
    "#         load_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\PC Pretrain two annotations'\n",
    "#         load_folder = load_folder.replace('\\\\', '/')\n",
    "#         date_str = '2024_11_18'\n",
    "# #         load_models_AE(Enc_base, Dec_base, test_idx, load_folder, date_str)\n",
    "#         load_models_AE(Enc_base, Dec_base, 0, load_folder, date_str)\n",
    "#         #################\n",
    "\n",
    "        Train_Data = Train_Data_list[task_idx]\n",
    "        Train_Target_Data = Train_Target_Data_list[task_idx]\n",
    "        Test_Data_aug = Test_Data_list[task_idx]\n",
    "        Test_Target_Data_aug = Test_Target_Data_list[task_idx]\n",
    "\n",
    "        Train_Target_Data_alt = Train_Target_Data_list_alt[task_idx]\n",
    "        Test_Target_Data_aug_alt = Test_Target_Data_list_alt[task_idx]\n",
    "\n",
    "        params_list = list(Enc_base.parameters()) + list(Dec_base.parameters())\n",
    "        lr = 1E-4\n",
    "        optimizer = torch.optim.Adam(params_list, lr=lr, betas=(0.9, 0.999))\n",
    "\n",
    "        one_hot = torch.zeros(args.num_tasks).to(args.device)\n",
    "        one_hot[task_idx] = 1\n",
    "        ones = torch.ones(args.batch_size,1,args.num_tasks).to(args.device)\n",
    "        one_hot_enc = ones*one_hot\n",
    "\n",
    "        #####################Training loop ###########################\n",
    "\n",
    "        mean_epoch_losses = np.zeros(args.num_epochs)\n",
    "        log_mean_epoch_losses = np.zeros(args.num_epochs)\n",
    "\n",
    "        train_dice = np.zeros(args.num_epochs)\n",
    "        test_dice = np.zeros(args.num_epochs)\n",
    "\n",
    "        loss = nn.BCELoss()\n",
    "        # loss_b = Dice_loss()\n",
    "        loss2 = nn.L1Loss()\n",
    "\n",
    "        # Train for a maximum of max_epochs:\n",
    "        for epoch in tqdm(np.arange(args.num_epochs), desc=\"Training progress...\"):\n",
    "            #################################\n",
    "\n",
    "            Train_Target = Train_Target_Data\n",
    "#             Train_Target, one_hot_enc = f_interpolate(Train_Target_Data, Train_Target_Data_alt, args)\n",
    "\n",
    "            if task_names[task_idx] != 'Photocoag':\n",
    "                trans = 50\n",
    "                p_shear = 0.5\n",
    "                p_rot = 0.5\n",
    "                num_aug = args.num_aug\n",
    "            else:\n",
    "                trans = 0\n",
    "                p_shear = 0\n",
    "                p_rot = 0.5\n",
    "                num_aug = 1\n",
    "    #                 Train_Data_aug = Train_Data\n",
    "    #                 Train_Target_Data_aug = Train_Target_Data\n",
    "            Train_Data_aug, Train_Target_Data_aug = f_augment_all_single(Train_Data, Train_Target, p_rot = p_rot, p_flip = 0.5, p_jitter = 0.8, p_shear = p_shear, trans = trans, N = num_aug)\n",
    "\n",
    "            Train_Data_aug = Train_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "            Train_Target_Data_aug = Train_Target_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "            args.num_batches = int(len(Train_Data_aug)/args.N)\n",
    "\n",
    "            #################################\n",
    "\n",
    "            epoch_losses = single_epoch_AE(Train_Data_aug, Train_Target_Data_aug, Enc_base, Dec_base, one_hot_enc, optimizer, loss, loss2, params_list, args)\n",
    "\n",
    "            mean_epoch_loss = np.mean(epoch_losses)\n",
    "            mean_epoch_losses[epoch] = mean_epoch_loss\n",
    "            log_mean_epoch_losses[epoch] = np.log(mean_epoch_loss)\n",
    "\n",
    "            train_dice[epoch] = f_Tot_Dice(Train_Data_aug, Train_Target_Data_aug,  Enc_base, Dec_base, one_hot_enc, args)\n",
    "            test_dice[epoch] = f_Tot_Dice(Test_Data_aug, Test_Target_Data_aug,  Enc_base, Dec_base, one_hot_enc, args)\n",
    "\n",
    "            if np.mod(epoch,args.show_example_epochs) == args.show_example_epochs-1:\n",
    "                print(\"Task:\", task_names[task_idx])\n",
    "                \n",
    "                display_AE(Train_Data_aug, Train_Target_Data_aug, Enc_base, Dec_base, one_hot_enc, args)\n",
    "\n",
    "                fig1, ax = plt.subplots(nrows=1, ncols=1 )\n",
    "                plt.plot(log_mean_epoch_losses[0:epoch])\n",
    "                plt.grid()\n",
    "                plt.show()\n",
    "\n",
    "                colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'aquamarine', 'mediumseagreen']\n",
    "                fig2, ax = plt.subplots(nrows=1, ncols=1 )\n",
    "\n",
    "                plt.plot(train_dice[0:epoch],color=colors[task_idx])\n",
    "    #             plt.grid()\n",
    "    #             plt.show()\n",
    "\n",
    "                plt.plot(test_dice[0:epoch],color=colors[task_idx],linestyle='--')\n",
    "                plt.grid()\n",
    "                plt.show()\n",
    "\n",
    "            if np.mod(epoch,args.save_epochs) == args.save_epochs-1:    \n",
    "\n",
    "                np.savetxt(model_folder + '/' + 'task_idx'+ str(task_idx) + '_mean_epoch_losses' + '_epoch_' + str(epoch+1) + '_' + save_name + '.txt', mean_epoch_losses, fmt='%.2f')\n",
    "                np.savetxt(model_folder + '/' +'task_idx'+ str(task_idx) + '_train_dice' + '_epoch_' + str(epoch+1) + '_' + save_name + '.txt', train_dice, fmt='%.2f')\n",
    "                np.savetxt(model_folder + '/' +'task_idx'+ str(task_idx) + '_test_dice' + '_epoch_' + str(epoch+1) + '_' + save_name + '.txt', test_dice, fmt='%.2f')\n",
    "\n",
    "                fig1.savefig(model_folder + '/' +'task_idx'+ str(task_idx) + '_loss' + save_name + '.png')\n",
    "                fig2.savefig(model_folder + '/' +'task_idx'+ str(task_idx) + '_dice' + save_name + '.png')\n",
    "\n",
    "                save_models(Enc_base, Dec_base, [], [], test_idx, model_folder)\n",
    "\n",
    "        np.savetxt(model_folder + '/' +'task_idx'+ str(task_idx) + '_mean_epoch_losses' + '_epoch_' + str(epoch+1) + '_' + save_name + '.txt', mean_epoch_losses, fmt='%.2f')\n",
    "        np.savetxt(model_folder + '/' +'task_idx'+ str(task_idx) + '_train_dice' + '_epoch_' + str(epoch+1) + '_' + save_name + '.txt', train_dice, fmt='%.2f')\n",
    "        np.savetxt(model_folder + '/' +'task_idx'+ str(task_idx) + '_test_dice' + '_epoch_' + str(epoch+1) + '_' + save_name + '.txt', test_dice, fmt='%.2f')\n",
    "\n",
    "        fig1.savefig(model_folder + '/' +'task_idx'+ str(task_idx) + '_loss' + save_name + '.png')\n",
    "        fig2.savefig(model_folder + '/' +'task_idx'+ str(task_idx) + '_dice' + save_name + '.png')\n",
    "\n",
    "        save_models(Enc_base, Dec_base, [], [], test_idx, model_folder)\n",
    "        \n",
    "        f_display_all(Test_Data_aug, Test_Target_Data_aug, Enc_base, Dec_base, one_hot_enc, splits[test_idx], args, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_idx = 4\n",
    "\n",
    "test_idx = 1\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "splits = get_train_test_splits(Photocoag_Imgs,split=num_splits)\n",
    "Photocoag_Imgs_train, Photocoag_Imgs_test, Photocoag_Masks_train, Photocoag_Masks_test = train_test_split(Photocoag_Imgs, Photocoag_Masks,splits,test_idx)\n",
    "\n",
    "# splits = get_train_test_splits(Healthy_Imgs_SVC,split=num_splits)\n",
    "# Healthy_Imgs_SVC_train, Healthy_Imgs_SVC_test, Healthy_RealMasks_SVC_train, Healthy_RealMasks_SVC_test = train_test_split(Healthy_Imgs_SVC, Healthy_Masks_SVC,splits,test_idx)\n",
    "# Healthy_Imgs_SVC_train_alt, Healthy_Imgs_SVC_test_alt, Healthy_RealMasks_SVC_train_alt, Healthy_RealMasks_SVC_test_alt = train_test_split(Healthy_Imgs_SVC, Healthy_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "# splits = get_train_test_splits(ALZ_Imgs_SVC,split=num_splits)\n",
    "# ALZ_Imgs_SVC_train, ALZ_Imgs_SVC_test, ALZ_RealMasks_SVC_train, ALZ_RealMasks_SVC_test = train_test_split(ALZ_Imgs_SVC, ALZ_Masks_SVC,splits,test_idx)\n",
    "# ALZ_Imgs_SVC_train_alt, ALZ_Imgs_SVC_test_alt, ALZ_RealMasks_SVC_train_alt, ALZ_RealMasks_SVC_test_alt = train_test_split(ALZ_Imgs_SVC, ALZ_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "# splits = get_train_test_splits(AMD_Imgs_SVC,split=num_splits)\n",
    "# AMD_Imgs_SVC_train, AMD_Imgs_SVC_test, AMD_RealMasks_SVC_train, AMD_RealMasks_SVC_test = train_test_split(AMD_Imgs_SVC, AMD_Masks_SVC,splits,test_idx)\n",
    "# AMD_Imgs_SVC_train_alt, AMD_Imgs_SVC_test_alt, AMD_RealMasks_SVC_train_alt, AMD_RealMasks_SVC_test_alt = train_test_split(AMD_Imgs_SVC, AMD_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "# splits = get_train_test_splits(DR_Imgs_SVC,split=num_splits)\n",
    "# DR_Imgs_SVC_train, DR_Imgs_SVC_test, DR_RealMasks_SVC_train, DR_RealMasks_SVC_test = train_test_split(DR_Imgs_SVC, DR_Masks_SVC,splits,test_idx)\n",
    "# DR_Imgs_SVC_train_alt, DR_Imgs_SVC_test_alt, DR_RealMasks_SVC_train_alt, DR_RealMasks_SVC_test_alt = train_test_split(DR_Imgs_SVC, DR_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "# print(Healthy_Imgs_SVC_train.size())\n",
    "# print(Healthy_Imgs_SVC_test.size())\n",
    "print(Photocoag_Imgs_train.size())\n",
    "print(Photocoag_Imgs_test.size())\n",
    "\n",
    "# print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(2024)\n",
    "\n",
    "# splits = get_train_test_splits(Photocoag_Imgs,split=num_splits)\n",
    "# Photocoag_Imgs_train, Photocoag_Imgs_test, Photocoag_Masks_train, Photocoag_Masks_test = train_test_split(Photocoag_Imgs, Photocoag_Masks,splits,test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_tasks = 5*2\n",
    "\n",
    "Enc_base = Unet_Enc_base(nhead_base, args).to(args.device)\n",
    "Dec_base = Unet_Dec_base(nhead_base, args).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_str = '2024_11_6'\n",
    "\n",
    "# # test_idx = 1\n",
    "# # date_str = '2024_10_20'\n",
    "\n",
    "#################\n",
    "# Load weights\n",
    "%cd Y:\\FAZ\\Models\\Models New\\Models New New\\AE\n",
    "load_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\AE' + '\\\\' + task_names[task_idx]\n",
    "load_folder = load_folder.replace('\\\\', '/')\n",
    "load_models_AE(Enc_base, Dec_base, test_idx, load_folder, date_str)\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_Data = Train_Data_list[task_idx]\n",
    "# Train_Target_Data = Train_Target_Data_list[task_idx]\n",
    "\n",
    "Train_Data = Photocoag_Imgs_train\n",
    "Train_Target_Data = Photocoag_Masks_train\n",
    "Test_Data = Photocoag_Imgs_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "Test_Target_Data = Photocoag_Masks_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "Train_Data_aug, Train_Target_Data_aug = f_augment_all_single(Train_Data, Train_Target_Data, p_rot = p_rot, p_flip = 0.5, p_jitter = 0.8, p_shear = p_shear, trans = trans, N = 1, mode=1)\n",
    "\n",
    "# Test_Data_aug = Test_Data_list[task_idx]\n",
    "# Test_Target_Data_aug = Test_Target_Data_list[task_idx]\n",
    "Test_Data_aug = Photocoag_Imgs_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "Test_Target_Data_aug = Photocoag_Masks_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "Train_Data_aug = Train_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "Train_Target_Data_aug = Train_Target_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "one_hot = torch.zeros(args.num_tasks).to(args.device)\n",
    "one_hot[task_idx] = 1\n",
    "ones = torch.ones(args.batch_size,1,args.num_tasks).to(args.device)\n",
    "one_hot_enc = ones*one_hot\n",
    "\n",
    "print(Train_Data_aug.size())\n",
    "print(Test_Data_aug.size())\n",
    "print(Train_Target_Data_aug.size())\n",
    "print(Test_Target_Data_aug.size())\n",
    "\n",
    "Test_Data_aug = rearrange_by_index(Test_Data_aug)\n",
    "Test_Target_Data_aug = rearrange_by_index(Test_Target_Data_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_v = f_display_all(Test_Data, Test_Target_Data, Enc_base, Dec_base, one_hot_enc, splits[test_idx], args, model_folder)\n",
    "print(filt_v)\n",
    "print(len(filt_v))\n",
    "f_Tot_Dice(Test_Data_aug, Test_Target_Data_aug,  Enc_base, Dec_base, one_hot_enc, args)\n",
    "\n",
    "np.savetxt('filt_v_test_idx_' + str(test_idx) + \".csv\", filt_v, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = Photocoag_Imgs[filt_v].unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "# y =  Photocoag_Masks[filt_v].unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "# filt_v = f_display_all(x,y, Enc_base, Dec_base, one_hot_enc, splits[test_idx], args, model_folder)\n",
    "# print(filt_v)\n",
    "# print(len(filt_v))\n",
    "# f_Tot_Dice(Test_Data_aug, Test_Target_Data_aug,  Enc_base, Dec_base, one_hot_enc, args)\n",
    "\n",
    "# # np.savetxt('filt_v_test_idx_' + str(test_idx) + \".csv\", filt_v, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_idxs0 = np.loadtxt('filt_v_test_idx_0.csv', delimiter=',')\n",
    "filt_idxs1 = np.loadtxt('filt_v_test_idx_1.csv', delimiter=',')\n",
    "\n",
    "set1 = set(filt_idxs0)\n",
    "set2 = set(filt_idxs1)\n",
    "print(list(set1.intersection(set2)))\n",
    "\n",
    "print(filt_idxs0)\n",
    "print(filt_idxs1)\n",
    "\n",
    "filt_idxs = np.sort(np.concatenate((filt_idxs0,filt_idxs1)))\n",
    "np.shape(filt_idxs)\n",
    "filt_idxs\n",
    "print(len(filt_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i1 = Photocoag_Imgs[filt_idxs].unsqueeze(1).unsqueeze(2).to(args.device)\n",
    "# i2 = Photocoag_Masks[filt_idxs].unsqueeze(1).unsqueeze(2).to(args.device)\n",
    "\n",
    "# f_display_all(i1, i2, Enc_base, Dec_base, one_hot_enc, splits[1-test_idx], args, model_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_v = f_display_all(Train_Data_aug, Train_Target_Data_aug, Enc_base, Dec_base, one_hot_enc, splits, args, model_folder)\n",
    "print(filt_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable Mask Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleConvNet(nn.Module):\n",
    "#     def __init__(self, sigma, smooth_kernel_size):\n",
    "#         super(SimpleConvNet, self).__init__()\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(1, 16, kernel_size=smooth_kernel_size, padding=smooth_kernel_size // 2, bias=False)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv2d(16, 16, kernel_size=smooth_kernel_size, padding=smooth_kernel_size // 2, bias=False)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.conv3 = nn.Conv2d(16, 1, kernel_size=smooth_kernel_size, padding=smooth_kernel_size // 2, bias=False)\n",
    "\n",
    "#         # Initialize the convolutional layers with standard initialization\n",
    "#         self.initialize_weights()\n",
    "\n",
    "#     def initialize_weights(self):\n",
    "#         \"\"\"Use Xavier initialization and scale the output.\"\"\"\n",
    "#         nn.init.xavier_uniform_(self.conv1.weight)\n",
    "#         self.conv1.weight.data *= 0.1  # Scale down by a factor of 0.1\n",
    "\n",
    "#         nn.init.xavier_uniform_(self.conv2.weight)\n",
    "#         self.conv2.weight.data *= 0.1  # Scale down by a factor of 0.1\n",
    "\n",
    "#         nn.init.xavier_uniform_(self.conv3.weight)\n",
    "#         self.conv3.weight.data *= 0.1  # Scale down by a factor of 0.1\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Apply the first convolution and residual connection\n",
    "#         out1 = self.conv1(x)\n",
    "#         out1_relu = self.relu1(out1)\n",
    "#         out1_residual = out1 + x  # Residual connection\n",
    "\n",
    "#         # Apply the second convolution and residual connection\n",
    "#         out2 = self.conv2(out1_residual)\n",
    "#         out2_relu = self.relu2(out2)\n",
    "#         out2_residual = out2 + out1_residual  # Residual connection\n",
    "\n",
    "#         # Apply the third convolution\n",
    "#         return self.conv3(out2_residual)\n",
    "\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "\n",
    "#         # Define a symmetric 5-layer CNN with padding to preserve input size\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)  # (N, 1, H, W) -> (N, 16, H, W)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1) # (N, 16, H, W) -> (N, 32, H, W)\n",
    "#         self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1) # (N, 32, H, W) -> (N, 64, H, W)\n",
    "#         self.conv4 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1)  # (N, 64, H, W) -> (N, 32, H, W)\n",
    "#         self.conv5 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, padding=1)   # (N, 32, H, W) -> (N, 1, H, W)\n",
    "\n",
    "#         # Activation function\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Pass through the layers with ReLU activations\n",
    "#         x = self.relu(self.conv1(x))  # (N, 16, H, W)\n",
    "#         x = self.relu(self.conv2(x))  # (N, 32, H, W)\n",
    "#         x = self.relu(self.conv3(x))  # (N, 64, H, W)\n",
    "#         x = self.relu(self.conv4(x))  # (N, 32, H, W)\n",
    "#         x = self.conv5(x)              # (N, 1, H, W)\n",
    "#         return x\n",
    "    \n",
    "# class DifferentiableMaskGenerator(nn.Module):\n",
    "#     def __init__(self, sigma=1.0, smooth_kernel_size=5, initial_threshold=5.0):\n",
    "#         super(DifferentiableMaskGenerator, self).__init__()\n",
    "\n",
    "#         # Replace smoothing convolution with SimpleConvNet\n",
    "#         self.smoothing_conv = SimpleConvNet(sigma, smooth_kernel_size)\n",
    "#         self.smoothing_conv1 = nn.Conv2d(1, 1, kernel_size=smooth_kernel_size, padding=smooth_kernel_size // 2, bias=False)\n",
    "#         self.init_smoothing_kernel(sigma)\n",
    "\n",
    "#         # Initialize a learnable threshold parameter\n",
    "#         self.c = nn.Parameter(torch.tensor(1.0))\n",
    "#         self.threshold = nn.Parameter(torch.tensor(initial_threshold))\n",
    "        \n",
    "#         self.Sigmoid = nn.Sigmoid()\n",
    "# #         self.ReLU = nn.ReLU()\n",
    "        \n",
    "#     def init_smoothing_kernel(self, sigma):\n",
    "#         \"\"\"Initialize the smoothing kernel to behave like a Gaussian blur with the given sigma.\"\"\"\n",
    "#         def gaussian_kernel(size, sigma):\n",
    "#             coords = torch.arange(size).float()\n",
    "#             x_grid, y_grid = torch.meshgrid(coords, coords, indexing='ij')\n",
    "#             center = size // 2\n",
    "#             gaussian_kernel = 1 / (2.0 * np.pi * sigma ** 2) * torch.exp(-((x_grid - center) ** 2 + (y_grid - center) ** 2) / (2 * sigma ** 2))\n",
    "#             gaussian_kernel /= gaussian_kernel.sum()\n",
    "#             return gaussian_kernel\n",
    "\n",
    "#         size = self.smoothing_conv1.kernel_size[0]\n",
    "#         with torch.no_grad():\n",
    "#             self.smoothing_conv1.weight.copy_(gaussian_kernel(size, sigma).view(1, 1, size, size))\n",
    "\n",
    "#     def forward(self, c_img):\n",
    "#         # Apply Gaussian smoothing using SimpleConvNet\n",
    "#         smoothed_img = self.smoothing_conv(c_img) + self.smoothing_conv1(c_img) # [N, 1, H, W]\n",
    "\n",
    "#         # Soft thresholding\n",
    "#         soft_mask = self.c / (1 + torch.exp(smoothed_img * 255 - self.threshold))\n",
    "\n",
    "#         return 1 - soft_mask  # Return the opened mask\n",
    "\n",
    "# class StackedMaskGenerator(nn.Module):\n",
    "#     def __init__(self, layer_params):\n",
    "#         super(StackedMaskGenerator, self).__init__()\n",
    "#         self.layers = nn.ModuleList()\n",
    "#         for params in layer_params:\n",
    "#             # Unpack the parameters for each layer\n",
    "#             sigma, smooth_kernel_size, initial_threshold = params\n",
    "#             self.layers.append(DifferentiableMaskGenerator(sigma, smooth_kernel_size, initial_threshold))\n",
    "        \n",
    "#         # Replace dilation convolution with SimpleConvNet\n",
    "#         self.dilation_conv = SimpleConvNet(sigma=1.0, smooth_kernel_size=5)\n",
    "#         self.dilation_conv1 = nn.Conv2d(1, 1, kernel_size=5, padding=2, bias=False)  # Adjust kernel size as needed\n",
    "#         nn.init.ones_(self.dilation_conv1.weight)  # Initialize the weights to ones for dilation effect\n",
    "\n",
    "#         self.scaling_factor1 = nn.Parameter(torch.tensor(1.0))\n",
    "#         self.scaling_factor2 = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "#         self.CNN_enc = CNN()\n",
    "#         self.CNN_dec = CNN()\n",
    "        \n",
    "#         self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#     def forward(self, c_img):\n",
    "#         # Pass the input through all layers\n",
    "#         c_img = self.CNN_enc(c_img)\n",
    "#         output_mask = c_img\n",
    "#         first_layer_output = None  # Variable to store output of the first layer\n",
    "\n",
    "#         for idx, layer in enumerate(self.layers):\n",
    "#             output_mask = layer(output_mask)  # Feed the output of the previous layer into the next\n",
    "#             if idx == 0:\n",
    "#                 first_layer_output = 1 - output_mask  # Store the output of the first layer\n",
    "\n",
    "#         # If there's a second layer, apply the learnable dilation convolution\n",
    "#         if len(self.layers) > 1:\n",
    "#             second_layer_output = 1 - output_mask\n",
    "\n",
    "#             # Use the learnable dilation convolution (now using SimpleConvNet)\n",
    "#             dilated_mask = self.dilation_conv(second_layer_output) + self.dilation_conv1(second_layer_output)  # Dilation using SimpleConvNet\n",
    "\n",
    "# #             # Ensure the mask values are between 0 and 1\n",
    "# #             dilated_mask = 1.0*(dilated_mask > 0)  # Convert to binary\n",
    "#             dilated_mask = self.Sigmoid(dilated_mask * self.scaling_factor1)\n",
    "\n",
    "#             # Multiply the dilated mask with the first layer's output\n",
    "#             output_mask = first_layer_output * dilated_mask\n",
    "        \n",
    "#         output_mask = self.CNN_dec(output_mask)\n",
    "#         output_mask = self.Sigmoid(output_mask * self.scaling_factor2)\n",
    "\n",
    "#         return output_mask  # Return the output mask if only one layer is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameters\n",
    "# num_epochs = 100\n",
    "# learning_rate = 1E-3\n",
    "\n",
    "# layer_params = [\n",
    "#     (1.0, 5, 5.0), # Parameters for layer 1\n",
    "#     (1.0, 5, 5.0)  # Parameters for layer 2\n",
    "# ]\n",
    "# model = StackedMaskGenerator(layer_params).to(args.device)\n",
    "# model.train()  # Set the model to training mode\n",
    "\n",
    "# loss = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train_Data = Train_Data_list[0]\n",
    "# Target_Data = Train_Target_Data_list[0]\n",
    "\n",
    "# Train_Data_aug, Train_Target_Data_aug = f_augment_all_single(Train_Data, Train_Target_Data, p_rot = p_rot, p_flip = 0.5, p_jitter = 0.8, p_shear = p_shear, trans = trans, N = num_aug)\n",
    "\n",
    "# Train_Data_aug = Train_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "# Train_Target_Data_aug = Train_Target_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "# def single_iter(model, optimizer, loss, in_frames, target_frames):\n",
    "\n",
    "#     optimizer.zero_grad() # Zero out gradients\n",
    "\n",
    "#     out_frames = model(in_frames)\n",
    "#     loss_i = loss(out_frames,target_frames)\n",
    "\n",
    "#     loss_i.backward()\n",
    "#     torch.nn.utils.clip_grad_norm_(params_list, 1)\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     return loss_i\n",
    "\n",
    "# def single_epoch(Train_Data, Target_Data, model, optimizer, loss, args):\n",
    "    \n",
    "#     random_idxs = np.arange(len(Train_Data))\n",
    "#     np.random.shuffle(random_idxs)\n",
    "#     train_data_shuffle = Train_Data[random_idxs]\n",
    "#     target_data_shuffle = Target_Data[random_idxs]\n",
    "\n",
    "#     epoch_losses = np.zeros(args.num_batches)\n",
    "\n",
    "#     for it in range(args.num_batches):\n",
    "\n",
    "#         in_frames = train_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "#         target_frames = target_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "        \n",
    "#         in_frames = in_frames.squeeze(2)\n",
    "#         target_frames = target_frames.squeeze(2)\n",
    "\n",
    "#         epoch_losses[it] = single_iter(model, optimizer, loss, in_frames, target_frames)\n",
    "        \n",
    "#     return epoch_losses\n",
    "\n",
    "# # Training loop\n",
    "# mean_epoch_losses = np.zeros(num_epochs)\n",
    "# for epoch in range(num_epochs):\n",
    "\n",
    "#     epoch_losses = single_epoch(Train_Data_aug, Train_Target_Data_aug, model, optimizer, loss, args)\n",
    "    \n",
    "#     mean_epoch_losses[epoch] = np.mean(epoch_losses)\n",
    "    \n",
    "#     plt.plot(mean_epoch_losses)\n",
    "#     plt.show()\n",
    "    \n",
    "#     in_frames = Train_Data_aug[0]\n",
    "#     out_frames = Train_Target_Data_aug[0]\n",
    "#     out_frames = model(in_frames)\n",
    "#     plt.imshow(in_frames + out_frames)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(num_params(Enc_base.Enc1))\n",
    "# print(num_params(Enc_base.ea0))\n",
    "# print(num_params(Enc_base.ea1))\n",
    "# print(num_params(Enc_base.ea2))\n",
    "# print(num_params(Enc_base.ea3))\n",
    "# print(num_params(Enc_base.l1))\n",
    "# print(num_params(Enc_base.l2))\n",
    "# print(num_params(Enc_base.te0u_1))\n",
    "# print(num_params(Enc_base.te0u_2))\n",
    "# print(num_params(Enc_base.te1u_1))\n",
    "# print(num_params(Enc_base.te1u_2))\n",
    "# print(num_params(Enc_base.te2u_1))\n",
    "# print(num_params(Enc_base.te2u_2))\n",
    "# print(num_params(Enc_base.e0))\n",
    "# print(num_params(Enc_base.e0a))\n",
    "# print(num_params(Enc_base.e0b))\n",
    "# print(num_params(Enc_base.e0c))\n",
    "# print(num_params(Enc_base.e1))\n",
    "# print(num_params(Enc_base.e1a))\n",
    "# print(num_params(Enc_base.e1b))\n",
    "# print(num_params(Enc_base.e2))\n",
    "# print(num_params(Enc_base.e2a))\n",
    "# print(num_params(Enc_base.e2b))\n",
    "# print(num_params(Enc_base.C1))\n",
    "# print(num_params(Enc_base.DA1))\n",
    "# print(num_params(Enc_base.DA2))\n",
    "\n",
    "# print(num_params(Enc_base))\n",
    "# print(num_params(Dec_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FAZ Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Y:\\FAZ\\Models\\Models New\\Models New New\\AE\n",
    "\n",
    "filt_idxs0 = np.loadtxt('filt_v_test_idx_0.csv', delimiter=',')\n",
    "filt_idxs1 = np.loadtxt('filt_v_test_idx_1.csv', delimiter=',')\n",
    "\n",
    "filt_idxs = np.sort(np.concatenate((filt_idxs0,filt_idxs1)))\n",
    "\n",
    "L_PC = len(Photocoag_Imgs)\n",
    "bad_idxs = [x for x in range(L_PC) if x not in filt_idxs]\n",
    "\n",
    "print(len(bad_idxs))\n",
    "print(len(filt_idxs))\n",
    "print(L_PC)\n",
    "\n",
    "# Photocoag_Imgs = Photocoag_Imgs[bad_idxs]\n",
    "# Photocoag_Masks = Photocoag_Masks[bad_idxs]\n",
    "Photocoag_Imgs = Photocoag_Imgs[filt_idxs]\n",
    "Photocoag_Masks = Photocoag_Masks[filt_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## jump\n",
    "\n",
    "# FAZ Loop\n",
    "\n",
    "## TRAIN TEST SPLIT\n",
    "\n",
    "%cd Y:\\FAZ\\Models\n",
    "# model_folder = 'Y:/FAZ/Models'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks, 2 annotations, no pretraining'\n",
    "model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\Multitask_PC_pretrain_filtered'\n",
    "\n",
    "# args.training_mode = 1\n",
    "\n",
    "args.num_tasks = 4*1\n",
    "\n",
    "args.num_epochs = 500\n",
    "#     args.show_example_epochs = args.num_tasks\n",
    "args.show_example_epochs = 1\n",
    "args.save_epochs = int(args.num_epochs/5)\n",
    "# args.augment_epochs = 4*args.num_tasks\n",
    "\n",
    "# task_names = ['Healthy', 'ALZ', 'AMD', 'DR']\n",
    "task_names = ['Healthy', 'ALZ', 'AMD', 'DR', 'Photocoag']\n",
    "# task_names = ['Healthy', 'ALZ', 'AMD', 'DR', 'Healthy_AE', 'ALZ_AE', 'AMD_AE', 'DR_AE']\n",
    "\n",
    "epoch_per_task = 1\n",
    "\n",
    "args.num_aug = 2\n",
    "\n",
    "np.random.seed(2024)\n",
    "num_splits = 1 # N-fold cross validation\n",
    "\n",
    "# for test_idx in np.arange(num_splits):\n",
    "for test_idx in [0]:\n",
    "\n",
    "    save_name = '_test_idx_' + str(test_idx)    \n",
    "\n",
    "#     splits = get_train_test_splits(Photocoag_Imgs,split=num_splits)\n",
    "#     Photocoag_Imgs_train, Photocoag_Imgs_test, Photocoag_Masks_train, Photocoag_Masks_test = train_test_split(Photocoag_Imgs, Photocoag_Masks,splits,test_idx)\n",
    "    Photocoag_Imgs_train = Photocoag_Imgs\n",
    "    Photocoag_Masks_train = Photocoag_Masks\n",
    "    Photocoag_Imgs_test = Photocoag_Imgs\n",
    "    Photocoag_Masks_test = Photocoag_Masks\n",
    "    \n",
    "    splits = get_train_test_splits(Healthy_Imgs_SVC,split=num_splits)\n",
    "    Healthy_Imgs_SVC_train, Healthy_Imgs_SVC_test, Healthy_RealMasks_SVC_train, Healthy_RealMasks_SVC_test = train_test_split(Healthy_Imgs_SVC, Healthy_Masks_SVC,splits,test_idx)\n",
    "    Healthy_Imgs_SVC_train_alt, Healthy_Imgs_SVC_test_alt, Healthy_RealMasks_SVC_train_alt, Healthy_RealMasks_SVC_test_alt = train_test_split(Healthy_Imgs_SVC, Healthy_Masks_SVC_alt,splits,test_idx)\n",
    "    \n",
    "    splits = get_train_test_splits(ALZ_Imgs_SVC,split=num_splits)\n",
    "    ALZ_Imgs_SVC_train, ALZ_Imgs_SVC_test, ALZ_RealMasks_SVC_train, ALZ_RealMasks_SVC_test = train_test_split(ALZ_Imgs_SVC, ALZ_Masks_SVC,splits,test_idx)\n",
    "    ALZ_Imgs_SVC_train_alt, ALZ_Imgs_SVC_test_alt, ALZ_RealMasks_SVC_train_alt, ALZ_RealMasks_SVC_test_alt = train_test_split(ALZ_Imgs_SVC, ALZ_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "    splits = get_train_test_splits(AMD_Imgs_SVC,split=num_splits)\n",
    "    AMD_Imgs_SVC_train, AMD_Imgs_SVC_test, AMD_RealMasks_SVC_train, AMD_RealMasks_SVC_test = train_test_split(AMD_Imgs_SVC, AMD_Masks_SVC,splits,test_idx)\n",
    "    AMD_Imgs_SVC_train_alt, AMD_Imgs_SVC_test_alt, AMD_RealMasks_SVC_train_alt, AMD_RealMasks_SVC_test_alt = train_test_split(AMD_Imgs_SVC, AMD_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "    splits = get_train_test_splits(DR_Imgs_SVC,split=num_splits)\n",
    "    DR_Imgs_SVC_train, DR_Imgs_SVC_test, DR_RealMasks_SVC_train, DR_RealMasks_SVC_test = train_test_split(DR_Imgs_SVC, DR_Masks_SVC,splits,test_idx)\n",
    "    DR_Imgs_SVC_train_alt, DR_Imgs_SVC_test_alt, DR_RealMasks_SVC_train_alt, DR_RealMasks_SVC_test_alt = train_test_split(DR_Imgs_SVC, DR_Masks_SVC_alt,splits,test_idx)\n",
    "\n",
    "    np.random.seed(None)\n",
    "\n",
    "#     Photocoag_Imgs_test, Photocoag_Masks_test = f_augment_all_single(Photocoag_Imgs_test, Photocoag_Masks_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=0, N = 2, mode=1)\n",
    "    Healthy_Imgs_SVC_test, Healthy_RealMasks_SVC_test = f_augment_all_single(Healthy_Imgs_SVC_test, Healthy_RealMasks_SVC_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "    ALZ_Imgs_SVC_test, ALZ_RealMasks_SVC_test = f_augment_all_single(ALZ_Imgs_SVC_test, ALZ_RealMasks_SVC_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "    AMD_Imgs_SVC_test, AMD_RealMasks_SVC_test = f_augment_all_single(AMD_Imgs_SVC_test, AMD_RealMasks_SVC_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "    DR_Imgs_SVC_test, DR_RealMasks_SVC_test = f_augment_all_single(DR_Imgs_SVC_test, DR_RealMasks_SVC_test, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "\n",
    "    _, Healthy_RealMasks_SVC_test_alt = f_augment_all_single(Healthy_Imgs_SVC_test_alt, Healthy_RealMasks_SVC_test_alt, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "    _, ALZ_RealMasks_SVC_test_alt = f_augment_all_single(ALZ_Imgs_SVC_test_alt, ALZ_RealMasks_SVC_test_alt, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "    _, AMD_RealMasks_SVC_test_alt = f_augment_all_single(AMD_Imgs_SVC_test_alt, AMD_RealMasks_SVC_test_alt, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)\n",
    "    _, DR_RealMasks_SVC_test_alt = f_augment_all_single(DR_Imgs_SVC_test_alt, DR_RealMasks_SVC_test_alt, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, trans=50, N = args.num_aug, mode=1)    \n",
    "    \n",
    "    Photocoag_Imgs_test = Photocoag_Imgs_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    Photocoag_Masks_test = Photocoag_Masks_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    Healthy_Imgs_SVC_test = Healthy_Imgs_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    Healthy_RealMasks_SVC_test = Healthy_RealMasks_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    ALZ_Imgs_SVC_test = ALZ_Imgs_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    ALZ_RealMasks_SVC_test = ALZ_RealMasks_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    AMD_Imgs_SVC_test = AMD_Imgs_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    AMD_RealMasks_SVC_test = AMD_RealMasks_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    DR_Imgs_SVC_test = DR_Imgs_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    DR_RealMasks_SVC_test = DR_RealMasks_SVC_test.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "    Healthy_RealMasks_SVC_test_alt = Healthy_RealMasks_SVC_test_alt.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    ALZ_RealMasks_SVC_test_alt = ALZ_RealMasks_SVC_test_alt.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    AMD_RealMasks_SVC_test_alt = AMD_RealMasks_SVC_test_alt.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    DR_RealMasks_SVC_test_alt = DR_RealMasks_SVC_test_alt.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "    \n",
    "    ##################################\n",
    "\n",
    "    ## DEFINE MODELS\n",
    "\n",
    "    args.d_attn0 = 128\n",
    "    args.d_attn1 = 256\n",
    "    args.d_attn2 = 512\n",
    "\n",
    "#     args.d_attn0 = 64\n",
    "#     args.d_attn1 = 128\n",
    "#     args.d_attn2 = 256\n",
    "    \n",
    "    args.fac = 1 # Relative size of base and aux decoders\n",
    "\n",
    "    nhead_base = 8\n",
    "    nhead = int(nhead_base/args.fac)\n",
    "    args.nhead = nhead\n",
    "\n",
    "    #################\n",
    "    # Define model\n",
    "    Enc_base = Unet_Enc_base(nhead_base, args).to(args.device)\n",
    "    Dec_base = Unet_Dec_base(nhead_base, args).to(args.device)\n",
    "\n",
    "    args.d_attn0 = int(args.d_attn0/args.fac)\n",
    "    args.d_attn1 = int(args.d_attn1/args.fac)\n",
    "    args.d_attn2 = int(args.d_attn2/args.fac)\n",
    "\n",
    "    Dec_aux_healthy_mask = Unet_Dec_v3(nhead, args).to(args.device)\n",
    "    Dec_aux_ALZ_mask = Unet_Dec_v3(nhead, args).to(args.device)\n",
    "    Dec_aux_AMD_mask = Unet_Dec_v3(nhead, args).to(args.device)\n",
    "    Dec_aux_DR_mask = Unet_Dec_v3(nhead, args).to(args.device)\n",
    "    #     Dec_aux_Photocoag_mask = Unet_Dec_v3(nhead, args).to(args.device)\n",
    "\n",
    "    Dec_aux_healthy_mask_alt = Unet_Dec_v3(nhead, args).to(args.device)\n",
    "    Dec_aux_ALZ_mask_alt = Unet_Dec_v3(nhead, args).to(args.device)\n",
    "    Dec_aux_AMD_mask_alt = Unet_Dec_v3(nhead, args).to(args.device)\n",
    "    Dec_aux_DR_mask_alt = Unet_Dec_v3(nhead, args).to(args.device)\n",
    "    \n",
    "    ###############################################################\n",
    "\n",
    "    ## Four Tasks (photocoag only)\n",
    "    Train_Data_list = [Photocoag_Imgs_train, Photocoag_Imgs_train, Photocoag_Imgs_train, Photocoag_Imgs_train]\n",
    "    Train_Target_Data_list = [Photocoag_Masks_train, Photocoag_Masks_train, Photocoag_Masks_train, Photocoag_Masks_train]\n",
    "    Test_Data_list = [Photocoag_Imgs_test, Photocoag_Imgs_test, Photocoag_Imgs_test, Photocoag_Imgs_test]\n",
    "    Test_Target_Data_list = [Photocoag_Masks_test, Photocoag_Masks_test, Photocoag_Masks_test, Photocoag_Masks_test]\n",
    "    Dec_aux_list = [Dec_aux_healthy_mask, Dec_aux_ALZ_mask, Dec_aux_AMD_mask, Dec_aux_DR_mask]\n",
    "    Dec_name_list = ['Dec_aux_healthy_mask', 'Dec_aux_ALZ_mask', 'Dec_aux_AMD_mask', 'Dec_aux_DR_mask']\n",
    "\n",
    "#     ## Four Tasks (masks)\n",
    "#     Train_Data_list = [Healthy_Imgs_SVC_train, ALZ_Imgs_SVC_train, AMD_Imgs_SVC_train, DR_Imgs_SVC_train]\n",
    "#     Train_Target_Data_list = [Healthy_RealMasks_SVC_train, ALZ_RealMasks_SVC_train, AMD_RealMasks_SVC_train, DR_RealMasks_SVC_train]\n",
    "#     Test_Data_list = [Healthy_Imgs_SVC_test, ALZ_Imgs_SVC_test, AMD_Imgs_SVC_test, DR_Imgs_SVC_test]\n",
    "#     Test_Target_Data_list = [Healthy_RealMasks_SVC_test, ALZ_RealMasks_SVC_test, AMD_RealMasks_SVC_test, DR_RealMasks_SVC_test]\n",
    "#     Dec_aux_list = [Dec_aux_healthy_mask, Dec_aux_ALZ_mask, Dec_aux_AMD_mask, Dec_aux_DR_mask]\n",
    "#     Dec_name_list = ['Dec_aux_healthy_mask', 'Dec_aux_ALZ_mask', 'Dec_aux_AMD_mask', 'Dec_aux_DR_mask']\n",
    "\n",
    "    Train_Target_Data_list_alt = [Healthy_RealMasks_SVC_train_alt, ALZ_RealMasks_SVC_train_alt, AMD_RealMasks_SVC_train_alt, DR_RealMasks_SVC_train_alt, Photocoag_Masks_train]\n",
    "    Test_Target_Data_list_alt = [Healthy_RealMasks_SVC_test_alt, ALZ_RealMasks_SVC_test_alt, AMD_RealMasks_SVC_test_alt, DR_RealMasks_SVC_test_alt, Photocoag_Masks_test]\n",
    "    \n",
    "#         ## Five Tasks (masks)\n",
    "#         Train_Data_list = [Photocoag_Imgs_train, Healthy_Imgs_SVC_train, ALZ_Imgs_SVC_train, AMD_Imgs_SVC_train, DR_Imgs_SVC_train]\n",
    "#         Train_Target_Data_list = [Photocoag_Masks_train, Healthy_RealMasks_SVC_train, ALZ_RealMasks_SVC_train, AMD_RealMasks_SVC_train, DR_RealMasks_SVC_train]\n",
    "#         Test_Data_list = [Photocoag_Imgs_test, Healthy_Imgs_SVC_test, ALZ_Imgs_SVC_test, AMD_Imgs_SVC_test, DR_Imgs_SVC_test]\n",
    "#         Test_Target_Data_list = [Photocoag_Masks_test, Healthy_RealMasks_SVC_test, ALZ_RealMasks_SVC_test, AMD_RealMasks_SVC_test, DR_RealMasks_SVC_test]\n",
    "#         Dec_aux_list = [Dec_aux_Photocoag_mask, Dec_aux_healthy_mask, Dec_aux_ALZ_mask, Dec_aux_AMD_mask, Dec_aux_DR_mask]\n",
    "#         Dec_name_list = ['Dec_aux_Photocoag_mask', 'Dec_aux_healthy_mask', 'Dec_aux_ALZ_mask', 'Dec_aux_AMD_mask', 'Dec_aux_DR_mask']\n",
    "\n",
    "#     # Eight Tasks (masks)\n",
    "#     Train_Data_list = [Healthy_Imgs_SVC_train, ALZ_Imgs_SVC_train, AMD_Imgs_SVC_train, DR_Imgs_SVC_train, Healthy_Imgs_SVC, ALZ_Imgs_SVC, AMD_Imgs_SVC, DR_Imgs_SVC]\n",
    "#     Train_Target_Data_list = [Healthy_RealMasks_SVC_train, ALZ_RealMasks_SVC_train, AMD_RealMasks_SVC_train, DR_RealMasks_SVC_train, Healthy_Masks_SVC_alt, ALZ_Masks_SVC_alt, AMD_Masks_SVC_alt, DR_Masks_SVC_alt]\n",
    "#     Test_Data_list = [Healthy_Imgs_SVC_test, ALZ_Imgs_SVC_test, AMD_Imgs_SVC_test, DR_Imgs_SVC_test, 0*Healthy_Imgs_SVC_test, 0*ALZ_Imgs_SVC_test, 0*AMD_Imgs_SVC_test, 0*DR_Imgs_SVC_test]\n",
    "#     Test_Target_Data_list = [Healthy_RealMasks_SVC_test, ALZ_RealMasks_SVC_test, AMD_RealMasks_SVC_test, DR_RealMasks_SVC_test, 0*Healthy_RealMasks_SVC_test, 0*ALZ_RealMasks_SVC_test, 0*AMD_RealMasks_SVC_test, 0*DR_RealMasks_SVC_test]\n",
    "#     Dec_aux_list = [Dec_aux_healthy_mask, Dec_aux_ALZ_mask, Dec_aux_AMD_mask, Dec_aux_DR_mask, Dec_aux_healthy_mask_alt, Dec_aux_ALZ_mask_alt, Dec_aux_AMD_mask_alt, Dec_aux_DR_mask_alt]\n",
    "#     Dec_name_list = ['Dec_aux_healthy_mask', 'Dec_aux_ALZ_mask', 'Dec_aux_AMD_mask', 'Dec_aux_DR_mask', 'Dec_aux_healthy_mask_alt', 'Dec_aux_ALZ_mask_alt', 'Dec_aux_AMD_mask_alt', 'Dec_aux_DR_mask_alt']\n",
    "\n",
    "    #################\n",
    "    # Load weights\n",
    "#     load_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks with PC pretraining'\n",
    "#     load_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\PC Pretrain all (800 epochs)'\n",
    "    load_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\Multitask_PC_pretrain_filtered_bad'\n",
    "    load_folder = load_folder.replace('\\\\', '/')\n",
    "    date_str = '2024_11_20'\n",
    "    load_models_FAZ(Enc_base, Dec_base, Dec_aux_list, Dec_name_list, test_idx, load_folder, date_str)\n",
    "    #################\n",
    "    \n",
    "    sz_min = np.inf\n",
    "    for i in np.arange(len(Train_Data_list)):\n",
    "        sz_i = Train_Data_list[i].size()\n",
    "        if sz_i[0] < sz_min:\n",
    "            sz_min = sz_i[0]\n",
    "    args.sz_min = sz_min*args.num_aug\n",
    "\n",
    "    params_list = list(Enc_base.parameters()) + list(Dec_base.parameters())\n",
    "    optimizers = []\n",
    "    lr = 1E-4\n",
    "    for i in np.arange(len(Dec_aux_list)):\n",
    "        params_list_i = params_list + list(Dec_aux_list[i].parameters())\n",
    "        optimizer_i = torch.optim.Adam(params_list_i, lr=lr, betas=(0.9, 0.999))\n",
    "        optimizers.append(optimizer_i)\n",
    "\n",
    "    one_hot_enc_v = []\n",
    "    for task_idx in np.arange(args.num_tasks):\n",
    "        one_hot = torch.zeros(args.num_tasks).to(args.device)\n",
    "        one_hot[task_idx] = 1\n",
    "        ones = torch.ones(args.batch_size,1,args.num_tasks).to(args.device)\n",
    "        one_hot_enc = ones*one_hot\n",
    "\n",
    "        one_hot_enc_v.append(one_hot_enc)\n",
    "\n",
    "    #####################Training loop ###########################\n",
    "\n",
    "    mean_epoch_losses = np.zeros((args.num_tasks,int(args.num_epochs/args.num_tasks)))\n",
    "    log_mean_epoch_losses = np.zeros((args.num_tasks,int(args.num_epochs/args.num_tasks)))\n",
    "\n",
    "    train_dice = np.zeros((args.num_tasks,int(args.num_epochs/args.num_tasks)))\n",
    "    test_dice = np.zeros((args.num_tasks,int(args.num_epochs/args.num_tasks)))\n",
    "\n",
    "    loss = nn.BCELoss()\n",
    "    # loss_b = Dice_loss()\n",
    "    loss2 = nn.L1Loss()\n",
    "\n",
    "    # Train for a maximum of max_epochs:\n",
    "    for epoch in tqdm(np.arange(args.num_epochs), desc=\"Training progress...\"):\n",
    "\n",
    "        #################################\n",
    "    #     task_idx = np.random.choice(np.arange(args.num_tasks))\n",
    "        task_idx = int(np.floor(np.mod(epoch,epoch_per_task*args.num_tasks)/epoch_per_task))\n",
    "        print(task_idx)\n",
    "\n",
    "    #     if task_idx < (args.num_tasks/2):\n",
    "    #         loss2 = loss_b\n",
    "    #     else:\n",
    "    #         loss2 = loss\n",
    "\n",
    "        Dec_i = Dec_aux_list[task_idx]\n",
    "        params_list_i = params_list + list(Dec_aux_list[task_idx].parameters())\n",
    "        optimizer = optimizers[task_idx]\n",
    "#         one_hot_enc = one_hot_enc_v[task_idx]\n",
    "\n",
    "        Train_Data = Train_Data_list[task_idx]\n",
    "        Train_Target_Data = Train_Target_Data_list[task_idx]\n",
    "        Test_Data_aug = Test_Data_list[task_idx]\n",
    "        Test_Target_Data_aug = Test_Target_Data_list[task_idx]\n",
    "        \n",
    "        Train_Target_Data_alt = Train_Target_Data_list_alt[task_idx]\n",
    "        Test_Target_Data_aug_alt = Test_Target_Data_list_alt[task_idx]\n",
    "        \n",
    "        Train_Target = Train_Target_Data\n",
    "#         Train_Target, one_hot_enc = f_interpolate(Train_Target_Data, Train_Target_Data_alt, args)\n",
    "\n",
    "        # Params for Photocoag data augmentation\n",
    "        num_aug = args.num_aug\n",
    "        trans = 0\n",
    "        p_shear = 0\n",
    "        p_rot = 0.5\n",
    "        \n",
    "#         # Params for FAZ data augmention:\n",
    "#         num_aug = args.num_aug\n",
    "#         trans = 50\n",
    "#         p_shear = 0.5\n",
    "#         p_rot = 0.5\n",
    "        \n",
    "        Train_Data_aug, Train_Target_Data_aug = f_augment_all_single(Train_Data, Train_Target, p_rot = p_rot, p_flip = 0.5, p_jitter = 0.8, p_shear = p_shear, trans = trans, N = num_aug)\n",
    "\n",
    "        Train_Data_aug = Train_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "        Train_Target_Data_aug = Train_Target_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "        args.num_batches = int(len(Train_Data_aug)/args.N)\n",
    "\n",
    "        #################################\n",
    "\n",
    "        epoch_losses = single_epoch_FAZ(Train_Data_aug, Train_Target_Data_aug, Enc_base, Dec_base, Dec_i, one_hot_enc, optimizer, loss, loss2, args, params_list_i)\n",
    "        mean_epoch_loss = np.mean(epoch_losses)\n",
    "        mean_epoch_losses[task_idx,int(epoch/args.num_tasks)] = mean_epoch_loss\n",
    "        log_mean_epoch_losses[task_idx,int(epoch/args.num_tasks)] = np.log(mean_epoch_loss)\n",
    "\n",
    "        if task_idx < 4:\n",
    "            train_dice[task_idx,int(epoch/args.num_tasks)] = f_Tot_Dice(Train_Data_aug, Train_Target_Data_aug, Enc_base, Dec_base, one_hot_enc, args)\n",
    "            test_dice[task_idx,int(epoch/args.num_tasks)] = f_Tot_Dice(Test_Data_aug, Test_Target_Data_aug, Enc_base, Dec_base, one_hot_enc, args)\n",
    "\n",
    "            if np.mod(epoch,args.show_example_epochs) == 0:\n",
    "        #         if np.mod(epoch,args.show_example_epochs) == args.show_example_epochs - 1:\n",
    "                display_FAZ(Train_Data_aug, Train_Target_Data_aug, Enc_base, Dec_base, one_hot_enc, args)\n",
    "\n",
    "                fig1, ax = plt.subplots(nrows=1, ncols=1 )\n",
    "                for task in np.arange(args.num_tasks):\n",
    "        #             plt.plot(mean_epoch_losses[task,0:int(epoch/args.num_tasks)])\n",
    "                    plt.plot(log_mean_epoch_losses[task,0:int(epoch/args.num_tasks)])\n",
    "                plt.grid()\n",
    "                plt.show()\n",
    "\n",
    "                colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'aquamarine', 'mediumseagreen']\n",
    "                fig2, ax = plt.subplots(nrows=1, ncols=1 )\n",
    "                for i in np.arange(len(train_dice)):\n",
    "                    plt.plot(train_dice[i,0:int(epoch/args.num_tasks)+1],color=colors[i])\n",
    "    #             plt.grid()\n",
    "    #             plt.show()\n",
    "    #             fig3, ax = plt.subplots(nrows=1, ncols=1 )\n",
    "                for i in np.arange(4):\n",
    "                    plt.plot(test_dice[i,0:int(epoch/args.num_tasks)+1],color=colors[i],linestyle='--')\n",
    "                plt.grid()\n",
    "                plt.show()\n",
    "\n",
    "            if np.mod(epoch,args.save_epochs) == args.save_epochs-1:    \n",
    "\n",
    "                np.savetxt('mean_epoch_losses' + '_epoch_' + str(epoch) + '_' + save_name + '.txt', mean_epoch_losses, fmt='%.2f')\n",
    "                np.savetxt('train_dice' + '_epoch_' + str(epoch) + '_' + save_name + '.txt', train_dice, fmt='%.2f')\n",
    "                np.savetxt('test_dice' + '_epoch_' + str(epoch) + '_' + save_name + '.txt', test_dice, fmt='%.2f')\n",
    "\n",
    "                fig1.savefig('loss' + save_name + '.png')\n",
    "                fig2.savefig('dice' + save_name + '.png')\n",
    "\n",
    "                save_models(Enc_base, Dec_base, Dec_aux_list, Dec_name_list, test_idx, model_folder)\n",
    "\n",
    "    np.savetxt(model_folder + '/' + 'mean_epoch_losses' + '_epoch_' + str(epoch) + '_' + save_name + '.txt', mean_epoch_losses, fmt='%.2f')\n",
    "    np.savetxt(model_folder + '/' + 'train_dice' + '_epoch_' + str(epoch) + '_' + save_name + '.txt', train_dice, fmt='%.2f')\n",
    "    np.savetxt(model_folder + '/' + 'test_dice' + '_epoch_' + str(epoch) + '_' + save_name + '.txt', test_dice, fmt='%.2f')\n",
    "\n",
    "    fig1.savefig('loss' + save_name + '.png')\n",
    "    fig2.savefig('dice' + save_name + '.png')\n",
    "\n",
    "    save_models(Enc_base, Dec_base, Dec_aux_list, Dec_name_list, test_idx, model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_v = f_display_all(Test_Data_aug, Test_Target_Data_aug, Enc_base, Dec_base, one_hot_enc, args, model_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data = Test_Data_aug\n",
    "# Target_Data = 1.*(Test_Target_Data_aug > 0.5)\n",
    "\n",
    "# num_batches = int(len(Data)/args.batch_size)\n",
    "\n",
    "# dice_tot = 0\n",
    "# for it in np.arange(num_batches):\n",
    "\n",
    "#     in_frames = Data[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "#     target_frames = Target_Data[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = Enc_base(in_frames, one_hot_enc)\n",
    "#         rec_frames, _, _, _, _, _ = Dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=4)\n",
    "\n",
    "# #     rec_frames = 1.*(rec_frames > 0.5)\n",
    "\n",
    "#     for i in np.arange(args.batch_size):\n",
    "#         in_frame =  in_frames.detach().cpu().numpy().squeeze()[i]\n",
    "#         target_frame = target_frames.detach().cpu().numpy().squeeze()[i]\n",
    "#         rec_frame = rec_frames.detach().cpu().numpy().squeeze()[i]\n",
    "        \n",
    "#         plt.imshow(in_frame)\n",
    "#         plt.show()\n",
    "#         plt.imshow(target_frame)\n",
    "#         plt.show()\n",
    "#         plt.imshow(rec_frame)\n",
    "#         plt.show()\n",
    "\n",
    "#         dice_i, _ = f_dice_jac(target_frame,rec_frame)\n",
    "#         print(dice_i)\n",
    "#         dice_tot += dice_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_idx = 0\n",
    "\n",
    "# Dec_i = Dec_aux_list[task_idx]\n",
    "# params_list_i = params_list + list(Dec_aux_list[task_idx].parameters())\n",
    "# optimizer = optimizers[task_idx]\n",
    "# one_hot_enc = one_hot_enc_v[task_idx]\n",
    "\n",
    "# Train_Data = Train_Data_list[task_idx]\n",
    "# Train_Target_Data = Train_Target_Data_list[task_idx]\n",
    "# Test_Data_aug = Test_Data_list[task_idx]\n",
    "# Test_Target_Data_aug = Test_Target_Data_list[task_idx]\n",
    "\n",
    "# if Dec_name_list[task_idx] != 'Dec_aux_Photocoag_mask' and Dec_name_list[task_idx] != 'Dec_aux_Photocoag_auto':\n",
    "#     num_aug = args.num_aug\n",
    "#     trans = 50\n",
    "#     p_shear = 0.5\n",
    "#     p_rot = 0.5\n",
    "# else:\n",
    "#     num_aug = 2\n",
    "#     trans = 0\n",
    "#     p_shear = 0\n",
    "#     p_rot = 0\n",
    "# Train_Data_aug, Train_Target_Data_aug = f_augment_all_single(Train_Data, Train_Target_Data, p_rot = p_rot, p_flip = 0.5, p_jitter = 0.8, p_shear = p_shear, trans = trans, N = num_aug)\n",
    "\n",
    "# Train_Data_aug = Train_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "# Train_Target_Data_aug = Train_Target_Data_aug.unsqueeze(1).unsqueeze(1).to(args.device)\n",
    "\n",
    "# args.num_batches = int(len(Train_Data_aug)/args.N)\n",
    "\n",
    "# #################################\n",
    "\n",
    "# # epoch_losses = single_epoch_FAZ(Train_Data_aug, Train_Target_Data_aug, Enc_base, Dec_base, Dec_i, one_hot_enc, optimizer, loss, loss2, args, params_list_i)\n",
    "# # mean_epoch_loss = np.mean(epoch_losses)\n",
    "# # mean_epoch_losses[task_idx,int(epoch/args.num_tasks)] = mean_epoch_loss\n",
    "# # log_mean_epoch_losses[task_idx,int(epoch/args.num_tasks)] = np.log(mean_epoch_loss)\n",
    "\n",
    "# # train_dice[task_idx,int(epoch/args.num_tasks)] = f_Tot_Dice(Train_Data_aug, Train_Target_Data_aug, one_hot_enc, args)\n",
    "# # test_dice[task_idx,int(epoch/args.num_tasks)] = f_Tot_Dice(Test_Data_aug, Test_Target_Data_aug, one_hot_enc, args)\n",
    "\n",
    "# display_FAZ(Train_Data_aug, Train_Target_Data_aug, Enc_base, Dec_base, one_hot_enc, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = Train_Data_aug\n",
    "# target_data = Train_Target_Data_aug\n",
    "\n",
    "# random_idxs = np.arange(len(train_data))\n",
    "# np.random.shuffle(random_idxs)\n",
    "# train_data_shuffle = train_data[random_idxs]\n",
    "# target_data_shuffle = target_data[random_idxs]\n",
    "# it = 0\n",
    "# in_frames = train_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "# target_frames = target_data_shuffle[it*args.batch_size:(it+1)*args.batch_size,:,:,:,:]\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz = Enc_base(in_frames, one_hot_enc)\n",
    "# #         rec_frames, feats1n_base, feats2n_base, feats4n_base, feats5n_base = dec_base(feats1u, feats2u, feats4u_f, feats5_f, x4_sz, one_hot_enc)\n",
    "# #         rec_frames_aux, feats1n_aux, feats2n_aux, feats4n_aux, feats5n_aux      = dec_aux(feats1u, feats2u, feats4u_f, feats5_f, x4_sz)\n",
    "\n",
    "#     rec_frames_base_4, _, _, _, _, _ = Dec_base(feats0u, feats1u, feats2u, feats3u_f, feats4_f, x4_sz, one_hot_enc, mode=4)\n",
    "\n",
    "\n",
    "# plt.imshow(in_frames[i,0,0,:,:].detach().cpu().numpy())\n",
    "# plt.show()\n",
    "# plt.imshow(target_frames[i,0,0,:,:].detach().cpu().numpy())\n",
    "# plt.show()\n",
    "# plt.imshow(rec_frames_base_4[i,0,0,:,:].detach().cpu().numpy())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "##################################\n",
    "\n",
    "def txt_to_array(txt_name):\n",
    "    text_file = open(txt_name, \"r\")\n",
    "    lines = text_file.read().split('\\n')[0:-1]\n",
    "    S = []\n",
    "    for i in range(len(lines)):\n",
    "        s = '[' + lines[i] + ']'\n",
    "        s2 = re.sub(\"\\s+\", \",\", s.strip())\n",
    "        s3 = eval(s2)\n",
    "        S.append(s3)\n",
    "    return np.array(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# ##################################\n",
    "\n",
    "# # %cd Y:/FAZ/Models/Aya_with_photocoag_without_inner_losses\n",
    "# # %cd Y:/FAZ/Models/Aya, without photocoag, no inner losses\n",
    "\n",
    "# # epoch = 599\n",
    "# epoch = 499\n",
    "# colors = ['b', 'g', 'r', 'c', 'y']\n",
    "# # labels = ['Healthy', 'ALZ', 'AMD', 'DR']\n",
    "# labels = ['Photocoag', 'Healthy', 'ALZ', 'AMD', 'DR']\n",
    "\n",
    "# task_idx = 0\n",
    "# model_folder = 'Y:/FAZ/Models/AE2/' + task_names[task_idx]\n",
    "\n",
    "# ##################################\n",
    "\n",
    "# def txt_to_array(txt_name):\n",
    "#     text_file = open(txt_name, \"r\")\n",
    "#     lines = text_file.read().split('\\n')[0:-1]\n",
    "#     S = []\n",
    "#     for i in range(len(lines)):\n",
    "#         s = '[' + lines[i] + ']'\n",
    "#         s2 = re.sub(\"\\s+\", \",\", s.strip())\n",
    "#         s3 = eval(s2)\n",
    "#         S.append(s3)\n",
    "#     return np.array(S)\n",
    "\n",
    "# ##########################\n",
    "\n",
    "# train_dice = 0\n",
    "# for test_idx in range(4):\n",
    "# #     epoch = args.num_epochs-1\n",
    "#     txt_name = 'task_idx' + str(task_idx) + 'train_dice' + '_epoch_' + str(epoch) + '__' + 'test_idx_' + str(test_idx) + '.txt'\n",
    "#     train_dice += txt_to_array(txt_name)\n",
    "# train_dice /= 4\n",
    "\n",
    "# for i in range(len(train_dice)):\n",
    "#     label = labels[i]\n",
    "#     plt.plot(train_dice[i],color=colors[i],label=label)\n",
    "# plt.grid()\n",
    "# plt.title('Train Dice')\n",
    "# # plt.ylim((0.85,1))\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# ##########################\n",
    "\n",
    "# test_dice = 0\n",
    "# for test_idx in range(4):\n",
    "# #     epoch = args.num_epochs-1\n",
    "#     txt_name = 'test_dice' + '_epoch_' + str(epoch) + '__' + 'test_idx_' + str(test_idx) + '.txt'\n",
    "#     test_dice += txt_to_array(txt_name)\n",
    "# test_dice /= 4\n",
    "\n",
    "# for i in range(len(test_dice)):\n",
    "#     label = labels[i]\n",
    "#     plt.plot(test_dice[i],color=colors[i],label=label)\n",
    "# plt.grid()\n",
    "# plt.title('Test Dice')\n",
    "# # plt.ylim((0.7,1))\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# test_dice_final = np.round(np.mean(test_dice[:,-100:],axis=1)*100,1)\n",
    "\n",
    "# print('Dice Index:')\n",
    "# for i in range(len(test_dice_final)):\n",
    "#     print(labels[i] + ': ' + str(test_dice_final[i]) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task_idx = 0\n",
    "splits = [0, 1]\n",
    "# splits = [0]\n",
    "final_epoch = 1000\n",
    "N_epochs = final_epoch\n",
    "# N_epochs = 100\n",
    "colors = ['b', 'g', 'r', 'c', 'y']\n",
    "task_names = ['Healthy', 'ALZ', 'AMD', 'DR', 'Photocoag']\n",
    "test_names = ['split 1', 'split 2']\n",
    "N_splits = len(splits)\n",
    "N_avg_epochs = 100\n",
    "\n",
    "# model_folder = 'Y:/FAZ/Models/Models New/Models New New/AE'\n",
    "# model_folder = 'Y:/FAZ/Models/Models New/Models New New/AE_with_2_annotations'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks, no pretraining test ixd0'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks, no pretraining test idx1'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks, with PC Pretrained, Idx0'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks, with PC Pretrained, Idx1'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Aya, without photocoag, no inner losses'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\AE filtered 2_annotations'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\AE_with_2_annotations'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\AE_filtered'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\PC Pretrain two-fold'\n",
    "model_folder = 'Y:/FAZ/Models/Models New/Models New New/AE2/'\n",
    "\n",
    "# model_folder = model_folder + '\\\\'\n",
    "model_folder = model_folder + task_names[task_idx] + '\\\\'\n",
    "\n",
    "train_dice = np.zeros((N_splits,N_epochs))\n",
    "test_dice = np.zeros((N_splits,N_epochs))\n",
    "\n",
    "for test_idx in range(N_splits):\n",
    "    split_idx = splits[test_idx]\n",
    "#     txt_name = model_folder + task_names[task_idx] + '/' + 'task_idx' + str(task_idx) + 'train_dice' + '_epoch_' + str(final_epoch) + '__' + 'test_idx_' + str(test_idx) + '.txt'\n",
    "#     train_dice[test_idx,:] += np.squeeze(txt_to_array(txt_name))\n",
    "    txt_name = model_folder + 'task_idx' + str(task_idx) + '_' + 'train_dice' + '_epoch_' + str(final_epoch) + '__' + 'test_idx_' + str(split_idx) + '.txt'\n",
    "    train_dice[test_idx,:] += np.squeeze(txt_to_array(txt_name))\n",
    "\n",
    "#     txt_name = model_folder + task_names[task_idx] + '/' + 'task_idx' + str(task_idx) + 'test_dice' + '_epoch_' + str(final_epoch) + '__' + 'test_idx_' + str(test_idx) + '.txt'\n",
    "#     test_dice[test_idx,:] += np.squeeze(txt_to_array(txt_name))\n",
    "    txt_name = model_folder + 'task_idx' + str(task_idx) + '_' + 'test_dice' + '_epoch_' + str(final_epoch) + '__' + 'test_idx_' + str(split_idx) + '.txt'\n",
    "    test_dice[test_idx,:] += np.squeeze(txt_to_array(txt_name))\n",
    "\n",
    "for i in range(len(train_dice)):\n",
    "    label = test_names[i]\n",
    "    plt.plot(train_dice[i],color=colors[i],label=label)\n",
    "plt.grid()\n",
    "plt.title('Train Dice')\n",
    "# plt.ylim((0.85,1))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "##########################\n",
    "\n",
    "for i in range(len(test_dice)):\n",
    "    label = test_names[i]\n",
    "    plt.plot(test_dice[i],color=colors[i],label=label)\n",
    "plt.grid()\n",
    "plt.title('Test Dice')\n",
    "# plt.ylim((0.7,1))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "train_dice_final = np.round(np.mean(train_dice[:,-N_avg_epochs:],axis=1)*N_avg_epochs,1)\n",
    "test_dice_final = np.round(np.mean(test_dice[:,-N_avg_epochs:],axis=1)*N_avg_epochs,1)\n",
    "\n",
    "print('TASK:', task_names[task_idx])\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Train Dice Index:')\n",
    "for i in range(len(train_dice_final)):\n",
    "    print(test_names[i] + ': ' + str(train_dice_final[i]) + '%')\n",
    "print('Avg Train Dice:', np.mean(train_dice_final), '%')\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Test Dice Index:')\n",
    "for i in range(len(test_dice_final)):\n",
    "    print(test_names[i] + ': ' + str(test_dice_final[i]) + '%')\n",
    "print('Avg Test Dice:',np.mean(test_dice_final), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Calculate Cohen's d for paired samples\n",
    "def cohens_d(set1, set2):\n",
    "    diff = set2 - set1\n",
    "    return np.mean(diff) / np.std(diff, ddof=1)\n",
    "\n",
    "task_idx = 0\n",
    "splits = [0, 1]\n",
    "# splits = [0]\n",
    "final_epoch = 1000\n",
    "N_epochs = final_epoch\n",
    "# N_epochs = 100\n",
    "colors = ['b', 'g', 'r', 'c', 'y']\n",
    "task_names = ['Healthy', 'ALZ', 'AMD', 'DR', 'Photocoag']\n",
    "test_names = ['split 1', 'split 2']\n",
    "N_splits = len(splits)\n",
    "N_avg_epochs = 100\n",
    "\n",
    "# model_folder = 'Y:/FAZ/Models/Models New/Models New New/AE'\n",
    "# model_folder = 'Y:/FAZ/Models/Models New/Models New New/AE_with_2_annotations'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks, no pretraining test ixd0'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks, no pretraining test idx1'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks, with PC Pretrained, Idx0'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\FAZ 4 tasks, with PC Pretrained, Idx1'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Aya, without photocoag, no inner losses'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\AE filtered 2_annotations'\n",
    "# model_folder = 'Y:\\FAZ\\Models\\Models New\\Models New New\\PC Pretrain two-fold'\n",
    "\n",
    "main_folder1 = 'Y:\\FAZ\\Models\\Models New\\Models New New\\AE2'\n",
    "# main_folder2 = 'Y:\\FAZ\\Models\\Models New\\Models New New\\AE_filtered'\n",
    "main_folder2 = 'Y:\\FAZ\\Models\\Models New\\Models New New\\AE_with_2_annotations'\n",
    "# main_folder2 = 'Y:\\FAZ\\Models\\Models New\\Models New New\\Multitask 4 tasks, 2 annotations, no pretraining'\n",
    "\n",
    "folders = [main_folder1, main_folder2]\n",
    "ms = [0, 0]\n",
    "\n",
    "# model_folder = model_folder + '\\\\'\n",
    "\n",
    "Test_Dices = np.zeros((2,4,N_avg_epochs))\n",
    "\n",
    "for m_idx in range(2):\n",
    "    \n",
    "    main_folder = folders[m_idx] + '\\\\'\n",
    "\n",
    "    if ms[m_idx] == 0:\n",
    "        final_epoch = 1000\n",
    "        for task_idx in range(4):\n",
    "            train_dice = np.zeros((N_avg_epochs))\n",
    "            test_dice = np.zeros((N_avg_epochs))\n",
    "            model_folder = main_folder + task_names[task_idx] + '\\\\'\n",
    "            for test_idx in range(N_splits):\n",
    "                split_idx = splits[test_idx]\n",
    "                txt_name = model_folder + 'task_idx' + str(task_idx) + '_' + 'train_dice' + '_epoch_' + str(final_epoch) + '__' + 'test_idx_' + str(test_idx) + '.txt'\n",
    "                train_dice += np.squeeze(txt_to_array(txt_name))[-N_avg_epochs:]/2\n",
    "\n",
    "                txt_name = model_folder + 'task_idx' + str(task_idx) + '_' + 'test_dice' + '_epoch_' + str(final_epoch) + '__' + 'test_idx_' + str(test_idx) + '.txt'\n",
    "                test_dice += np.squeeze(txt_to_array(txt_name))[-N_avg_epochs:]/2\n",
    "            Test_Dices[m_idx,task_idx,:] = test_dice\n",
    "\n",
    "    else:\n",
    "        model_folder = main_folder\n",
    "        f_epoch = 479\n",
    "        for test_idx in range(N_splits):\n",
    "            txt_name = model_folder + '\\\\' + 'train_dice' + '_epoch_' + str(f_epoch) + '__' + 'test_idx_' + str(split_idx) + '.txt'\n",
    "            Test_Dices[1] += np.squeeze(txt_to_array(txt_name))[:,-N_avg_epochs:]/2\n",
    "\n",
    "\n",
    "for task_idx in range(4):\n",
    "    t_stat, p_value = ttest_rel(Test_Dices[0,task_idx,:], Test_Dices[1,task_idx,:]) # Perform a paired t-test\n",
    "    print('p value:', p_value)\n",
    "    cd = cohens_d(Test_Dices[0,task_idx,:], Test_Dices[1,task_idx,:])\n",
    "    print('Cohens d:', cd)\n",
    "\n",
    "# for i in range(len(train_dice)):\n",
    "#     label = test_names[i]\n",
    "#     plt.plot(train_dice[i],color=colors[i],label=label)\n",
    "# plt.grid()\n",
    "# plt.title('Train Dice')\n",
    "# # plt.ylim((0.85,1))\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(len(test_dice)):\n",
    "#     label = test_names[i]\n",
    "#     plt.plot(test_dice[i],color=colors[i],label=label)\n",
    "# plt.grid()\n",
    "# plt.title('Test Dice')\n",
    "# # plt.ylim((0.7,1))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder\n",
    "m_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %cd Y:/FAZ/Models/Aya\n",
    "# # %cd Y:/FAZ/Models/Nathan\n",
    "# # %cd Y:/FAZ/Models/Aya no inner losses\n",
    "# # %cd Y:/FAZ/Models/Nathan no inner losses\n",
    "\n",
    "# ##########################\n",
    "\n",
    "# train_dice = 0\n",
    "# for test_idx in range(4):\n",
    "# #     epoch = args.num_epochs-1\n",
    "#     epoch = 1999\n",
    "#     txt_name = 'train_dice' + '_epoch_' + str(epoch) + '__' + 'test_idx_' + str(test_idx) + '.txt'\n",
    "#     train_dice += txt_to_array(txt_name)\n",
    "# train_dice /= len(train_dice)\n",
    "\n",
    "# colors = ['b', 'g', 'r', 'c']\n",
    "# labels = ['Healthy', 'ALZ', 'AMD', 'DR']\n",
    "# for i in range(len(test_dice)):\n",
    "#     label = labels[i]\n",
    "#     plt.plot(train_dice[i],color=colors[i],label=label)\n",
    "# plt.grid()\n",
    "# plt.title('Train Dice')\n",
    "# plt.ylim((0.85,1))\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# ##########################\n",
    "\n",
    "# test_dice = 0\n",
    "# for test_idx in range(4):\n",
    "# #     epoch = args.num_epochs-1\n",
    "#     epoch = 1999\n",
    "#     txt_name = 'test_dice' + '_epoch_' + str(epoch) + '__' + 'test_idx_' + str(test_idx) + '.txt'\n",
    "#     test_dice += txt_to_array(txt_name)\n",
    "# test_dice /= len(test_dice)\n",
    "\n",
    "# colors = ['b', 'g', 'r', 'c']\n",
    "# labels = ['Healthy', 'ALZ', 'AMD', 'DR']\n",
    "# for i in range(len(test_dice)):\n",
    "#     label = labels[i]\n",
    "#     plt.plot(test_dice[i],color=colors[i],label=label)\n",
    "# plt.grid()\n",
    "# plt.title('Test Dice')\n",
    "# plt.ylim((0.7,1))\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# test_dice_final = np.round(np.mean(test_dice[:,-100:],axis=1)*100,1)\n",
    "\n",
    "# print('Dice Index:')\n",
    "# for i in range(len(test_dice_final)):\n",
    "#     print(labels[i] + ': ' + str(test_dice_final[i]) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
