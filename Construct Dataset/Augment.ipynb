{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_reshape_training_data(data):\n",
    "    train0 = data[0,:,:].unsqueeze(0)\n",
    "    train1 = data[1,:,:].unsqueeze(0)\n",
    "    train2 = data[2,:,:].unsqueeze(0)\n",
    "    train3 = data[3,:,:].unsqueeze(0)\n",
    "\n",
    "    y1 = torch.concatenate((train0,train1),axis=0).unsqueeze(0)\n",
    "    y2 = torch.concatenate((train1,train2),axis=0).unsqueeze(0)\n",
    "    y3 = torch.concatenate((train2,train3),axis=0).unsqueeze(0)\n",
    "\n",
    "    z1 = torch.concatenate((y1,y2,y3),axis=0).unsqueeze(0)\n",
    "    \n",
    "    return z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ce028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_rotate(img, angle):\n",
    "    sz = img.size()[0]\n",
    "    \n",
    "    # Zoom out so that nothing is cut off by rotation:\n",
    "    rsc = int(np.ceil((2**0.5)*sz/2)*2)\n",
    "    marg = int((rsc-sz)/2)\n",
    "    img_z = torch.zeros(rsc,rsc)\n",
    "    img_z[marg:rsc-marg,marg:rsc-marg] = img\n",
    "\n",
    "    # Convert to PIL, rotate, then convert back to tensor\n",
    "    img_pil = TF.to_pil_image(img_z)\n",
    "    img_pil_rot = TF.rotate(img_pil, angle)\n",
    "    img_rot = TF.pil_to_tensor(img_pil_rot).squeeze().to(torch.float)\n",
    "    \n",
    "    resize = transforms.Resize(size = sz)\n",
    "    img_rsz = resize.forward(img_rot.unsqueeze(0)).squeeze()\n",
    "    \n",
    "    return img_rsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc59bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_translate(img, trans=None):\n",
    "    if trans == None:\n",
    "        sz = img.size()[0]\n",
    "        mean_x = (torch.mean(img,0)>0)*1\n",
    "        l_margin = torch.argmax(mean_x)\n",
    "        mean_flip = torch.flip(mean_x,dims=(0,))\n",
    "        r_margin = torch.argmax(mean_flip)\n",
    "\n",
    "        margin = torch.min(l_margin, r_margin)\n",
    "\n",
    "        trans = random.uniform(0,margin)\n",
    "\n",
    "    img_shift = transforms.functional.affine(img.unsqueeze(2), angle = 0.0, translate = (0,trans), scale = 1.0, shear = 0.0).squeeze()\n",
    "    \n",
    "    return img_shift, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e00b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_resize(img, params=None, rm=1):\n",
    "\n",
    "    sz = img.size()[0]\n",
    "    \n",
    "    if params == None:\n",
    "\n",
    "        mean_x = (torch.mean(img,0)>0)*1\n",
    "        x_l = torch.argmax(mean_x)\n",
    "        mean_flip = torch.flip(mean_x,dims=(0,))\n",
    "        r_margin = torch.argmax(mean_flip)\n",
    "        x_h = sz - r_margin\n",
    "        x_sz = x_h - x_l\n",
    "\n",
    "        mean_y = (torch.mean(img,1)>0)*1\n",
    "        y_l = torch.argmax(mean_y)\n",
    "        mean_flip = torch.flip(mean_y,dims=(0,))\n",
    "        d_margin = torch.argmax(mean_flip)\n",
    "        y_h = sz - d_margin\n",
    "        y_sz = y_h - y_l\n",
    "\n",
    "        max_sz = max(x_sz,y_sz)\n",
    "    #     dec = random.randint(0,int(torch.floor((sz - max_sz)/2)))\n",
    "        dec = random.randint(0,rm*int(torch.floor((sz - max_sz))))\n",
    "        dec_x = random.randint(0,dec)\n",
    "        dec_y = random.randint(0,dec)\n",
    "        \n",
    "        img2 = torch.zeros((max_sz+dec,max_sz+dec))\n",
    "        diff = y_sz - x_sz\n",
    "\n",
    "        if y_sz > x_sz:\n",
    "            f2 = int(torch.floor(diff/2))\n",
    "            a = dec_y\n",
    "            b= y_h-y_l+dec_y\n",
    "            c = f2+dec_x\n",
    "            d = x_h-x_l+f2+dec_x\n",
    "\n",
    "    #         img2[dec_y:y_h-y_l+dec_y,f2+dec_x:x_h-x_l+f2+dec_x] = img[y_l:y_h,x_l:x_h]\n",
    "        else:\n",
    "            f2 = int(torch.floor(-diff/2))\n",
    "            a = f2 + dec_y\n",
    "            b = y_h-y_l+f2 + dec_y\n",
    "            c = dec_x\n",
    "            d = x_h-x_l+dec_x\n",
    "            \n",
    "        params = [a,b,c,d,y_l,y_h,x_l,x_h, max_sz+dec]\n",
    "\n",
    "    #         img2[f2:y_h-y_l+f2,0:x_h-x_l] = img[y_l:y_h,x_l:x_h]\n",
    "    else:\n",
    "        a   = params[0]\n",
    "        b   = params[1]\n",
    "        c   = params[2]\n",
    "        d   = params[3]\n",
    "        y_l = params[4]\n",
    "        y_h = params[5]\n",
    "        x_l = params[6]\n",
    "        x_h = params[7]\n",
    "        msd = params[8]\n",
    "        \n",
    "        img2 = torch.zeros((msd,msd))\n",
    "    \n",
    "    img2[a:b,c:d] = img[y_l:y_h,x_l:x_h]\n",
    "    \n",
    "    resize = transforms.Resize(size = sz)\n",
    "    img_rsz = resize.forward(img2.unsqueeze(0)).squeeze()\n",
    "    \n",
    "    return img_rsz, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_augment_img(img):\n",
    "\n",
    "    Nt = img.size()[0]\n",
    "    sz = img.size()[1]\n",
    "\n",
    "    for ii in np.arange(Nt):\n",
    "        img[ii,:,:] /= torch.max(img[ii,:,:])\n",
    "\n",
    "    if random.uniform(0,1) > 0.5:\n",
    "        img_rsz = torch.zeros(Nt,sz,sz)\n",
    "        _, params = f_resize(2*img[0,:,:] + img[1,:,:], rm=0)\n",
    "        for ii in np.arange(Nt):\n",
    "            img_rsz[ii,:,:], _ = f_resize(img[ii,:,:], params, rm=0)\n",
    "        \n",
    "        img_rot = torch.zeros(Nt,sz,sz)\n",
    "        angle = random.randint(-180,180)\n",
    "        for ii in np.arange(Nt):\n",
    "            img_rot[ii,:,:] = f_rotate(img[ii,:,:],angle)\n",
    "        \n",
    "        img = img_rot\n",
    "\n",
    "    if random.uniform(0,1) > 0.5:\n",
    "        img_shift = torch.zeros(Nt,sz,sz)\n",
    "        img_shift[Nt-1,:,:] , trans = f_translate(img[Nt-1,:,:])\n",
    "        for ii in np.arange(Nt-1):\n",
    "            img_shift[ii,:,:] , _ = f_translate(img[ii,:,:], trans=trans)\n",
    "\n",
    "        img = img_shift\n",
    "\n",
    "    if random.uniform(0,1) > 0.5:\n",
    "        img_rsz = torch.zeros(Nt,sz,sz)\n",
    "        img_sum = 0\n",
    "        for ii in np.arange(Nt):\n",
    "            img_sum += img[ii,:,:]\n",
    "        _, params = f_resize(img_sum)\n",
    "\n",
    "        for ii in np.arange(Nt):\n",
    "            img_rsz[ii,:,:], _ = f_resize(img[ii,:,:], params)\n",
    "\n",
    "        img = img_rsz\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_augment_dataset(train_data, num_pass=5):\n",
    "    num_img = np.shape(train_data.data)[0]\n",
    "\n",
    "    augmented_data = torch.zeros(tuple(np.append(num_img*num_pass,np.shape(train_data.data)[1:])))\n",
    "\n",
    "    for ii in np.arange((num_pass-1)*num_img):\n",
    "    # for ii in np.arange(10):\n",
    "\n",
    "        i = np.mod(ii,num_img)\n",
    "\n",
    "        img = train_data.data[i,:,:,:,:].squeeze()\n",
    "\n",
    "        plt.imshow(img[0,:,:] + img[1,:,:]/1.5, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(img[1,:,:] + img[2,:,:]/1.5, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(img[2,:,:] + img[3,:,:]/1.5, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        \n",
    "        print('-------------------------')\n",
    "        \n",
    "        img = f_augment_img(img)\n",
    "\n",
    "        augmented_data[ii,:,:,:,:] = img.unsqueeze(0)\n",
    "\n",
    "        plt.imshow(img[0,:,:] + img[1,:,:]/1.5, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(img[1,:,:] + img[2,:,:]/1.5, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(img[2,:,:] + img[3,:,:]/1.5, cmap=\"gray\")\n",
    "        plt.show()\n",
    "        \n",
    "        print('-------------------------')\n",
    "        print('-------------------------')\n",
    "\n",
    "    augmented_data[num_img*(num_pass-1):,:,:,:,:] = train_data.data\n",
    "    \n",
    "    return augmented_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
