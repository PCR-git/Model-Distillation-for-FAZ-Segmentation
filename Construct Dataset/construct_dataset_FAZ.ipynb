{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f74d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import f_rescale_dataset, f_train_test_split, f_get_mask, f_get_all_masks, f_Residuals\n",
    "# from utils import f_reshape_training_data, f_rotate, f_translate, f_resize, f_augment_img, f_augment_dataset\n",
    "from utils import f_reshape_training_data, f_rotate_and_zoom, f_random_crop, f_rotate_and_zoom_all, f_crop_all, f_flip_all, f_augment_dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c161973",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "batch_size = N\n",
    "ngpus = 1\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_normalize_imgs(imgs):\n",
    "    v, i = torch.max(imgs,1)\n",
    "    v, i = torch.max(v,1)\n",
    "\n",
    "    return (imgs.T/v).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io as sio\n",
    "\n",
    "# %cd /Users/Pracioppo/Desktop/VPTR/GA\n",
    "\n",
    "# GA_data_FAF = sio.loadmat('GA_data_orig_256.mat')[\"GA_data\"].astype(np.float32)\n",
    "# GA_data_mask = sio.loadmat('GA_data_256.mat')[\"GA_data_256\"].astype(np.float32)\n",
    "\n",
    "# print(np.shape(GA_data_FAF))\n",
    "# print(np.shape(GA_data_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15412a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd Y:/FAZ/Healthy/all_Healthy/extras/mats\n",
    "\n",
    "# imgs_DVC = torch.from_numpy(sio.loadmat('DVC_resized.mat')[\"Imgs\"].astype(np.float32))\n",
    "# masks_DVC = torch.from_numpy(sio.loadmat('DVC_masks.mat')[\"Imgs\"].astype(np.float32))\n",
    "# imgs_SVC = torch.from_numpy(sio.loadmat('SVC_resized.mat')[\"Imgs\"].astype(np.float32))\n",
    "# masks_SVC = torch.from_numpy(sio.loadmat('SVC_masks.mat')[\"Imgs\"].astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e94291",
   "metadata": {},
   "source": [
    "### Photocoagulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdde0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd Y:\\FAZ\\Photocoagulation\\Laser and Mask - All-orig-extractedImages\\mats\n",
    "\n",
    "# imgs = torch.from_numpy(sio.loadmat('resized.mat')[\"Imgs_rsz\"].astype(np.float32))\n",
    "# masks = torch.from_numpy(sio.loadmat('real_masks.mat')[\"Imgs_mask\"].astype(np.float32))\n",
    "# masks /= torch.max(masks)\n",
    "# L = len(imgs)\n",
    "# L\n",
    "\n",
    "# imgs = f_normalize_imgs(imgs)\n",
    "# masks = f_normalize_imgs(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c917b37",
   "metadata": {},
   "source": [
    "### Healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a54c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd Y:\\FAZ\\FAZ-cropped-SVC-graded\\Healthy\\all_Healthy\\PR\\mats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85922b",
   "metadata": {},
   "source": [
    "### ALZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96608f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd Y:\\FAZ\\FAZ-cropped-SVC-graded\\Alz\\all_Alz\\PR\\mats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7628ac",
   "metadata": {},
   "source": [
    "### AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277e9c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd Y:\\FAZ\\FAZ-cropped-SVC-graded\\AMD\\all_AMD\\PR\\mats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fdde5",
   "metadata": {},
   "source": [
    "### DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd471be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd Y:\\FAZ\\FAZ-cropped-SVC-graded\\DR\\all_DR\\PR\\mats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf50df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_DVC = torch.from_numpy(sio.loadmat('DVC_resized.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_DVC = torch.from_numpy(sio.loadmat('DVC_fake_masks.mat')[\"Imgs\"].astype(np.float32))\n",
    "imgs_SVC = torch.from_numpy(sio.loadmat('SVC_resized.mat')[\"Imgs\"].astype(np.float32))\n",
    "# masks_SVC = torch.from_numpy(sio.loadmat('SVC_fake_masks.mat')[\"Imgs\"].astype(np.float32))\n",
    "masks_SVC = torch.from_numpy(sio.loadmat('SVC_real_masks_aya.mat')[\"Imgs\"].astype(np.float32))\n",
    "\n",
    "masks_DVC /= torch.max(masks_DVC)\n",
    "masks_SVC /= torch.max(masks_SVC)\n",
    "imgs_SVC /= torch.max(imgs_SVC)\n",
    "\n",
    "masks_DVC = 1.0*(masks_DVC > 0.1)\n",
    "masks_SVC = 1.0*(masks_SVC > 0.1)\n",
    "\n",
    "L = len(imgs_DVC)\n",
    "L\n",
    "len(masks_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6596490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(L):    \n",
    "#     plt.imshow(255*masks_DVC[i,:,:] + imgs_DVC[i,:,:])\n",
    "#     plt.show()\n",
    "    plt.imshow(255*masks_SVC[i,:,:])\n",
    "    plt.show()\n",
    "    plt.imshow(255*masks_SVC[i,:,:] + 255*imgs_SVC[i,:,:])\n",
    "    plt.show()\n",
    "\n",
    "# for i in np.arange(L):   \n",
    "#     plt.imshow(255*imgs[i,:,:])\n",
    "#     plt.show()\n",
    "#     plt.imshow(255*masks[i,:,:] + 255*imgs[i,:,:])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516ebd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def f_augment_all(imgs, masks, p_rot = 0.8, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.25, N = 10):\n",
    "\n",
    "#     VF = torchvision.transforms.RandomVerticalFlip(1)\n",
    "#     CJ = torchvision.transforms.ColorJitter(brightness = 0.8, contrast = 0.8)\n",
    "\n",
    "#     Imgs = torch.zeros(N*L,256,256)\n",
    "#     Masks = torch.zeros(N*L,256,256)\n",
    "\n",
    "#     for j in np.arange(N):\n",
    "\n",
    "#         for i in np.arange(L):\n",
    "\n",
    "#             img = imgs[i]\n",
    "#             mask = masks[i]\n",
    "\n",
    "#             img /= torch.max(img)\n",
    "\n",
    "#             if j > 0:\n",
    "\n",
    "#                 if np.random.uniform(0,1) < p_shear:\n",
    "#                     shr = np.random.uniform(-25,25)\n",
    "#                     RA = torchvision.transforms.RandomAffine(degrees=0,shear=(shr,shr))\n",
    "#                     img = RA.forward(img.unsqueeze(0)).squeeze()\n",
    "#                     mask = RA.forward(mask.unsqueeze(0)).squeeze()\n",
    "\n",
    "#                 if np.random.uniform(0,1) < p_rot:\n",
    "#                     angle = np.random.uniform(0,90)\n",
    "#                     img = f_rotate_and_zoom(img, angle)\n",
    "#                     mask = f_rotate_and_zoom(mask, angle)\n",
    "\n",
    "#                 if np.random.uniform(0,1) < p_flip:\n",
    "#                     img = VF.forward(img)\n",
    "#                     mask = VF.forward(mask)\n",
    "\n",
    "#                 if np.random.uniform(0,1) < p_jitter:\n",
    "#                     img = CJ.forward(img.unsqueeze(0)).squeeze()\n",
    "\n",
    "#                 mask = mask>0.5\n",
    "\n",
    "#             Imgs[i*N + j,:,:] = img\n",
    "#             Masks[i*N + j,:,:] = mask\n",
    "\n",
    "#     return Imgs, Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_augment_all2(imgs_svc, masks_svc, imgs_dvc, masks_dvc, p_rot = 0.8, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.25, N = 10):\n",
    "\n",
    "    VF = torchvision.transforms.RandomVerticalFlip(1)\n",
    "    HF = torchvision.transforms.RandomHorizontalFlip(1)\n",
    "    CJ = torchvision.transforms.ColorJitter(brightness = 0.8, contrast = 0.8)\n",
    "\n",
    "    Imgs_SVC = torch.zeros(N*L,256,256)\n",
    "    Imgs_DVC = torch.zeros(N*L,256,256)\n",
    "    Masks_SVC = torch.zeros(N*L,256,256)\n",
    "    Masks_DVC = torch.zeros(N*L,256,256)\n",
    "\n",
    "    for j in np.arange(N):\n",
    "\n",
    "        for i in np.arange(L):\n",
    "\n",
    "            img_svc = imgs_svc[i]\n",
    "            mask_svc = masks_svc[i]\n",
    "            img_dvc = imgs_dvc[i]\n",
    "            mask_dvc = masks_dvc[i]\n",
    "\n",
    "            img_svc /= torch.max(img_svc)\n",
    "            img_dvc /= torch.max(img_dvc)\n",
    "\n",
    "            if j > 0:\n",
    "\n",
    "                if np.random.uniform(0,1) < p_flip:\n",
    "                    img_svc = VF.forward(img_svc)\n",
    "                    mask_svc = VF.forward(mask_svc)\n",
    "                    img_dvc = VF.forward(img_dvc)\n",
    "                    mask_dvc = VF.forward(mask_dvc)\n",
    "                    \n",
    "                if np.random.uniform(0,1) < p_flip:\n",
    "                    img_svc = HF.forward(img_svc)\n",
    "                    mask_svc = HF.forward(mask_svc)\n",
    "                    img_dvc = HF.forward(img_dvc)\n",
    "                    mask_dvc = HF.forward(mask_dvc)\n",
    "                    \n",
    "                if np.random.uniform(0,1) < p_rot:\n",
    "                    angle = np.random.uniform(0,90)\n",
    "                    img_svc = f_rotate_and_zoom(img_svc, angle)\n",
    "                    mask_svc = f_rotate_and_zoom(mask_svc, angle)\n",
    "                    img_dvc = f_rotate_and_zoom(img_dvc, angle)\n",
    "                    mask_dvc = f_rotate_and_zoom(mask_dvc, angle)\n",
    "                    \n",
    "                if np.random.uniform(0,1) < p_shear:\n",
    "                    shr = np.random.uniform(-25,25)\n",
    "                    RA = torchvision.transforms.RandomAffine(degrees=0,shear=(shr,shr))\n",
    "                    img_svc = RA.forward(img_svc.unsqueeze(0)).squeeze()\n",
    "                    mask_svc = RA.forward(mask_svc.unsqueeze(0)).squeeze()\n",
    "                    img_dvc = RA.forward(img_dvc.unsqueeze(0)).squeeze()\n",
    "                    mask_dvc = RA.forward(mask_dvc.unsqueeze(0)).squeeze()\n",
    "\n",
    "                if np.random.uniform(0,1) < p_jitter:\n",
    "                    img_svc = CJ.forward(img_svc.unsqueeze(0)).squeeze()\n",
    "                    img_dvc = CJ.forward(img_dvc.unsqueeze(0)).squeeze()\n",
    "\n",
    "                mask_svc = mask_svc>0.5\n",
    "                mask_dvc = mask_dvc>0.5\n",
    "\n",
    "            Imgs_SVC[i*N + j,:,:] = img_svc\n",
    "            Masks_SVC[i*N + j,:,:] = mask_svc\n",
    "            Imgs_DVC[i*N + j,:,:] = img_dvc\n",
    "            Masks_DVC[i*N + j,:,:] = mask_dvc\n",
    "\n",
    "    return Imgs_SVC, Masks_SVC, Imgs_DVC, Masks_DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_augment_all_single(imgs, masks, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, N = 1):\n",
    "\n",
    "#     np.random.seed(seed=None)\n",
    "    \n",
    "    VF = torchvision.transforms.RandomVerticalFlip(1)\n",
    "    HF = torchvision.transforms.RandomHorizontalFlip(1)\n",
    "    CJ = torchvision.transforms.ColorJitter(brightness = 0.8, contrast = 0.8)\n",
    "\n",
    "    Imgs = torch.zeros(N*L,256,256)\n",
    "    Masks = torch.zeros(N*L,256,256)\n",
    "\n",
    "    for j in np.arange(N):\n",
    "\n",
    "        for i in np.arange(L):\n",
    "\n",
    "            img = imgs[i]\n",
    "            mask = masks[i]\n",
    "\n",
    "#             if j > 0:\n",
    "            \n",
    "            h_flip_dice = np.random.uniform(0,1)\n",
    "            if h_flip_dice < p_flip:\n",
    "                img = HF.forward(img)\n",
    "                mask = HF.forward(mask)\n",
    "\n",
    "            rot_dice = np.random.uniform(0,1)\n",
    "            if rot_dice < p_rot:\n",
    "#                     angle = np.random.uniform(0,90)\n",
    "#                     angle = np.random.uniform(0,90**0.5/2)**2\n",
    "                angle = np.random.uniform(0,1)**2*45\n",
    "                img = f_rotate_and_zoom(img, angle)\n",
    "                mask = f_rotate_and_zoom(mask, angle)\n",
    "\n",
    "            v_flip_dice = np.random.uniform(0,1)\n",
    "            if v_flip_dice < p_flip:\n",
    "                img = VF.forward(img)\n",
    "                mask = VF.forward(mask)\n",
    "\n",
    "            shear_dice = np.random.uniform(0,1)\n",
    "            if shear_dice < p_shear:\n",
    "                shr = np.random.uniform(-15,15)\n",
    "\n",
    "                if rot_dice > p_rot:\n",
    "                    transx = np.random.uniform(-50,50)\n",
    "                    transy = np.random.uniform(-50,50)\n",
    "                else:\n",
    "                    transx = 0\n",
    "                    transy = 0\n",
    "                # RA = torchvision.transforms.RandomAffine(degrees=0,translate=(transx,transy),shear=(shr,shr))\n",
    "#                     img = RA.forward(img.unsqueeze(0)).squeeze()\n",
    "#                     mask = RA.forward(mask.unsqueeze(0)).squeeze()\n",
    "                img = torchvision.transforms.functional.affine(img.unsqueeze(0),angle=0,scale=1,translate=(transx,transy),shear=(shr,shr))\n",
    "                mask = torchvision.transforms.functional.affine(mask.unsqueeze(0),angle=0,scale=1,translate=(transx,transy),shear=(shr,shr))\n",
    "\n",
    "                jitter_dice = np.random.uniform(0,1)\n",
    "                if jitter_dice < p_jitter:\n",
    "                    img = CJ.forward(img.unsqueeze(0)).squeeze()\n",
    "            \n",
    "#             print(h_flip_dice)\n",
    "#             print(rot_dice)\n",
    "#             print(v_flip_dice)\n",
    "#             print(shear_dice)\n",
    "#             print(jitter_dice)\n",
    "            \n",
    "#             mask = mask>0.5\n",
    "\n",
    "            Imgs[i*N + j,:,:] = img\n",
    "            Masks[i*N + j,:,:] = mask\n",
    "\n",
    "    return Imgs, Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b91107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imgs_SVC, Masks_SVC, Imgs_DVC, Masks_DVC = f_augment_all2(imgs_SVC, masks_SVC, imgs_DVC, masks_DVC)\n",
    "\n",
    "# if torch.sum(torch.isnan(Imgs_SVC + Masks_SVC + Imgs_DVC + Masks_DVC)) > 0:\n",
    "#     print('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(N*L):\n",
    "#     plt.imshow((Imgs_SVC + Masks_SVC)[i,:,:])\n",
    "#     plt.show()\n",
    "# #     plt.imshow((Imgs_DVC + Masks_DVC)[i,:,:])\n",
    "# #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9297ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs_SVC.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7001dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imgs, Masks = f_augment_all_single(imgs_SVC, masks_SVC, p_rot = 0.5, p_flip = 0.5, p_jitter = 0.8, p_shear = 0.5, N = 1)\n",
    "\n",
    "if torch.sum(torch.isnan(Imgs+Masks)) > 0:\n",
    "    print('ERROR')\n",
    "\n",
    "for i in np.arange(N*L):\n",
    "    plt.imshow((255*Imgs)[i,:,:])\n",
    "    plt.imshow((255*Imgs + 255*Masks)[i,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat('Imgs_DVC_aug.mat',{\"Imgs_DVC\": Imgs_DVC.numpy()})\n",
    "sio.savemat('Imgs_SVC_aug.mat',{\"Imgs_SVC\": Imgs_SVC.numpy()})\n",
    "sio.savemat('Fake_Masks_DVC_aug.mat',{\"Masks_DVC\": Masks_DVC.numpy()})\n",
    "# sio.savemat('Fake_Masks_SVC_aug.mat',{\"Masks_SVC\": Masks_SVC.numpy()})\n",
    "sio.savemat('Real_Masks_SVC_aug.mat',{\"Masks_SVC\": Masks_SVC.numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99817ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sio.savemat('Imgs_aug.mat',{\"Imgs\": Imgs.numpy()})\n",
    "# sio.savemat('Fake_Masks_aug.mat',{\"Masks\": Masks.numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a5b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
